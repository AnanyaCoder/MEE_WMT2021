I am committed to assisting computers in communicating with the world around us.
There are many ways to do this, and I like to focus on helping computers talk about what they see and understand.
Given this scenario, a modern computer vision algorithm can tell you that there is a woman and a dog.
It can tell you that the woman is smiling.
It can even tell you that this dog is very cute.
I deal with this problem thinking about how humans understand and live with the world.
Those thoughts, memories, and stories in such a scene, might arouse human attention.
The interconnection of all connected situations.
Maybe you've seen a dog like this before, or you've spent time, running on a beach like this, and further evoked memories and thoughts of past vacations, time spent running around with other dogs, when you used to go to the beach.
One of my guiding principles is that by helping computers understand what this experience is like, and thus understand what we believe and feel in common, then we have the ability to start evolving computer technology in a way that complements our experience.
So, digging deeper into this, I started working on helping computers generate human-like stories a few years ago, from image sequences.
So, one day, while I was working on my computer, I asked it what it thought about my trip to Australia.
It looked at the picture and saw a koala bear.
It doesn't know what a koala is, but the computer says it thinks a koala looks like an interesting creature.
Then I shared a series of images with the computer of the burning house.
The computer looked at the picture and it said, "This is an amazing view! It's spectacular!"
It sends chills down my spine.
The computer sees a horrific, life-changing and life-destroying event and sees it as a positive thing.
I realized that the computer recognized the contrast between red and yellow, and thought it was something to be positively evaluated.
Partly because most of what I feed into my computer is positive images.
That's because when people talk about their experiences, they tend to share positive images.
When was the last time you saw a selfie at a funeral?
I realized that in the process of improving artificial intelligence, it is task to task, data set to data set, creating huge gaps, flaws and blind spots in computer understanding.
While doing this, I'm coding for various biases.
Prejudice reflects limited perspectives, stemming from a data set -- which reflects the same human beings, such as stereotypes and stereotypes.
I think back to the development of that technology that got me to where I was that day -- the first color image was calibrated for the skin color of a white woman, which meant that color photography was biased against blackface.
And that same bias, that blind spot carried over into the 90s.
The same blind spot still exists even today in the application of facial recognition technology, how to identify the faces of different people.
In today's research, I think of state-of-the-art techniques that tend to limit our thinking to one dataset and one question.
And in doing so, we're creating more blind spots and biases that will be further amplified when using AI.
That's when I realized we had to think deeply about how the technology we invent today will be seen five to ten years from now.
In human interaction with the environment, humans take time to correct problems, so evolution is slow.
Artificial intelligence, by contrast, is advancing at an incredible rate.
That means it does matter, and we need to think about it now -- reflect on our blind spots and biases, and consider how those biases affect the technology we create today, and discuss what today's technology means for the future.
CEOs and scientists, have weighed their ideas about the future of AI development.
Stephen Hawking warned: "Artificial intelligence will kill humanity."
Elon Musk warns that this is an existential risk, and one of the greatest risks we face as a civilized society.
"I don't see why people aren't more worried about AI," Bill Gates said.
But these views -- are only part of the story.
The math, the models, these basic building blocks of artificial intelligence, that we can all get and use.
We have open-source tools for learning machines and making our own contributions at the same time.
In addition, we can also share our experience.
We can share what makes us excited about technology and how it relates to us.
We can discuss what we love.
We can communicate with the foreseeable future, which may be more beneficial on the technical side, or more problems may arise over time.
If we all focus on opening up conversations about AI and looking to the future, it will help create a regular conversation and awareness about what AI is, what it can become? and all the things we need to do to achieve the outcomes that are best for us.
We've seen and understood this in the technologies we use today.
We use smartphones, digital assistants and automatic vacuum cleaners.
Are they evil?
Maybe sometimes.
Are they beneficial?
Yes, they are too.
They are not exactly the same.
There you have seen the light of the future.
The future will continue to start with what we build and create now.
We kicked off the domino effect, which opened up the evolutionary pathway for AI
In our time, shaping tomorrow's artificial intelligence.
Let us immerse ourselves in the technology of augmented reality and bring the world of the past to life,
When people have trouble communicating, technology helps them share their experiences with each other.
Technology built on online visual media can be used for autonomous driving of cars.
Technology produces language based on the understanding of images, which can evolve into technology that assists the visually impaired, helping them better have a visual world.
We also see how technology can cause some problems.
We have technology today that analyzes the physical characteristics we are born with -- like the color of our skin or the expressions on our faces -- to determine if we're criminals or terrorists.
We have the technology to process data, to process data about gender or race to determine if we can get a loan.
Everything we see now is just a snapshot of the evolution of AI.
Because where we are now is a moment in evolution.
This means that what we do now will affect how things will go down the road and into the future world.
If we want AI to help us evolve the way humans do, we need to define strategies and goals, and open that path right away.
What I want to see is the direction of the development of a culture and environment suitable for human beings.
Technology can help us heal people with neurological disorders or other disabilities, making life as challenging as everyone else.
Technology works without regard to your features or skin color.
My focus today is on the technology of tomorrow and ten years from now,
Artificial intelligence can emerge in many different ways.
But in this case, it's not a self-driving car without any destination.
This is a car we can drive and control at the same time.
We choose when to speed up and when to slow down.
We choose whether or not to turn.
We choose what the future of artificial intelligence will be.
There will be a vast arena where AI can be everything.
It becomes a lot of different things.
Now it's up to us to figure out what needs to be implemented to ensure that AI outcomes are better for all humans.
Thank you.
(applause)
I hope you'll take a moment to consider the very simple fact that, so far, most of what we know about the universe comes from light.
We stand on the earth and look up at the night sky. We can see the stars in the sky with the naked eye.
The strong sunlight is so dazzling,
We can see the light reflected from the moon,
Ever since Galileo pointed his humble telescope at the celestial bodies in the universe, the universe as we know it today is presented to us through light.
With the help of modern telescopes, we've been able to collect dazzling, silent images of the universe -- a series of images going all the way back to the Big Bang.
However, the universe is not a mime because the universe is not really silent.
I want to tell you that the universe has its own soundtrack, and the universe itself is playing non-stop because space can vibrate like a drum.
So it can send out a series of sounds to the universe when something big happens.
Now, we want to be able to give sound to this magnificent visual work of the universe.
While we've never heard a voice from outer space, we should be able to turn up the volume and hear what's going on there in the next few years.
With the ambitious goal of capturing cosmic sounds, we're focusing our attention on black holes and the promise they present, because black holes can hit space-time like drumsticks hitting a drumhead and make very special sounds, and I'm very excited to play you some of the sounds we've predicted.
One day in the future we might see a shadow. A black hole can leave a shadow on a very bright background, but it hasn't been observed yet.
Although black holes cannot be seen, they can be heard because they hit space-time like drums.
The idea that the universe could sound like a drum came from Albert Einstein, and a lot of our ideas come from him.
Einstein realized that if the universe was empty, if the universe was empty, it would look like this picture, except for those guide lines drawn on it.
But if we were in free fall in the universe, even without these guide lines, our trajectory would draw these lines, because we would find us moving in a straight line through the universe along a straight line that doesn't bend.
Einstein also realized -- and this is really the most critical part (matter also means "matter") -- that if you put energy and matter in the universe, the universe bends. Objects that are in free fall will be deflected as they pass through a celestial body like the sun, following a curved path in space.
This is Einstein's great theory of general relativity.
Even the path of light is bent.
When the bend is large enough, it will revolve around the orbit of the sun, just like the earth revolves around the sun and the moon revolves around the earth.
This is the natural curve of the universe.
But Einstein didn't realize that if you compress the sun into a ball 6 kilometers in diameter -- that is, if you compress a million times the mass of Earth into a ball 6 kilometers in diameter, you would create a black hole, an object so dense that if light got too close to it, it wouldn't be able to escape -- leaving a giant black shadow in the universe,
But Einstein always thought black holes were just a mathematical singularity.
He doesn't believe that black holes really exist.
He believed that nature would prevent black holes from forming to protect us.
It was decades before people started using the term "black hole" and realized that black holes are real objects -- in fact, they are the dead state of some extremely massive stars after a catastrophic collapse at the end of their lives.
Our sun does not collapse to form a black hole.
It's actually not big enough for its mass.
But if we do some thought experiments -- which Einstein loved so much -- we can imagine smashing the sun into six kilometers, and then putting a tiny Earth in an orbit around it, say, 30 kilometers from the black hole sun.
The earth will shine by itself, because now that the sun is gone, we have no other source of light - so our little earth has to shine by itself.
You'll find that you can even put Earth in orbit 30 kilometers away from a black hole and have it orbit happily.
The black hole is actually about the size of Manhattan.
It could swell up to Hudson Avenue before it destroys the Earth.
But basically that's what we're talking about.
We're talking about an object compressed to half the size of Manhattan.
So we moved this Earth close to the black hole - 30 kilometers away - and we noticed that it was orbiting the black hole in perfect orbit.
There are some rumors that black holes will eat everything in the universe, but in reality you have to get really close to actually fall in.
But impressively, from our point of view, we can always see the Earth.
It cannot hide behind a black hole.
Some of the light emitted from the earth falls into the black hole, but some of it is bent by the black hole and is seen by us.
So you can't hide anything behind a black hole.
If this is Battlestar Galactica and you're fighting Cylons, don't hide behind a black hole.
They can see you.
Our sun doesn't collapse into a black hole; it's not massive enough, but there are tens of thousands of black holes in our galaxy.
If one of them was eating the Milky Way, it would look like this.
We'll see the shadow of a black hole cast on hundreds of billions of stars in the Milky Way and the dust lanes lit by the stars.
If we were to fall into this black hole, we would see light being refracted around the black hole, and we wouldn't even feel some huge change happening at all when we started to enter this shadow.
If we try to fire the rocket and get out of there, it won't work out well, because we can't escape, not even light.
Although a black hole looks dark from the outside, it doesn't look like that from the inside, because light from all galaxies can fall with us into the black hole.
And even so, our clocks seem to be slowing down compared to the Milky Way's time due to relativistic time dilation effects, which makes it look like the galaxies outside are accelerating, just before we ourselves are destroyed by the black hole.
It's like experiencing a near-death experience, where you see the light at the end of the tunnel, but it's a complete death experience.
(Laughter) You can't tell anyone that you saw light at the end of the tunnel.
So far, we've never seen such a shadow cast by a black hole, but black holes can be heard, even if they can't be seen.
Imagine, in a real astronomical scene - imagine two black holes that have been together for a long time.
Maybe they used to be stars and then collapsed into two black holes - each 10 times the mass of the sun.
Now we compress them to within 60 kilometers.
They can rotate hundreds of times per second.
At the end of their lives, they approach each other at the speed of light.
They travel thousands of kilometers in fractions of a second, and in the process, they not only bend space, but they also create vibrations in space in the wake behind them, a real space-time wave.
Black holes squeeze and stretch space when they collide with the universe.
These vibrations travel through space at the speed of light.
This computer simulation was done by NASA Goddard's Relativity Group.
It took almost 30 years before and after solving this problem.
This is one of many groups.
It shows two black holes orbiting each other, these are imaginary curves.
As you can see - maybe a little blurry - you can see the red waves being emitted, these are gravitational waves.
They are the actual cosmic sounds that will travel outward at the speed of light from the black holes as they merge with each other, until the two black holes merge into one quietly spinning black hole.
If you stand close enough, your ears will resonate with the squeezing and stretching of these spaces.
You can really hear these sounds.
Of course, you'll find helplessly that your head is also squeezed and stretched, so you may not be able to understand what's going on.
But I'd like to play the sound of our prediction for you.
This is the result of my group's research - a relatively simple computational model.
Imagine a less massive black hole falling into a more massive black hole.
The sound you hear comes from the collision of the low-mass black hole with space as it approaches the massive black hole.
If they are far apart, the sound will be very low.
But gradually the sound became like a drumstick hitting the space, making the space vibrate like a drum.
We can predict what this sound will become.
We know that low-mass black holes get faster and louder as they fall.
Eventually, we will hear that the small black hole falls completely into the big black hole.
I've never felt this sound so loud - it's actually amplified here.
When I listened to it at home, I felt that the sound was a little unsatisfactory.
It sounds like, ding, ding, ding.
Here's another sound our research group simulated.
I'm not going to show you images here, because black holes don't leave any useful trails, and real space doesn't show you those virtual curves.
But if you hear this sound while you're on vacation in space, I suggest you run away.
(laughs) Better stay away from this sound.
Both black holes are moving.
Two black holes are approaching each other.
In this case, they are all shaking violently.
Then, they will merge into one.
That high-pitched sound is the hallmark of black hole fusion - a high-pitched sound when the fusion is over.
This is our prediction of what we're going to see.
Luckily we are very safe in Long Beach, CA.
Needless to say, somewhere in the universe, two black holes have merged together.
There is also no doubt that the space around us can also feel these vibrations that travel a million light-years across, or from a million years ago, travel at the speed of light and eventually meet us.
But these sounds are so small that we can't hear them at all.
There are experiments in the world that take a lot of effort to set up -- one of them called LIGO -- that will detect vibrations in space less than a nucleus every four kilometers.
This is a very bold attempt, and its sensitivity will not be surpassed in the next few years - it will be used to detect vibrations in space.
Another research project on the universe, which is expected to start within the next decade, is called LISA.
LISA will be able to see supermassive black holes - those that are millions or even billions of times the mass of the sun.
In images from Hubble, we see these two galaxies.
It looked like they were still hugging each other.
There may be a supermassive super black hole in their center respectively.
But they are not standing still, in fact they are merging.
The two black holes will collide, and their fusion will take billions of years.
So collecting the sounds they make is beyond the limits of our human perception.
But LISA can see the final stages of two supermassive black holes that started merging long ago, 15 minutes before they merge.
This detection is not limited to black holes, it can also be used to detect any large disturbance in the universe - the biggest of which is the "big bang".
When the term was coined, some people jeered - "Oh, who would believe in the Big Bang?"
This animated short, made by my friends at Proton Studios, shows what it looks like to watch the Big Bang from the outside.
We would never really want to be that way; we would like to be inside the universe, because there is no such thing as being outside the universe.
So, imagine you're in the middle of a big bang.
The universe is everywhere, everything in the world surrounds you, and space sways chaotically.
Fourteen billion years have passed, and the voice still haunts us.
Galaxies gradually formed, batches of stars formed in the galaxy. On a certain planet, there exists at least one such planet, which is suitable for life.
Here, we're frantically building experiments, doing calculations, writing computer code.
Imagine, a billion years ago, two black holes collided.
This voice has always traveled through time and space.
We didn't even show up here.
It's getting closer - 40,000 years ago, we were still painting on the stone walls of the cave.
If the sound we were trying to capture was the Big Bang, it would sound like this.
Strictly speaking, it is noise.
It's a white noise, a chaotic bell.
But it's everywhere around us, as long as it's not canceled out by some other process in the universe.
If we could detect these sounds, it would be like music to our ears, because this quiet echo comes from the moment we were created, from the universe we look up into.
So in the next few years, we'll be able to turn these soundtracks up a little bit, and let the universe be presented to us as audio.
But if we can detect those earliest moments, it will also bring us one step closer to understanding the Big Bang, and enable us to ask some of the most difficult and elusive questions.
If we play the history of the universe backwards, we can know that there was a big bang in the past, and we can even hear its loud noise, but is our big bang the only big bang in the universe?
I mean we can't help but ask, has there ever been a similar big bang before then?
Will it happen again in the future?
I would say that if you take this question up to the level that TED advocates for rethinking, at least in this last minute, we can ask some questions that we really may never be able to answer.
But we can't help but ask: Could our universe be just an episode in a larger history?
Or, are we just a branch in the multiverse - each of which has experienced its own big bang - maybe some of them have humming black holes, maybe some don't - maybe some have conscious life, maybe some don't - they don't belong to our past or our future, but are somehow connected to us?
So we can't help but wonder, if there is a multiverse, is there life in the other branches of this multiverse?
This is life in our multiverse.
Are there other beings in the multiverse who are also guessing our existence, thinking about their own origins?
If so, I can imagine them doing calculations, writing computer code, building experimental instruments, trying to detect those faint sounds from their origin, and wondering who else was there.
Thank you. Thank you all.
(applause)
One winter morning a few years ago, in Johannesburg, South Africa, I was driving to work to find the city shrouded in smog.
I drive by it almost every day, but this time it's unusual, I've never seen anything like it before.
Johannesburg is famous for its characteristically beautiful skyline, but it was barely visible that morning.
I soon realized that what I was seeing was a severe haze caused by air pollution.
The contrast between the beautiful environment I used to know and the skyline now shrouded in smog swells in my mind.
I fear that there is a good chance that the once colorful sunset will be swallowed up by a dark haze.
At that moment, I felt a strong urge to do something, but I didn't know what to do.
All I know is that I can't just sit back and watch.
The biggest challenge was that I didn't know much about environmental science, air quality management, or atmospheric chemistry.
I'm a computer engineer, and I'm pretty sure I can't solve air pollution by coding.
(Laughter) In what capacity am I going to address this?
I'm just a peep of the market.
Over the next few years, I learned an important lesson that we should all take to heart if we want to achieve a better future.
Even if you are not an expert in a particular field, your expertise may imply solutions to problems in that field.
Sometimes the unique perspective you have can trigger unconventional thinking that can shape a situation, but you need to be bold.
Only then can you know the result.
All I knew at the time was that if I wanted to try to change, I had to know enough about pollution, so I was a student again.
I did some basic research, and I quickly learned that air pollution is the biggest environmental health risk in the world.
According to the World Health Organization, in 2012, almost 14% of all deaths worldwide were caused by air pollution in and around the home, especially in low- and middle-income countries.
Air pollution kills more people each year than malaria and AIDS.
In Africa, premature deaths from unsafe sanitation, or deaths from malnutrition among children, pale in the face of air pollution, and it also has a huge economic cost: In 2013, spending on them exceeded $400 billion, according to the Organization for Economic Cooperation and Development.
In my work, I explore the technological frontiers of artificial intelligence, including the symbiotic relationship between humans and machines, to find beneficial footholds and help us make better decisions.
When I think about air pollution again, it becomes clear that we need to find better ways to make better decisions about how to deal with air pollution. Given the size of the problem, collaboration is very necessary.
So I decided to meet some people working in this field.
I started talking to officials in Johannesburg and other surrounding cities, I joined the local scientific community, and I made a few phone calls to people who were totally unknown but related.
The experiences I have embarked on in intervening have helped me gain a deeper understanding of the issue.
It also helps me avoid the pitfall that people in my field sometimes fall into when trying to innovate: adopting a technology quickly before actually mastering the problem.
I started thinking, what can I do to improve this situation?
I started asking myself how to effectively blend my knowledge and skills in software engineering and artificial intelligence with the expertise of the people I connect with.
I want to create an online air quality management platform to reveal future pollution trends and make relevant predictions to determine what may happen.
I'm sure my idea can become a realistic solution, but with uncertainty, I can't guarantee it will work.
All I have is a specific set of engineering skills, skills that I get from my job. (Laughter) Of course, my skills are new to someone who's been working in air pollution for years.
I've come to realize that sometimes a fresh perspective, a new skill set, can lead to something remarkable.
Our willpower and imagination are a beacon that directs us to overcome obstacles and start a new chapter.
I got a deeper understanding of the air pollution issue, looking for air pollution data over the past decade, and meteorological data in and around Johannesburg. After that, with my colleagues in South Africa and China, I created an air quality resolution support system and uploaded it to the cloud.
The software analyzes historical and real-time data to reveal trends in pollution over time and space.
We then used new machine learning techniques to predict future pollution days in advance.
This means residents can make better decisions about their daily itineraries and where to settle with their families.
We can predict adverse pollution events in advance, and define the sources of severe pollution, so that relevant authorities can issue orders to adjust their business activities.
By supporting scenario planning, city planners can also make better decisions about how to expand infrastructure work, such as housing settlements in industrial areas.
We have established a pilot pilot of the technology, running for 120 days, covering the whole of South Africa.
Our expected results were validated. The predicted data we showed showed a strong correlation with the data we collected in the field.
Through our management, we brought in the world's leading cutting-edge instrumentation to predict air quality with unprecedented resolution and accuracy, benefiting the city I drove into on a recent winter morning. At that point, I said to myself, "Something's not right, and I have to figure out what to do about it."
So, the point is: What if I hadn't researched in depth about air pollution?
What if instead of focusing on the state of the environment in the country, I hope that some place, some other person will take care of it?
What I've learned from this is that when working hard on a cause we all believe in, it's important to focus on the likelihood of success and consider the consequences of inaction.
We should not be distracted by opposition and resistance, it should motivate us to go further.
So no matter where you are in the world, the next time you find that some kind of natural curiosity in you is piqued and it's about something you care about, and you have some crazy or brave idea, even if it's not your area of expertise, ask yourself: why not try it?
Why not go ahead and solve the problem, do your best, in your own way?
You may get a pleasant surprise.
Thank you all.
(applause)
Many people think that driving is something that only those who can see can do.
Blind people trying to drive a car alone and safely has until now been considered an impossible task.
Hi, my name is Dennis Hong, and we've built a car for people with visual impairments for the freedom and independence of the blind.
Before I talk about this car for the blind, let me briefly mention another project I worked on called the DARPA Urban Challenge.
It's about building a mechanical car that can drive itself.
You press the start button, don't touch anything, and it reaches its destination completely automatically.
At the 2007 Challenge, our team won $500,000 and finished third in the competition.
Around that time, the National Association of the Blind, or the Blind Association, challenged the design team about who could design a car that would allow blind people to drive independently and safely.
We thought we'd give it a try because we thought, hey, how hard is this going to be.
We already have an autonomous car.
We just have to let the blind drive inside, and that's it, right?
(Laughter) But we were wrong.
What the Blind Association wants is not a car that can carry blind people around, but a car that blind people can take the initiative to make choices and drive.
So we had to give up everything we had and start from scratch.
To test this crazy idea, we designed a prototype of a small sand buggy to test its feasibility.
In the summer of 2009, we invited many blind youths across the country and gave them a chance to take this car for a spin.
It was definitely a cool experience.
But the problem with this car is that it's designed to allow blind people to drive only in very limited situations, like a closed parking lot -- even on a trail made of red traffic cones.
So with this success, we decided to take the important next step, to build a real car that can drive on real roads.
So how does it work?
Well, it's a relatively complex system, but let me explain it and simplify it.
We have three stages.
We have a sensing phase, a computational phase and a non-visual interface.
The driver is clearly invisible, so the system must be able to sense its surroundings and collect data for the driver.
For this, we use the initial metering element.
It measures acceleration, angular acceleration -- just like the human ear, the inner ear.
I combined this information with the global positioning system to predict where the vehicle is.
We also use two cameras to detect the driving path.
We also use three laser rangefinders.
The laser scans the environment to detect obstacles - vehicles passing by from the front, rear, and any obstacles in the way, any obstacles around the vehicle.
All this massive amount of information is then aggregated into a computer, and the computer does two things.
First and foremost, one thing is to process information to understand the surrounding environment -- which are driving paths and which are obstacles -- and translate that information to the driver.
This system is also very intelligent and can calculate the safest driving path.
We can also issue instructions on how to operate the vehicle's operating procedures.
But the question is: How can we transmit information and instructions quickly and accurately enough to a blind person to make sure he can drive?
To this end, we have designed many different non-visual user interface technologies.
The original three-dimensional flat sound system, vibrating vests, voice-activated gears, leg straps, and even shoes that put pressure on the feet.
But today we're talking about three of these non-visual user interface technologies.
The first interface is called the steering handle.
It's a pair of gloves, and it has vibrating elements in the knuckles, so you can transmit instructions on how to drive -- direction and magnitude.
Another device is called a velocity belt.
This car chair -- actually, it's a massage chair.
We took it apart, we reorganized the vibrating elements in different patterns. We let them transmit information about speed, but also instructions on how to use the throttle and brakes.
Here, you can see how the computer understands its surroundings. Because you can't see the vibrations, we actually put red LEDs on the driver so he can see what's going on.
This is the sensor data, which is transmitted from the sensor to the computer.
So these two devices, the steering handle and the speed belt, are very effective.
But the problem is that these are command hinting devices.
So it's not really freedom, right?
The computer tells you how to drive -- turn left, turn right, accelerate, brake.
I call this the co-pilot problem.
So we're avoiding command-hint devices and focusing more on information devices.
A typical example of such a non-visual information interface is called an empty graph.
Think of this as a display for the blind.
It's a small tabletop with a lot of holes in it through which compressed air is drawn out, so it can be described as a picture.
So even if you're blind and you put your hand on it, you can sense the path and obstacles.
In fact, you can also change the frequency and possibly the temperature of the air.
This is actually a multidimensional user interface.
Here, you can see the left and right cameras and how the computer parses and sends this information to the empty image.
That's it, we're showing a simulation program where a blind man is driving with an empty map.
This program is very helpful in training blind drivers and quickly testing different theories in terms of different kinds of non-visual user interfaces.
That's basically how it works.
But this car is a model car, and it won't be on the road unless it's proven to be as safe to drive as today's cars, or safer.
I truly believe this will happen.
But are societies, can they accept this radical idea?
How are we going to handle insurance?
How will we issue a driver's license?
Behind the technical challenges there are many different obstacles that we need to address before they become a reality.
Of course, the main purpose of this project is to design a car that can be driven by blind people.
But potentially more important than that is the enormous value contained in the by-products of this project.
Sensors that can be used to see through darkness, rain and fog.
And this new kind of interface, we can use these technologies to make them safer vehicles for visible crowds.
Or for the blind, home devices in everyday life - educational facilities, office facilities application services.
Imagine a classroom where a teacher writes notes on a blackboard. Blind students can also use these non-visual interfaces to understand and read what the teacher writes.
This is extremely precious.
What I have shown you today is just the beginning.
Thank you very much.
(applause)
As an artist, connection is very important to me.
Through my artwork I try to illustrate that human beings are not separated from nature but that everything is connected.
I went to Antarctica for the first time about 10 years ago, and I also saw icebergs for the first time.
I am in awe.
My heart was beating fast, dizzy, trying to understand what was in front of me.
The iceberg next to me surfaced almost 200 feet. I can only find it strange that this is one snowflake over another, forming year after year.
Icebergs form when they break off glaciers or from ice shelves.
Each iceberg has its own unique personality.
They interact with their surroundings and their situation in a distinct way.
Some icebergs refuse to compromise and stick to the end, while others can't bear to break apart in a moment of intense passion.
When you look at icebergs, it's easy to think that they're all isolated, that they're separate, singular, more like what we humans sometimes think of ourselves.
But the reality is much more than that.
As the iceberg melts, I breathe its ancient smell.
As the iceberg melts, it releases fresh, mineral-rich water that nourishes everything.
I set out to photograph these icebergs as if I were photographing portraits of my ancestors, learning that in these individual moments the icebergs were there in that way but never again.
When they melt, it's not death; it's not an end, but a continuation of the road to life.
Some of the icebergs I've photographed are very young -- thousands of years old.
Some ice is more than 100,000 years old.
The final image I want to show you is an iceberg I took on Kekertsuatsiak in Greenland.
This is a very rare opportunity for people to actually witness an iceberg roll.
So this is as shown in the picture.
On the left you can see a small boat.
It's a boat about 15 feet.
I want you to pay attention to the shape of the iceberg and its deformation on the water.
Here you see it start to roll, the boat moves to the other side and a man is standing there.
This is an average-sized Greenland iceberg.
It surfaced about 120 feet or 40 meters high.
This video was shot in real time.
(Music) Like these icebergs, they show people different aspects of their personality.
Thank you.
(applause)
Do you know how many medium flowering plants there are?
There are 250,000 species - at least as many as we know - 250,000 flowering plants.
And flowers are a hassle.
Getting plants to thrive is really difficult.
It takes a lot of experience and a lot of resources.
Why is it so troublesome?
The answer, of course, is, like so many other things in the world, gender.
I know what goes through your mind when you look at these pictures.
The reason sexual reproduction is so important -- there are so many other ways plants can reproduce.
Can be used for cuttings; can be bisexually propagated from the same plant; can be pollinated from the same plant.
But they do need to spread their genes mixed with other genes so that they can survive.
That's how evolution works.
Plants now transmit this information through pollen.
Some of you may have seen these pictures before.
Like I said, every home should have a scanning electron microscope that can see this.
There are as many different types of pollen as there are flowering plants.
This is actually quite useful for forensics and so on.
Most of the pollen that causes us to get hay fever comes from plants that use the wind to spread the pollen. It's a very inefficient process, which is why pollen always ends up in our noses.
Because most of them were thrown away, it was hoped that the germ cells contained in the pollen, the male germ cells, would just happen to land on another flower.
All grasses, which means all grains, and most trees wind pollen.
But most species actually use insects to do this, which is in a way smarter because it doesn't require as much pollen.
Insects and other species can carry pollen, transferring it directly to where it is needed.
Obviously, we noticed the relationship between insects and plants.
It's a symbiotic relationship, whether it's a bird or a bee, they get a reward, usually nectar.
Sometimes this symbiotic relationship leads to wonderful adaptations -- the red-dressed hawkmoth is a beautiful adaptation.
Plants also harvested, and Tian'e spread the pollen elsewhere.
Plants have evolved, creating landing strips everywhere where bees can get lost.
Many plants have markings that look like other insects.
These are the pollen sacs of lilies, and it's very clever, so when an unsuspecting insect lands on it, the pollen sac flips over and hits the insect's back with a lot of pollen, so that it can follow the insect to other plants.
There's an orchid that looks like it has jaws, and in a way, it does; it forces insects to crawl over, get pollen, and carry it somewhere else.
Orchids: There are at least 20,000 species of orchids - an amazing variety.
They have all sorts of tricks.
They have to try and attract pollinators to help them through this process.
This orchid, called Darwin's Orchid, because it was studied by Darwin and made a fantastic prediction when he saw this orchid. You can see here there is a long nectar tube hanging from the orchid.
Basically what the insect has to do is -- we come to the middle of the flower -- it sticks its mouthparts into the middle and all the way down to the nectar tube to get the nectar.
Looking at the flower, Darwin said, "I guess something co-evolved with it."
Undoubtedly, insects.
When I mean, it's usually rolled up, but when it's straightened, it looks like this.
Now imagine if something so valuable as nectar was expensive for plants to produce and attracted many pollinators, then, as in human sexuality, people might start cheating on each other.
They might say, "I have some nectar. Would you like to come and get some?"
This is a plant.
This plant is a favorite of South African insects, who have evolved long mouthparts to get the nectar at the bottom.
This is a copycat.
This plant is mimicking the previous plant.
There's a fly with long mouthparts that doesn't get any nectar from the counterfeiter. Because the counterfeiter doesn't give it any nectar. It thinks it can get it.
So not only are the flies not getting nectar from the fake plants, but -- if you look very closely at the top of the head, you'll see some pollen there that's going to be spread to other plants, if no botanist comes along and sticks it on a blue card.
(Laughter) This lie is spread all over the plant kingdom.
This flower with black spots: They may look like black spots to us, but I'm telling you, to a male insect of the right species, this looks like two very, very sexy females.
(Laughter) When the insect arrives and lands on it, it dips itself in the pollen, and of course that pollen will be carried to other plants by it, and if you look at the scanning electron microscope image that every home should have, you can see that there are actually patterns there, three-dimensional patterns.
It even makes insects feel comfortable and look good.
These electron microscope images -- this is an orchid masquerading as an insect -- you can see to our eyes that different parts of the structure have different colors and different textures, and insects might perceive very, very different textures.
This orchid has evolved to mimic the metallic sheen seen on some beetles.
You can see this surface under a scanning electron microscope -- it's very different from other surfaces we've seen.
Sometimes the whole plant mimics an insect, even to us.
I mean, I think it looks like some kind of flying animal or beast.
It's a wonderful and magical thing.
That's where it's clever. It's called obsidian.
I think it can be tricky at times.
For a bee of the right kind, this looks like another very aggressive bee, and it will fly over and hit it with its head many, many times, trying to drive it away, which of course will get it pollen.
Another thing it does is that the plant mimics another orchid rich in insect-loving food.
But there is nothing.
So it's cheating on two levels -- unbelievable.
(Laughter) What we're looking at is ylang-ylang, the fragrant part.
I've actually smelled it before.
The flowers don't actually have to be so showy.
They give off a wonderful scent that attracts any interested insect.
The flower doesn't smell very good.
This flower actually smells really bad. Again, this is evolution, and it looks like carrion.
So flies like it.
Flies fly in and pollinate them.
This is the white star calla lily, also known as the dead horse calla lily.
I don't know what a dead horse smells like, but this flower probably smells very much like it.
It's horrible.
The green-headed fly couldn't help it.
Fly into it, fly all the way into it.
Laying eggs on it, thinking it's a nice piece of carrion, not realizing that there's no food for the eggs here, the eggs will die here, but at the same time the plant will benefit because the bristles are loosened and the flies disappear and pollinate another flower -- it's amazing.
This is the calla lily plant, Alocasia japonica, variegated aroma, called trillium in this country.
I shot this in Dorset last week.
This guy heats up to about 15 degrees above the ambient temperature -- unbelievable.
If you look inside, there's something kind of a dam behind the spikes, and the flies are attracted to the heat -- it's a boiling volatile chemical, bugs -- and they're trapped under this container.
They drank the sweet nectar and they all got a little slimy.
They're covered in pollen at night, sprayed down from them, and then the bristles we see on top of them wilt and allow these pollen-covered bugs to escape -- unbelievable.
If you think it's unbelievable, this one is my favorite.
This is Spring Feather Philodendron.
Anyone here from Brazil should know this plant.
This is the most amazing thing.
Its stamens are about a foot long.
It has an ability that, as far as I know, no other plant has, when it's in full bloom -- this is the ear in the middle -- for about two days, it produces some sort of metabolic change that's kind of mammal-like.
It doesn't have starch, it's plant food, it has something very similar to brown fat to burn it at the rate of fat burning, metabolize it, about the speed of a kitten.
Double the energy output of a hummingbird by weight - absolutely amazing.
It also did something unusual.
Not only will it heat up to 155 degrees Fahrenheit, 43 or 44 degrees Celsius for two days, but it will remain constant.
There is a thermoregulation mechanism for maintaining a constant temperature.
Why do this? I hear you ask.
What you don't know yet is that some beetles like to mate at this temperature.
They burrow in, covered with pollen.
(Laughter) Plants dust them with pollen, let them go, and pollinate them.
What a wonderful thing this is.
Now we think that most pollinators are insects, but in the tropics, many birds and butterflies also pollinate.
Many tropical flowers are red, and that's because butterflies and birds are like us, and we think, can see red very well.
But if you look at the spectrum, birds and us, we see red, green and blue and see this spectrum.
Insects see green, blue, and ultraviolet, and they can see all shades of ultraviolet.
There's also some color behind this.
"Wouldn't it be nice if we could see those colors," I hear you ask.
Yes, we can see it.
So what do insects see?
Last week I took pictures of these desert rosettes, Heliotrope, in Dorset.
As we can see, these are little yellow flowers, and these little yellow flowers are everywhere.
It looks like this in visible light.
This is what it looks like if you remove the red.
Most bees cannot perceive red.
Then I put a UV filter in front of my lens and took a long exposure at a specific frequency of UV, and I got this photo.
It's like a real fantastic bull's-eye.
Now we don't know what the bees are seeing, and you know what I'm looking at when I call it red.
We have no way of knowing what's going on in it, whether it's in the brains of insects or other humans.
But the contrast looks presumably like this. Stands out from the background.
This is another small flower -- in a different UV frequency range, with different filters to match different pollinators.
It looks something like this.
Lest you think that all yellow flowers have this property -- no damage to the flower during the shoot; just stick it on a tripod, not plucked -- under UV light, look at this.
This can be used as the basis for sunscreen, since sunscreen works by absorbing UV light.
So maybe the chemicals in it have some use.
In the end, this is a nocturnal bouquet sent to me by Bjorn Rorslett in Norway -- a wonderful hidden pattern.
I like this hidden way.
I think it's very poetic. These pictures were taken with an ultraviolet filter, and the main use of this filter is that astronomers use to photograph Venus -- actually the clouds on Venus.
This is the main purpose of this filter.
Of course, Venus is the god of love and fertility, and this is the story of flowers.
Just as flowers spend so much effort trying to attract pollinators to accept their invitation, somehow they also succeed in convincing us that there is so much content in them. We send flowers to each other at birth and death, and especially at weddings, when you think about it, it's the moment when genetic material migrates from one organism to another.
Thank you very much.
(applause)
