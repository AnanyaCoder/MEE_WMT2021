I am committed to helping computers communicate with the world around us.
There are many ways to do this, but I like to focus on helping computers to talk about what they see and understand.
Given this scenario, a modern computer vision algorithm can tell you that there's a woman, and there's a dog.
It can tell you that the woman is smiling.
It could even tell you that the dog is very cute.
I deal with this problem of thinking about how humans understand and live with the world.
The thoughts, memories and stories that might be evoked in a scene like this.
The interconnectedness of all connected situations.
Maybe you've seen a dog like this before, or you've spent time running on a beach like this, and it further evokes memories and thoughts of past vacations, past trips to the beach, time spent running around with other dogs.
One of my guiding principles is that by helping the computer understand what this experience is like, and thus understand what we believe and feel in common, then we have the ability to begin to evolve the computer technology in a way that complements our experience.
So, digging deeper into that, I started working a few years ago on helping computers produce human-like stories, from image sequences.
So, one day, I was working with the computer and asked it what it thought about a trip to Australia.
It looked at the picture and saw a wombat.
It didn't know what a wombat was, but the computer said it thought the wombat looked like an interesting creature.
Then I shared with the computer a series of images of houses burning down.
The computer looked at the images and it said, "That's an amazing view! It's spectacular!"
It sends chills down my spine.
The computer saw a horrific, life-changing and life-destroying event and saw it as something positive.
I realized that the computer recognized the contrast between red and yellow and thought it was something positive.
Part of the reason for that is because most of what I put into the computer are positive images.
That's because when people talk about their experiences, they tend to share positive images.
When was the last time you saw a selfie at a funeral?
I realized that in improving AI, it's task to task, dataset to dataset, creating huge gaps, flaws and blind spots in the computer's understanding.
In doing so, I was coding for biases of all kinds.
Biases reflect a limited viewpoint, derived from a dataset - which reflects the same human, such as stereotypes and stereotypes.
I think back to the development of the technology that got me to where I was that day - the first color image was calibrated for a white woman's skin color, which meant that color photography was biased against black faces.
And that same bias, that blind spot, continued into the '90s.
The same blind spot is still present even today in the application of facial recognition technology, how to recognize the faces of different people.
In today's research, it occurs to me that the most advanced technologies tend to limit our ideas to one data set and one problem.
And in doing so, we are creating more blind spots and biases that will be further magnified when using AI.
It was then that I realized we had to think deeply about how our inventions and technologies today would be perceived five to ten years from now.
In the interaction between humans and their environment, humans take time to correct problems, so evolution is slow.
Artificial intelligence, by contrast, is evolving at an incredible rate.
That means it's really important, and we need to think carefully about that now -- reflect on our own blind spots, and biases, and consider how those biases affect the technology that we're creating now, and talk about what the technology of today means for the future.
CEOs and scientists, have weighed in with their thoughts about the future of AI development.
Stephen Hawking warns that "artificial intelligence will extinguish the human race."
Elon Musk warns that this is an existential risk, and one of the greatest risks we face as a civilized society.
Bill Gates noted: "I don't see why people aren't more worried about artificial intelligence.
But these points - they're only part of the story.
The math, the models, the basic components of AI, are available and accessible to us all.
We have source code tools that are open to the public to learn about machines and make our own contributions at the same time.
In addition to that, we can share our experience.
We can share what we love about technology and how it relates to us, and how it makes us excited.
We can talk about the things we love.
We can communicate about the foreseeable future, about what might be more beneficial in terms of technology, or what might be more problematic as time goes on.
If we all focus on opening up the discussion about AI going forward, it will help create a regular conversation and awareness about what AI is and what it can be. What can it be? and all the things we need to do to achieve the best results for us.
We already see and understand this in the technology we use today.
We use smartphones, digital assistants and automatic vacuum cleaners.
Are they evil?
Maybe sometimes.
Are they beneficial?
Yes, they are, too.
They're not all the same.
There you have seen the light of the future.
The future will continue to start with what we build and create now.
We start the domino effect, which unveils the evolution of artificial intelligence
in our time, shaping the AI of tomorrow.
Technology that allows us to immerse ourselves in augmented reality, resurrecting the world of the past.
When people have trouble communicating, technology helps them share their experiences with each other.
Technology built on online visual media that can be used in cars that drive themselves.
Technology that generates language based on the understanding of images can evolve into technology that assists the visually impaired to help them better navigate the visual world.
We also see how technology can lead to some problems.
We have technology today that analyzes the physical characteristics of our birth - like the color of our skin or the expression on our face to determine if we're a criminal or a terrorist.
We have the technology to process data, to process data about gender or race to determine whether we can get a loan or not.
Everything we see now is just a snapshot of the evolution of artificial intelligence.
Because where we are now is a moment in the evolution.
That means that what we do now will affect how things evolve down the road, and into the world of tomorrow.
If we want AI to assist in the evolution of the human way, we need to define a strategy and a goal, and open that path right now.
I want to see a direction of development that is appropriate to human culture and environment.
Technology can help us heal people with neurological or other disabilities and make life as challenging for them as it is for everyone else.
Technology works without taking into account your features or the color of your skin.
My focus today is on the technology of tomorrow and ten years from now.
Artificial intelligence can come in many different ways.
But in this case, it's not a driverless car without any destination.
It's a car that we can drive and control at the same time.
We choose when to accelerate and when to decelerate.
We choose whether or not we need to make a turn.
We choose what the future of artificial intelligence will be.
There will be a vast arena. Allowing for all the things that AI can be.
It's going to become a lot of different things.
Now it's up to us to figure out what we need to implement to make sure that the outcome of AI is going to be better for all humans.
Thank you.
(Applause)
I hope you will take a moment to consider the very simple fact that by far most of what we know about the universe comes from light.
We stand on Earth and look up at the night sky and we can see the stars with our naked eyes.
The intense sunlight is so blinding that
we can see the light reflected back from the moon.
Since Galileo aimed his humble telescope at the celestial bodies in the universe, the universe as we know it today has been presented to us through light.
With the help of modern astronomical telescopes, we have been able to collect dazzling, silent images of the universe - a series of images going all the way back to the Big Bang.
But the universe is not a pantomime, because it is not really silent.
I want to tell you that the universe has its own soundtrack, and that the universe itself is playing constantly. Because space can vibrate like a drum.
So when something big happens, it can send a series of sounds out into the universe.
Now, we want to put a soundtrack to this magnificent visual work about the universe.
Although we've never heard a sound from outer space, we should be able to turn up the volume and hear what's going on there in the next few years.
With the ambitious goal of capturing the sound of the universe, we're focusing on black holes and the prospect of what they can do, because black holes can hit space-time like drumsticks hitting a drum and make a very special sound, and I'm very happy to show you some of the sounds that we're predicting.
It's possible that someday in the future we'll be able to see a shadow that a black hole can make on a very bright background, but it hasn't been observed yet.
Although black holes can't be seen, they can be heard, because they hit space-time like a drum.
The idea that the universe could make a drum-like sound came from Albert Einstein, and in fact many of our ideas came from him.
Einstein realized that if the universe was empty, if the universe was empty, it would look like this picture, except for the auxiliary lines that are drawn on it.
But if we were in free fall in the universe, even without those auxiliary lines, our trajectory would draw those lines, because we would find ourselves moving in a straight line, a straight line through the universe without bending.
Einstein also realized - and this is really the key part (matter also means "matter") - that if you put energy and matter in the universe, the universe will bend. A free-falling object passing through a celestial body like the sun will be deflected and follow a path that is bent in space.
This is Einstein's great theory of general relativity.
Even the path of light can be bent.
And when the bend is large enough, it will orbit the sun, just like the earth orbits the sun and the moon orbits the earth.
This is the natural curve of the universe.
But Einstein didn't realize that if you take the sun and compress it into a ball 6 kilometers in diameter - that is, if you take matter that is a million times the mass of the Earth and compress it into a ball 6 kilometers in diameter - you will create a black hole, an object so dense that if light gets too close to it, it won't be able to escape - leaving a huge black shadow in the universe. A giant black shadow.
But Einstein always thought that a black hole was just a mathematical singularity.
He didn't believe in the existence of black holes.
He believed that nature would prevent the formation of black holes to protect us.
It took decades before people started using the term "black hole" and realized that black holes are real objects - in fact, they are the dead states of extremely massive stars that collapse catastrophically at the end of their lives.
Our sun does not collapse to form a black hole.
It's not really massive enough.
But if we did some thought experiments - and Einstein was very fond of this - we could hypothetically crush the sun and compress it to within six kilometers, and then put a tiny Earth in orbit around it, say 30 kilometers away from the black hole sun.
The Earth would glow by itself, because now the Sun is gone and we have no other source of light - so our little Earth would have to glow by itself.
You'll find that you can even put the Earth in orbit 30 kilometers away from the black hole and have it happily orbiting.
This black hole is actually only about the size of Manhattan.
It could expand to Hudson Street before it destroys the Earth.
But basically that's what we're talking about.
We're talking about an object that's compressed to about half the size of Manhattan.
So we move this Earth close to the black hole - 30 kilometers - and we notice that it's following a perfect orbit around the black hole.
There are rumors that the black hole will swallow everything in the universe, but you actually have to be very close to it to actually fall in.
But what's impressive is that from our perspective, we can always see the Earth.
It can't hide behind a black hole.
The light from the Earth, part of it falls into the black hole, but some of it is bent by the black hole and then we see it.
So you can't hide anything behind a black hole.
If this is an episode of Battlestar Galactica and you're fighting Cylons, don't hide behind a black hole.
They can see you.
Our sun doesn't collapse into a black hole; it's not massive enough, but there are tens of thousands of black holes in our galaxy.
If one of them is swallowing the galaxy, it will look like this.
We'd see the shadow of a black hole cast over hundreds of billions of stars in our galaxy and the dust belt lit by the stars.
If we were to fall into this black hole, we would see the light being refracted around the black hole, and we wouldn't even begin to enter the shadow without feeling some huge change taking place.
If we try to start a rocket and get out of there, it's not going to work out very well, because we can't escape, not even from the light.
Although a black hole looks dark from the outside, it doesn't look that way from the inside, because all the light from the galaxies can fall into the black hole with us.
And even so, because of the relativistic time dilation effect, our clocks seem to be slowing down compared to galactic time, and it looks as if the galaxies outside are changing faster, just before we ourselves are destroyed by the black hole.
It's like a near-death experience, where you see the light at the end of the tunnel, but it's a full-on death experience.
(laughter) There's no way you can tell anybody that you saw the light at the end of the tunnel.
So far, we've never seen such a shadow left by a black hole, but black holes can be heard, even if they can't be seen.
Imagine in a real astronomical scenario - imagine two black holes that have existed together for a long time.
Maybe they used to be stars and then collapsed into two black holes - each with 10 times the mass of the Sun.
Now we have them compressed to within 60 kilometers.
They can rotate hundreds of times a second.
At the end of their lives, they're approaching each other at the speed of light.
In a fraction of a second, they can travel thousands of kilometers. In the process, they not only bend space, but also create vibrations in the wake behind them, a real space-time wave.
Black holes squeeze and stretch space as they collide with the universe.
These vibrations travel through space at the speed of light.
This computer simulation was done by NASA Goddard's relativity group.
It took nearly 30 years to solve this problem.
This is one of many groups.
It shows two black holes spinning around each other, and these are imaginary curves.
As you can see - and it may be a little blurry - you can see waves being emitted by the red, and these are gravitational waves.
They're real cosmic sounds that will travel outward from these black holes at the speed of light as they merge with each other, until the two black holes merge into one quietly spinning black hole.
If you stand close enough, your ears will resonate with the squeezing and stretching of space.
You can really hear these sounds for yourself.
Of course, you will helplessly find your head squeezed and stretched too, so you may not be able to understand what's going on.
But I'd like to play for you the sounds we predicted.
Here's what my group came up with - a relatively abbreviated computational model.
Imagine a small-mass black hole falling into a larger-mass black hole.
The sound you hear comes from the collision of the small-mass black hole with space as it approaches the massive black hole.
If they are very far away, the sound will be very small.
But gradually the sound becomes like a drumstick beating against space, making space vibrate like a drum.
We can predict what this sound will become.
We know that during the fall, the small black hole will get faster and faster and make a louder sound.
Eventually, we'll hear the small black hole fall completely into the big black hole.
I never thought it was that loud - it's actually amplified here.
When I listen to it at home, I think it's a little underpowered.
It sounded like, ding, ding, ding.
This is another sound that our research team simulated.
I'm not going to show you images here, because black holes don't leave any useful traces, and real space doesn't show you those virtual curves.
But if you hear this sound while you're on vacation in the universe, I suggest you run.
(laughs) Better get away from that sound.
Both of these black holes are moving.
Both black holes are moving closer to each other.
In this case, they're both shaking violently.
And then they will merge into one.
That sharp sound is a sign that the black holes are fusing - a sharp sound at the end of the fusion.
This is our prediction of what we will see.
Fortunately, we are very safe in Long Beach, California.
There's no doubt that somewhere in the universe two black holes have merged together.
There's also no doubt that the space around us can feel these vibrations that travel a million light years, or from a million years ago, that travel at the speed of light and eventually meet up with us.
But these sounds are so small that we can't even hear them.
There are some experiments in the world that would take a lot of effort to set up - one of them is called LIGO - that would be able to detect vibrations in space that are smaller than the range of an atomic nucleus every four kilometers.
This is a very bold attempt, and its sensitivity will not be surpassed for years to come - it will be used to detect vibrations in space.
Another research project on the universe, which is expected to start within the next decade, is called LISA.
LISA will be able to see supermassive black holes - those with masses millions or even billions of times that of the Sun.
In images from the Hubble Telescope, we see these two galaxies.
It looks like they're hugging each other in a stationary embrace.
They may each have a massive super black hole at their center.
But they're not standing still, they're actually merging.
These two black holes will collide, and their fusion will take billions of years.
So collecting the sound they make is beyond the limits of our human perception.
But LISA can see the final stage of the fusion of two supermassive black holes that started long ago, 15 minutes before they merge.
This detection is not limited to black holes, but can be used to detect any large disturbance in the universe - the largest of which is the "Big Bang".
When the term was coined, some people mocked it by saying - "Oh, who believes in the Big Bang?"
This short animation by my friends at Proton Studios shows what the Big Bang looks like from the outside.
We would never really want to do that; we want to be on the inside of the universe, because there is no such thing as being outside the universe.
So, imagine you're in the Big Bang.
The universe is everywhere, everything in the world is around you, space is oscillating in a disorderly fashion.
Fourteen billion years have passed, and the sound is still with us.
Galaxies are forming, and stars are forming in galaxies, one by one. On some planet, there is at least one such planet, fit for life.
Here we are frantically building experiments, doing calculations, writing computer code.
Imagine that a billion years ago, two black holes collided.
The sound has been traveling through time and space all this time.
We're not even here.
It's getting closer and closer - 40,000 years ago, we were drawing on the stone walls of a cave.
If the sound we're trying to capture was from the Big Bang, it would sound something like this.
Technically speaking, it's noise.
It's a white noise, a chaotic ringing.
But it's everywhere around us, as long as it's not canceled out by some other process in the universe.
If we could detect these sounds, it would be like music to our ears, because the quiet echoes come from the moment we were created, from the universe we look up at.
So in the next few years, we'll be able to turn up the volume of these soundtracks a little bit and let the universe come to us in audio form.
But if we can detect those earliest moments, it will also take us a step closer to understanding the Big Bang, and allow us to ask some of the most difficult, and at the same time, elusive questions.
If we play the history of the universe backwards, we can know that there was a big bang, we can even hear its noisy sound, but is our big bang the only big bang in the universe?
I mean we can't help but ask, has there been a similar big bang before that?
Will it happen again in the future?
I would say that if we take this question to the level that TED is advocating to provoke people to rethink, at least in this last minute, we can ask some questions that we really may never be able to answer.
But we can't help but ask: Could our universe be just an episode in a larger history?
Or could we be just one branch of a multiverse - each having experienced its own big bang - maybe some of them with buzzing black holes, maybe some without - maybe some with conscious life, maybe some without - They don't belong to our past, they don't exist in our future, but are somehow connected to us?
So we can't help but wonder, if there is a multiverse, does life exist in other branches of that multiverse?
This is life in our multiverse.
Are there other beings in the multiverse, and could they be speculating about our existence and contemplating their own origins?
If so, I can imagine them doing the same calculations we do, writing computer code, building experimental instruments, trying to detect the faint sounds from their origins, and wondering who else is out there.
Thank you. Thank you, everybody.
(Applause)
One winter morning a few years ago in Johannesburg, South Africa, I was driving to work and found the city shrouded in fog.
I drive through there almost every day, but this was unusual, I had never seen anything like it before.
Johannesburg is known for its distinctive and beautiful skyline, but that morning it was barely visible.
I soon realized that what I was seeing was a severe haze caused by air pollution.
The contrast between the beautiful environment I had known in the old days and the hazy skyline at the moment was swirling in my mind.
I feared that there was a good chance that the once colorful sunset would be swallowed up by the gloomy haze.
In that moment, I felt a strong urge to do something about it, but I didn't know what to do.
All I knew was that I couldn't just stand by and watch.
The biggest challenge was that I didn't know anything about environmental science. Air quality management, or atmospheric chemistry.
I'm a computer engineer, and I'm pretty sure I can't code my way out of the air pollution problem.
(laughter) In what capacity will I solve this problem?
I was just a city boy.
Over the next few years, I learned an important lesson that we should all take to heart if we want to achieve a better future.
Even if you are not an expert in a particular field, your expertise may contain a solution to a problem in that field.
Sometimes the unique perspective you hold can inspire unconventional thinking that can shape the situation, but you need to be bold enough to try.
Only then will you be able to know the outcome.
What I knew at the time was that if I wanted to try to make a difference, I had to know enough about pollution to do it, so I went back to being a student.
I did some basic research and quickly learned that air pollution is the biggest environmental health risk in the world.
According to the World Health Organization, in 2012, almost 14 percent of all deaths worldwide were caused by air pollution in and around homes, especially in low- and middle-income countries.
The annual mortality rate from air pollution is higher than that from malaria and AIDS.
In Africa, premature deaths from unsafe sanitation or child malnutrition pale in comparison to the economic costs of air pollution: according to the Organization for Economic Cooperation and Development, the cost exceeded $400 billion in 2013.
In my work, I explore the technological frontiers of artificial intelligence, including the symbiotic relationship between humans and machines, to find useful grounding and help us make better decisions.
When I think about air pollution again, it becomes clear that we need to find better ways to make better decisions, and given the magnitude of the problem, collaboration is essential.
So I decided to get to know some of the people working in this area.
I started talking to officials in Johannesburg and other surrounding cities, I joined the local scientific community, and I made some phone calls to people who were completely new but relevant.
The experiences I had in getting involved helped me to understand the issue more deeply.
It also helped me avoid the trap that people in my line of work sometimes fall into when trying to innovate: quickly adopting a technology before really grasping the problem.
I started to think, what can I do to improve the situation?
I started asking myself how I could effectively blend my knowledge skills in software engineering and artificial intelligence with the expertise of the people I was connecting with.
I wanted to create an online air quality management platform that would reveal future pollution trends and make predictions about what might happen.
I'm sure my idea can be a realistic solution, but there is uncertainty and I can't guarantee its success.
All I have is a specific set of engineer skills, skills that I've acquired from my work. (laughter) Of course, my skills are new to someone who has been working in the field of air pollution for many years.
I've come to realize that sometimes a fresh perspective, a new skill set, can lead to something remarkable.
Our willpower and imagination are a light that guides us past obstacles and into new chapters.
I took a deeper look at the air pollution problem, looking at air pollution data from the last decade or so, as well as meteorological data from Johannesburg and its surroundings. I then worked with colleagues in South Africa and China to create an air quality resolution support system and upload it to the cloud.
This software analyzes historical and real-time data to reveal trends in pollution over time and space.
We then used new machine learning techniques to predict future pollution days in advance.
This means that residents can make better decisions about their daily schedules and where to settle with their families.
We can predict adverse pollution events in advance and define sources of heavy pollution so that the relevant authorities can give orders to adjust their operations.
By supporting scenario planning, urban planners can also make better decisions about how to expand their infrastructure efforts, such as the placement of housing in industrial areas.
We have set up a pilot of this technology, which ran for 120 days, covering the whole of South Africa.
Our expected results have been validated. The predictive data we showed correlated closely with the data we collected in the field.
Through our management, we introduced a world-leading, cutting-edge instrument to predict atmospheric quality with unprecedented resolution and accuracy, benefiting the city I drove into on a winter morning not long ago. And I said to myself, "Something's not right, and I've got to do something about it."
So, the point is, what if I hadn't researched the issue of air pollution in depth?
What if I hadn't been concerned about the state of the environment in the country and had looked to some place, some other person, to take care of it?
What I learned is that when pushing a cause that we all believe in, it's important to look at the possibility of success and consider the consequences of inaction.
We shouldn't be distracted by opposition and resistance, it should inspire us to go further.
So wherever you are in the world, the next time you find that your natural curiosity has been piqued and it's about something you care about, and you have some crazy or brave idea, even if it's not in your area of expertise, ask yourself: Why not give it a try?
Why not go ahead and solve the problem? Do your best, in your own way?
You might get a surprise.
Thank you, everyone.
(Applause)
Many people believe that driving is something that only those who can see can do.
A blind person trying to drive a car alone and safely has been considered an impossible task until now.
Hello, my name is Dennis Hong, and we have created a car designed for the freedom and independence of blind people with visual impairment problems.
Before I tell you about this car for the blind, let me tell you briefly about another project I worked on called the U.S. Defense Advanced Research Projects Agency Urban Challenge.
It was about building a mechanical car that could drive itself.
You press the start button, you don't touch anything, and it gets to its destination completely automatically.
At the 2007 challenge, our team won $500,000 and placed third in the competition.
Around that time, the National Federation of the Blind, or NFB, challenged the design team to come up with a car that would allow blind people to drive independently and safely.
We thought we'd give it a try, because we thought, hey, how hard could this be?
We already have a car that's autonomous.
All we have to do is let the blind person drive in it, and that's it, right?
(laughter) But we were wrong.
What the Association for the Blind wanted was not a car that could drive a blind person around, but a car that a blind person could make choices and drive.
So we had to give up everything we had and start from scratch.
To test this crazy idea, we designed a prototype of a small sand buggy to test its feasibility.
In the summer of 2009, we invited a lot of blind youth from all over the country and gave them a chance to take the car for a spin.
It was definitely a cool experience.
But the problem with the car was that it was designed to be driven by blind people in a very limited environment, like a closed parking lot - even on a path made of red traffic cones.
So with this success, we decided to take the next important step and build a real car that could drive on a real road.
And how does it work?
Well, it's a relatively complex system, but let me explain it and simplify it a little bit.
We have three phases.
We have a sensing phase, a computing phase and a non-visual interface.
The driver is obviously invisible, so the system has to be able to sense the surroundings and collect data for the driver.
For this, we use the initial metrology element.
It measures acceleration, angular acceleration - just like the human ear, the inner ear.
I combine that information with GPS to predict where the vehicle is.
We also use two cameras to detect the path of the vehicle.
We also use three laser rangefinders.
The lasers scan the environment to detect obstacles - vehicles coming from the front, from the rear, but also any obstacles that come into the road, any obstacles around the vehicle.
All of the massive amount of information is then aggregated into the computer, and the computer does two things.
The first thing is to process the information to understand the surroundings - what is the path of travel, what are the obstacles - and translate that information to the driver.
The system is also very intelligent and can figure out the safest path to take.
We can also give instructions on how to operate the vehicle's operating program.
But the question is: How do we get the information and instructions to the blind person fast enough and accurately enough to ensure that he or she can drive?
To do this, we have designed a variety of different non-visual user interface technologies.
The first 3-D flat sound systems, vibrating undershirts, voice-activated gears, leg straps, and even shoes that apply pressure to the feet.
But today we're talking about three of these non-visual user interface technologies.
The first interface is called a driving grip.
It's a pair of gloves that have vibration elements in the knuckles so that you can transmit instructions on how to drive - direction and amplitude.
The other device is called a speed vibration belt.
This car seat - actually, it's a massage chair.
We took it out and we reconfigured the vibration elements in different modes. We have them transmitting speed information, but also instructions on how to use the throttle and the brakes.
Here, you can see how the computer understands the surroundings. Because you can't see the vibrations, we actually put red light-emitting diodes on the driver so he can see what's going on.
This is sensed data, and this data is transmitted from the sensors to the computer.
So these two devices, the driver's grip and the speed vibration belt, are very effective.
But the problem is that these are command cue devices.
So it's not really free, right?
The computer tells you how to drive-- turn left, turn right, accelerate, brake.
I call this the co-pilot problem.
So we're avoiding the command cue device and focusing more on the information device.
A typical example of this non-visual information interface is called a null diagram.
Think of this as a monitor for the blind.
It's a little desktop with a lot of holes in it, from which compressed air is removed, so that it can be described as a picture.
So even if you're blind and you put your hand on it, you can sense paths and obstacles.
In fact, you can also change the frequency and possibly the temperature of the air that's being released.
This is actually a multi-dimensional user interface.
Here, you can see the cameras on the left and the right and how the computer parses and transmits that information to the air map.
So, we're showing a simulated program where a blind person is driving with a null map.
This program is very helpful in training blind drivers based on different kinds of non-visual user interfaces and in quickly testing different theories.
That's basically how it works.
But this is a model car, and it's not going to be on the road until it's proven to be as safe to drive as today's cars, or safer, for that matter.
I really believe that's going to happen.
But will society, will they accept this radical idea?
How will we handle insurance?
How will we issue driver's licenses?
There are a lot of different obstacles behind the technical challenges that we need to address before it can really become a reality.
Of course, the main goal of this project is to design a car for the blind.
But potentially more important than that is the enormous value of the by-products of this project.
Sensors that can see through darkness, rain and fog.
And this new kind of interface, we can use these technologies to make them safer vehicles for people who can see.
Or for the blind, everyday household devices - educational facilities, office applications.
Imagine a classroom where the teacher is writing notes on the blackboard and the blind student can use these non-visual interfaces to understand and read what the teacher is writing.
This is extremely valuable.
What I've shown you today is just the beginning.
Thank you very much.
(Applause)
As an artist, connection is very important to me.
Through my artworks I try to show that human beings are not separated from nature, but that everything is interconnected.
I went to Antarctica for the first time about 10 years ago, and I saw icebergs for the first time.
I was in awe.
My heart was pounding fast and my head was spinning, trying to understand what was in front of me.
The iceberg around me was almost 200 feet out of the water. I could only wonder that this was one snowflake covered by another snowflake, formed year after year.
Icebergs form when they break off from a glacier or break off from an ice shelf.
Each iceberg has its own unique personality.
They interact with their surroundings and their conditions in a distinctive way.
Some icebergs refuse to compromise and stay the course, while others can't stand to have their ice break up in the heat of the moment.
When you look at icebergs, it's easy to think of them as isolated, as separate, as one, more like the way we humans sometimes think of ourselves.
But the reality is much more than that.
As the iceberg melts, I breathe in its ancient scent.
As the iceberg melts, it releases the mineral-rich fresh water that nourishes everything.
I set out to photograph these icebergs as if I were taking portraits of my ancestors, knowing that in these individual moments the icebergs were there in that way but will never be there again.
When they melt, it's never death; it's never an end, it's a continuation of the path to life.
Some of the icebergs I've photographed, some of the ice is very young - a few thousand years old.
Some of the ice is over 100,000 years old.
The last image I want to show you is an iceberg that I photographed on Kekertsuatsiak, Greenland.
This is a very rare opportunity for people to actually get to witness an iceberg roll over.
So this is shown in the picture.
On the left you can see a small boat.
It's a boat of about 15 feet.
I want you to notice the shape of the iceberg as it deforms on the water.
And here you see it start to roll over, and the boat moves to the other side, and a man is standing there.
This is an average size Greenland iceberg.
It's surfaced about 120 feet high or 40 meters high.
This video was shot in real time.
(MUSIC) Like the iceberg, they show different aspects of their personality.
Thank you.
(Applause)
Do you know how many flowering plants there are?
There are 250,000 species -- at least that many that we know of -- 250,000 medium flowering plants.
And flowers are a pain in the ass.
It's really hard to get plants to reproduce.
It takes a lot of experience and a lot of resources.
Why is it so troubling?
The answer, of course, is that, like many other things in the world, gender.
I know what's going through your minds when you look at these pictures.
The reason that sexual reproduction is so important -- there are many other ways that plants can reproduce.
They can be propagated by plugging; they can be propagated by both sexes on the same plant; they can be pollinated on the same plant.
But they do need to spread their genes and mix them with other genes so that they can be ecologically viable.
That's how evolution works.
Now the way that plants transmit this information is through pollen.
Some of you may have seen these pictures before.
As I said, every home should have a scanning electron microscope that can see this.
There are as many different types of pollen as there are flowering plants.
This is actually quite useful for forensics and so on.
Most of the pollen that causes us to get hay fever comes from plants that use the wind to spread pollen. It's a very inefficient process, and that's why pollen keeps getting up our noses.
Because most of it is discarded in the hope that the germ cells, the male germ cells, that are contained in the pollen, will happen to land on another flower.
All grasses, which means all grains, and most trees rely on the wind to spread pollen.
But most species actually use insects to do this process. In some ways this is smarter, because it doesn't take much pollen.
Insects and other species can carry pollen and transfer it directly to where it's needed.
Obviously, we're noticing a relationship between insects and plants.
It's a symbiotic relationship, whether it's a bird or a bee, they both get something in return, usually in the form of nectar.
Sometimes this symbiosis leads to wonderful adaptations - the red skirt moth is a beautiful adaptation.
The plant also reaps the rewards, as the moth spreads its pollen elsewhere.
Plants have evolved to create landing strips everywhere, and bees can get lost in them.
On many plants there are markings that look like other insects.
These are the pollen sacs of lilies, so clever that when an unsuspecting insect lands on them, the sacs flip over and hit the insect on the back with so much pollen that they can follow the insect to other plants.
One orchid looks as if it has jaws. In a way, it does; it forces the insect to crawl through, get its hands on the pollen, and take it elsewhere.
Orchids: There are at least 20,000 species of orchids -- a surprising variety.
They have all sorts of tricks up their sleeves.
They must try and attract pollinators to help them through the process.
This orchid, it's called Darwin's orchid because it was studied by Darwin and he made a wonderful prediction when he saw it. You can see here a very long nectar tube hanging down from the orchid.
Basically what the insect has to do is -- we come to the middle of the flower -- it stabs its mouthparts into the middle part all the way down to the nectar tube to get to the nectar.
Darwin said, looking at the flower, "I guess something has co-evolved with it."
Without a doubt, it's insects.
I mean, normally it's all curled up, but when it's straightened out, it looks like this.
Now imagine if nectar, which is such a valuable thing for plants to produce at a high cost and to attract many pollinators, then, as in human sexuality, people might start to cheat each other.
They might say, "I have some nectar. Do you want to come and get some?"
This is a plant.
It's a plant that's popular with the insects of South Africa. They've evolved long mouthparts to get the nectar from the bottom.
This is an imitator.
This plant is imitating a previous plant.
There's a fly with long mouthparts and it doesn't get any nectar from the imitator. Because the impostor didn't give it any nectar. It thought it could get it.
So not only did the fly not get nectar from the counterfeit plant, but also -- if you look very close to the top of the head, you'll see some pollen there that would have been spread to other plants, if no botanist had come and stuck it on a blue card.
(laughter) This lie is all over the plant kingdom.
This flower with the black dots: they may look like black dots to us, but I'm telling you, to the male insect of the right species, these look like two very, very sexy females.
(laughter) When the insect arrives and lands on it, immerses itself in the pollen, which, of course, will be carried by it to other plants, and if you look at the scanning electron microscope images that every household should have, you can see that there's actually some patterns there, three-dimensional patterns.
It even makes the insects feel comfortable, and it looks good.
These electron microscope images -- this is an orchid disguised as an insect -- you can see that to our eyes, different parts of the structure have different colors and different textures, and the insect may be able to perceive very, very different textures.
This orchid has evolved to mimic the shiny metallic surface that you see on some beetles.
You can see this surface under a scanning electron microscope -- it's very different from any other surface we've seen.
Sometimes the whole plant will mimic an insect, even though it looks like an insect to us.
I mean, I think it looks like some kind of flying animal or beast.
It's something wonderful and magical.
That's what's so clever about it. It's called obsidian.
I think it's sometimes cunning.
For the right kind of bee, this looks like another very aggressive bee that will fly over and headbutt it many, many times to try to chase it away, which of course gets it covered in pollen.
The other thing it does is this plant mimics another orchid rich in the insects' favorite food.
But there's really nothing there.
So it's cheating on two levels -- it's incredible.
(laughter) What we're seeing is ylang-ylang, the part that has a strong scent.
I've actually smelled it before.
These flowers don't actually have to be so showy.
They give off a wonderful scent that attracts any insect that's interested.
This flower doesn't smell good.
This flower actually smells very bad. Again, this is evolutionary, it looks like carrion.
So flies like it.
Flies go in and help pollinate it.
This is the white star calla, also known as the dead horse calla.
I don't know what a dead horse smells like, but this flower probably smells a lot like it.
It's just awful.
The green flies couldn't help themselves.
Fly into it, all the way into it.
Laying eggs on it, thinking it's a nice piece of carrion, not realizing that there's no food for the eggs, that they're going to die here, but at the same time the plant benefits because the hairs loosen up and the fly disappears, pollinating another flower -- it's amazing.
This is the calla plant, the euphorbia, the spotted-leaf ajoemum, known in this country as the prolonged grass.
I photographed this in Dorset last week.
This guy heats up about 15 degrees above ambient -- unbelievable.
If you look inside it, behind the fleshy spike is a bit of a dam, and the flies are attracted to the heat -- it's a boiling volatile chemical, and the little bugs -- they're trapped underneath this container.
They drink in the sweet nectar and then they all get a little bit sticky.
At night they're covered in pollen, it sprays down from above them, and then the stiff hairs that we see up there become wilted and allow these little pollen-covered bugs to escape-- it's unbelievable.
If you think that's incredible, this one is my favorite.
It's the spring-feathered cranberry.
Anyone here from Brazil should know about this plant.
It's the most amazing thing.
It's got stamens that are about a foot long.
It has an ability that no other plant that I know of has, when it's in full bloom -- this is the fleshy spike in the middle -- for about two days, it produces some degree of metabolic change somewhat similar to a mammal.
It doesn't possess starch, which is the food of the plant, it possesses something very similar to brown fat at the rate at which it burns fat, burns it, metabolizes it, at about the rate of a small cat.
Twice the energy output of a hummingbird by weight -- absolutely amazing.
It also does something unusual.
Not only will it warm up to 155 degrees Fahrenheit, 43 or 44 degrees Celsius, for two days, but it will maintain a constant temperature.
There's a thermoregulatory mechanism for maintaining constant temperature.
Why do you want to do that? I hear you guys asking.
What you don't know yet is that some beetles like to mate at this temperature.
They burrow in and get covered in pollen.
(laughter) The plant sprinkles pollen all over them and lets them go and pollinate.
It's such a wonderful thing.
Now we think of most pollinators as insects, but actually in the tropics, many birds and butterflies also pollinate.
Many of the flowers in the tropics are red, and that's because butterflies and birds are similar to us, we think, and can see red very well.
But if you look at the spectrum, birds and us, we see red, green and blue and see this spectrum.
Insects see green, blue and ultraviolet, and they can see all kinds of light and dark ultraviolet.
There are some colors behind that.
"Wouldn't it be nice if we could see those colors," I hear you ask.
Yes, we can see.
So what do insects see?
Last week I took pictures of these desert seagrasses, the genus Hemerocallis, in Dorset.
As we can see, these are little yellow flowers, and they're everywhere.
In visible light it looks like this.
If you remove the red color it looks like this.
Most bees can't perceive red.
Then I put a UV filter in front of my lens and exposed it for a long time at a specific frequency of UV light, and I got this picture.
It's like a real, wonderful bull's-eye.
Now we don't know exactly what the bees are seeing, and when I call it red, you know what I'm looking at.
We can't know what's going on in it, whether it's insects, or in other human brains.
But the contrast probably looks like this. It stands out from the background.
This is another little flower -- in a different UV frequency range, different filters to match different pollinators.
It looks roughly like this.
And lest you think that all yellow flowers have this property -- no damage to the flower during the shoot; just stick it on a tripod, not take it off -- in the UV light, look at this.
This could be the basis of a sunscreen, because sunscreen works by absorbing ultraviolet light.
So maybe the chemicals in it are of some use.
And finally, this is a nightshade that was sent to me by Bjorn Rorslett from Norway -- wonderful hiding pattern.
I like the way it's hidden.
I think it's very poetic. These were taken with an ultraviolet filter, which is a filter that's used primarily by astronomers to photograph Venus -- actually the clouds on Venus.
That's the main use of this filter.
Venus, of course, is the god of love and fertility, which is the language of flowers.
Just as flowers spend so much energy trying to attract pollinators to accept their invitation, somehow they've also managed to convince us that there's a richness in the fact that we give each other flowers at birth and at death, especially at weddings, and when you think about it, it's within that moment that genetic material migrates from one organism to another.
Thank you very much.
(Applause)
