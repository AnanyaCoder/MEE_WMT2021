I am committed to helping computers communicate with the world around us.
There are many ways to do this, and I like to focus on assisting computers to talk about what they see and understand.
Given such a scenario, a modern computer vision algorithm that can tell you that there is a woman and a dog.
It can tell you that woman is smiling.
It can even tell you that this dog is very cute.
I deal with this question and think about how humanity understands and coexistence with the world.
Those thoughts, memories, and stories in such scenes may arouse human attention.
Interlinkages of all connected situations.
Maybe you've seen such dogs before, or you've ever spent time running on such a beach and further evoking memories and ideas of past holidays, previously spent time running with other dogs, running around with other dogs.
One of my guiding principles is that by helping computers understand what kind of experience this is, in order to understand what we believe and feel in common, then we have the ability to start developing computer technology in a way that complements our experience.
So digging deeper into this, I started working a few years ago to help computers produce human-like stories from image sequences.
So, one day, when I was working on a computer, asked it about my trip to Australia.
It looked at the picture and saw a tree bag bear.
It doesn't know what a tree Wombat is, but the computer says it thinks the tree Wombat looks very interesting creatures.
Then I shared with the computer a series of images about the house burned down.
The computer looked at the picture, and it said, “This is an amazing landscape! It's spectacular!”
It chills my spine back.
The computer sees a terrible, life-changing and life-destroying event and considers it a positive thing.
I realized that the computer recognized the contrast between red and yellow and thought it was something worthy of positive evaluation.
Part of the reason is because the majority of my input computer are positive images.
That's because people tend to share positive images when they talk about their experiences.
When was the last time you saw a selfie at the funeral?
I realized that in the process of improving AI, it was the task of the task, datasets grouped into datasets, creating huge gaps, flaws and blind spots in the understanding of computers.
While doing this, I'm coding for various biases.
Prejudice reflects a limited view, stems from a data set — which reflects the same human being, such as stereotypes and stereotypes.
I think back on that technological development that brought me to the point where I was that day — the first color image was calibrated for the color of the skin of a white woman, which means color photography deviates from the black face.
And the same deviation, that blind spot continued into the 90s.
Even today, the same blind spots still exist in the application of facial recognition technology, how to identify different people's faces.
In today's research, I think of the most advanced technologies that tend to limit our ideas to one dataset and one problem.
By doing so, we are creating more blind spots and biases that will be amplified further when using artificial intelligence.
And then I realized that we had to reflect on how we invented the creation technology today, five to ten years later.
In the interaction between humans and the environment, humans use time to correct problems, so evolution is slow.
Artificial intelligence, in contrast, is evolving at an incredible rate.
That means it really matters, and we need to think about it now — to reflect on our own blind spots and biases, and how they affect the technology we create now, and discuss today's technology, what it means for the future.
CEOs and scientists, have weighed their thoughts about the future of AI development.
“Artificial intelligence will kill humans,” warned Stephen Hawking.
Elon Musk warned that this is an existent risk and one of the greatest risks we face as a civilized society.
“I don't understand why people are less worried about AI,” says Bill Gates.
But these views — are just a part of the story.
That mathematics, models, the basic components of these artificial intelligence, are what we can all get and use.
We have source code tools that are open to the public to learn machines and make our own contributions at the same time.
In addition to that, we can also share our experience.
We can share the place in terms of technology and its relationship with us, and how we can enliven us.
We can discuss what we love.
We can communicate with the foreseeable future, which may be more beneficial in terms of technology, or more problems may arise over time.
If we are all focused on opening up the discussion on AI to the future, it will help create a regular conversation and awareness about what is AI? What can it be? And all we need to do to achieve the results that best suits us.
We've seen and understood this in the technology used today.
We use smartphones, digital assistants and automatic vacuum cleaners.
Are they evil?
Maybe sometimes.
Are they beneficial?
Yes, they are too.
They are not exactly the same.
There you have seen the light of the future.
The future will continue to start with what we build and create now.
We launched the domino effect, which unveiled the path of evolution of artificial intelligence
In our time, artificial intelligence is shaping tomorrow.
so that we can immerse ourselves in augmented reality, revive the world of the past,
When people have difficulty communicating, technology helps them share each other's experiences.
Technology built on online visual media can be used in autonomous vehicle driving.
Technology generates language based on image understanding and can evolve into technology that helps people with visual impairment to better own the visual world.
We also see how technology is causing some problems.
We have technology today to analyze the physical characteristics of our birth — like the color of our skin or the expression on our faces to determine if we are criminals or terrorists.
We have the technology to process data that processes data about gender or race to determine if we have access to a loan.
Everything we see now, is just a snapshot of the evolution of artificial intelligence.
Because where we are now, it is a moment of evolution.
This means that what we do now will affect the future of things and extend to the world of the future.
If we want artificial intelligence to help humanity to develop, we need to define strategies and goals, and start that path right away.
What I want to see is the direction that suits the culture and the environment.
Technology helps us cure patients with neurological diseases or other disabilities, making life as challenging as everyone.
The operation of technology does not take into account your characteristics or skin color.
My focus today is technology tomorrow and ten years later.
Artificial intelligence can come up in many different ways.
But in this case, it is not a driverless car without any destination.
This is a car that we can drive at the same time.
We choose when to accelerate and when to slow down.
We choose whether we need a turn.
We choose what artificial intelligence will be of the future.
There will be a vast arena. Allow artificial intelligence to be everything.
It turns into a lot of different things.
It's up to us to figure out what needs to be implemented to ensure that the result of artificial intelligence is better for all humans.
Thank you.
(Applause)
I hope you take a moment to think about the very simple fact that, so far, much of our understanding of the universe has come from light.
We stand on Earth looking at the night sky and see the stars in the sky with the naked eye.
Strong sunlight is so dazzling,
We can see the light reflected from the moon,
Ever since Galileo directed his shabby astronomical telescope to the celestial bodies in the universe, and to this day, the universe we know is presented to us through light.
With the help of modern astronomical telescopes, we have been able to collect dazzling, silent images of the universe — a series of images dating back to the Big Bang.
However, the universe is not a mimitation, because the universe is not really silent.
I want to tell you that the universe has its own soundtrack and that the universe itself is playing. Because space can vibrate like drums.
So when something big happens, it can make a series of sounds to the universe.
Today, we want to be able to match this magnificent visual work of the universe with sound.
While we never heard from outer space, we should be able to turn the volume up and hear what's going on there in the next few years.
For the ambitious goal of capturing cosmic sounds, we have focused our focus on black holes and the prospects it presents, because black holes can hit time and space and make very special sounds like drumsticks hit the drum surface, and I am very happy to show you some of the sounds we predicted.
One day in the future, we may see a shadow, a black hole that leaves a shadow on a very bright background, but it has not been observed.
Although black holes are not visible, they are likely to be heard because they hit time and space like drums.
The idea that the universe can make drum-like sounds comes from Albert Einstein, and many of our thoughts come from him.
Einstein realized that if the universe was empty, if the universe was empty, it would look like this photograph, except those of the auxiliary lines painted on it.
But if we are free fall in the universe, even without these guides, our trajectory will draw these lines, because we will find that we move along straight lines, along lines that do not bend through the universe.
Einstein also realized — that's really the most critical part (matter also means “matter”) — that if you put energy and matter into the universe, the universe will bend. Free fall objects will be deflected along bent paths in space as they pass through objects like the sun.
This is Einstein's great generalized relativist theory.
Even the path of light will be bent.
When the bend is large to a certain extent, it turns around the sun's motion, like the earth turns around the sun and the moon turns around the earth.
This is the natural curve in the universe.
But Einstein didn't realize that if you squeeze the sun into a ball of 6 kilometers in diameter — that is, you compress material equivalent to a million times the mass of the planet into a ball of 6 kilometers in diameter, you will make a black hole, and the density of this object is so large that if the light is too close to it, it would be nothing. Law Escape - leaving a huge shadow in the universe,
But Einstein has always thought that black holes are just a mathematical singularity.
He didn't believe that there was a black hole.
He believes nature will prevent the formation of black holes to protect us.
It took decades to use the term “black holes” and realized that black holes were real celestial bodies — in fact, they were the state of death after a catastrophic collapse of some of the stars of great quality at the end of their lives.
Our sun does not collapse into black holes.
Its quality is not large enough.
But if we do some thought experiments — Einstein really likes to do it — we can imagine crushing the sun within six kilometers, and then put a tiny Earth in orbit around it, like, on a orbit 30 kilometers away from the black hole sun.
The Earth will light itself, because now that the sun is gone, we have no other light sources — so our little Earth has to glow itself.
You'll find that you can even put the earth on a track 30 kilometers away from the black hole and let it run around the orbit happy.
This black hole is actually just as big as Manhattan.
Before it destroys the earth, it may swell into Hudson Avenue.
But basically that's what we're talking about.
We're talking about an object that is compressed to half the size of Manhattan.
So we moved the earth closer to the black hole — 30 kilometers — and we noticed that it ran along the perfect track around the black hole.
There are rumors that black holes will devour everything in the universe, but in fact you have to be very close to really fall into it.
But impressively, from our point of view, we always see the Earth.
It can't hide behind the black hole.
A part of the light emitted from the earth falls into a black hole, but another part is bent by the black hole.
So you can't hide anything behind a black hole.
If this is the story in the Galactica space fortress and you are fighting the Syons, don't hide behind the black holes.
They can see you.
Our sun will not collapse into a black hole; it is not large enough, but there are tens of thousands of black holes in our galaxy.
If one of them is devouring the galaxy, it will look like this.
We will see the shadow of a black hole cast on hundreds of billions of stars in the galaxy and dust belts illuminated by stars.
If we fall into this black hole, we'll see light refracted around the black hole, and we don't even feel that some huge changes are occurring quietly when we start entering the shadow.
If we try to start the rocket and get out of there, the result will not be good because we cannot flee, nor even light.
Although black holes look dark from the outside, this is not the case inside, as the light of all galaxies can fall into the black hole with us.
And even so, our clock seems to be slower than the time of the galaxy due to the relativistic time-bloating effect, which looks as if the outer galaxies were accelerating change, just before we were destroyed by black holes.
It's like experiencing the feeling of death, and you see the light at the end of the tunnel, but it's a complete death experience.
(Laughter) There's no way to tell anyone that you see the light at the end of the tunnel.
So far, we have never seen the shadows left by such a black hole, but black holes can be heard even if they can't be seen.
Imagine in a real astronomical scene — imagine two black holes that have been together for a long time.
Perhaps they used to be stars collapsed into two black holes — each 10 times the mass of the sun.
Now we'll compress them to 60 kilometers.
They can be rotated hundreds of times per second.
At the end of life, they approach each other at the speed of light.
You can cross thousands of kilometers in a fraction of a second. In the process, they not only bend the space, but also cause space vibration in the tail stream behind it, a real time and space wave.
Black holes make space squeezed and stretched when they hit the universe.
These vibrations spread in space at the speed of light.
This computer simulation was done by the Relativist Group of National Aeronautics and Space Administration Goddard.
It took almost 30 years to solve this problem.
This is one of many groups.
It shows two black holes that rotate around each other, these are the curves imagined.
And as you can see — maybe some blurry — you can see that the red waves are emitted, and these are gravitational waves.
They are real sounds of the universe, which will spread out from the black holes at the speed of light as they blend together, until the two black holes are integrated into a quietly rotating black hole.
If you stand close enough, your ears will resonate with the squeezing and stretching of these spaces.
You can really hear these sounds in your ears.
Of course, you will helplessly find that your head is also squeezed and stretched, so you may not be able to understand exactly what is going on.
But I would like to play the sound we predicted for you.
This is the result of my group's research - a relatively brief computational model.
Imagine a smaller black hole falling into a larger black hole.
The sound you hear comes from the collision of small mass black holes with space as they approach large black holes.
If they are far away, the sound will be very small.
But the gradual sound becomes like a drumstick beating space, making the space vibrate like a drum.
We can predict what this sound will look like.
We know that small quality black holes get faster and louder in the process of falling.
Ultimately, we will hear the small black hole completely fall into the big black hole.
I never felt that sound so loud — here it's actually amplified.
When listening at home, I feel that this sound is a little less powerful.
Sounds like, Ding, Ding.
This is another sound that we study the group simulates.
I'm not going to show you images here, because black holes leave no useful trail, and the real space will not show you those virtual curves.
But if you hear this when you're on vacation in the universe, I suggest you run quickly.
(Laughter) Better get away from this sound.
Both black holes are moving.
Two black holes are close to each other.
In this case, they are all shaking violently.
They will then blend together.
That sharp sound is the hallmark of black hole fusion — a sharp sound when the fusion ends.
This is what we predict about what we will see.
Fortunately, we are very safe in Long Beach, California.
There is no doubt that somewhere in the universe two black holes have fused together.
It is also unquestionable that the space around us can feel the vibrations that crossed a million light years, or a million years ago, that spread at the speed of light and eventually meet us.
But these voices are too small to hear.
Some experiments in the world take a lot of hard work to build up — one called LIGO — that will detect spatial vibrations at a distance of less than one atomic nucleus every four kilometers.
This is a very bold attempt, its sensitivity will not be overtaken in the coming years - it will be used to detect spatial vibrations.
Another research project on the universe is expected to be launched in the next decade, called LISA.
LISA will be able to see black holes of supermassive mass — black holes that are millions or billions of times the mass of the sun.
From the Hubble Telescope, we see these two galaxies.
Looks like they're still hugging together.
There may be a huge super black hole in their center.
But they are not static, and they are actually converting.
The two black holes will collide, and their fusion will take billions of years.
So collecting their voices is beyond the limits of our human perception.
But LISA can see the final stage of two supermassive black holes that began to blend long ago, that is, 15 minutes before they blends.
This detection is not limited to black holes; it can also be used to detect any big disturbance in the universe — the biggest of which is the Big Bang.
When the word was created, some people mocked — “Oh, who would believe the Big Bang?”
This animated short film with my friend in Proton Studios shows the big bang from the outside.
We would never really want to be true; we want to be inside the universe, because there is no situation outside the universe.
So, imagine you're in the Big Bang.
The universe is everywhere, everything in the world surrounds you, and space swings out of order.
14 billion years have passed, and that voice is still lingering around us.
Galaxy is gradually formed, and a batch of stars form in the galaxy. On one planet, there is at least one such planet, suitable for life.
Here we build experiments frantically, do calculations, write computer code.
Imagine two black holes collided a billion years ago.
This sound has always been in time and space.
We didn't even appear here.
It's getting closer - 40,000 years ago, we still painted on the stone walls of the cave.
If the sound we were going to get was from the Big Bang, it would sound like this.
Strictly speaking, it is noise.
It's a white noise, a chaotic ringtone.
But it's everywhere around us, as long as it is not offset by some other process in the universe.
If we could detect these sounds, it would be like music for our ears, because this quiet echo comes from the moment we were created, from the universe we looked up.
So in the coming years, we're going to be able to turn the volume of these soundtrack a little bit, so that the universe is presented to us in the form of audio.
But if we can detect the earliest moments, it will take us a step further from understanding the Big Bang, allowing us to ask some of the most difficult and at the same time the most elusive questions.
If we play the course of the universe upside down, we can know that there was a big bang in the past, and we can even hear its noisy voice, but is our Big Bang the only big bang in the universe?
I mean, we can't help but ask, have there been a similar explosion before then?
Will it happen again in the future?
I would like to say that if we raise the significance of this question to the level that TED advocates for rethinking, at least in this last minute, we can ask questions that we may not answer forever.
But we can't help but ask: will our universe be just an episode of a larger history?
Or, would we be just a branch of the multiverse — each of them has experienced its own big bang — maybe some of them have buzzing black holes, some not — maybe some of them have conscious lives, maybe some don't — they don't belong to our past and does not exist in our future, but in some way to associate with us?
So we can't help but guess that if there is a pluralistic universe, in other branches of this multidimensional universe, there is life?
This is life in our multidimensional universe.
Are there other lives in the multiverse, and are they also guessing our existence and thinking about their own origins?
If this is the case, I can imagine them doing calculations, writing computer code, building experimental instruments, trying to detect the faint sounds that come from their origins, and wonder who else is there.
Thank you. Thank you all.
(Applause)
A winter morning a few years ago, in Johannesburg, South Africa, I drove to work and found that the city was shrouded by haze.
I drive through there almost every day, but this time is unusual and I've never seen such a scene before.
Johannesburg is known for its distinctive beautiful skyline, but barely seen that morning.
Soon I realized that what I saw was the serious haze caused by air pollution.
The contrast between the beautiful environment I knew old days and the haze of the skyline at the moment surging in my heart.
I fear that it is possible that once colorful sunset scenery will be swallowed by the dark haze.
At that moment, I felt a strong urge to do something, but I didn't know what to do.
All I know is that I can't just stand idly by.
The biggest challenge is that I don't know about environmental science. Air quality management, or atmospheric chemistry.
I'm a computer engineer, and I'm pretty sure I can't rely on coding to solve the air pollution problem.
(Laughter) What will I do to solve this problem?
I'm just an Ichii people.
Over the next few years, I've learned an important lesson that we should all keep in mind if we want to achieve a better future.
Even if you are not an expert in a particular field, your expertise may contain a solution to the problem in that area.
Sometimes, the unique perspective you hold can inspire unconventional thinking to shape the situation, but you need to be bold to try.
Only then can you know the results.
What I knew at the time was that if I wanted to try to change, I had to know enough about pollution first, so I was back as a student.
I did some basic research and quickly learned that air pollution is the biggest environmental health risk in the world.
According to the World Health Organization (WHO), almost 14% of deaths worldwide were caused by atmospheric pollution in households and surrounding areas in 2012, especially in low- and middle-income countries.
Air pollution causes higher annual mortality than malaria and AIDS.
In Africa, premature deaths due to unsafe sanitation, or child malnutrition, are pale in the face of atmospheric pollution, and it also carries enormous economic costs: according to the Organization for Economic Cooperation and Development, spending exceeded $400 billion in 2013.
In my work, I explore the technological frontiers of artificial intelligence, including the symbiotic relationship between humans and machines, to find useful foothold and help us make better decisions.
When I think again about atmospheric pollution, things become clear about how to deal with it, and we need to find better ways to make better decisions, given the magnitude of the problem, and synergy is necessary.
So I decided to meet some of the people who work in this field.
I started a conversation with officials in Johannesburg and other surrounding cities, and I joined the local scientific community, and I made some calls to completely strange but relevant people.
These experiences I started to intervene helped me to understand the issue more deeply.
It also helped me avoid the trap that people in my line sometimes fall into when trying to innovate: quickly adopt a technology before they really grasp the problem.
I started thinking, what can I do to improve this situation?
I started asking myself how to effectively integrate my knowledge and skills in software engineering and artificial intelligence with the expertise of the people I contact.
I want to create an online air quality management platform to reveal future pollution trends and make relevant predictions to determine what can happen.
I am sure that my idea can be a realistic solution, but also faced with uncertainty, and I cannot guarantee that it will succeed.
All I have is a specific set of engineer skills, skills acquired from my job. (Laughter) Of course, for those who have been working in the field of atmospheric pollution for years, my skills are entirely new.
I've come to realize that sometimes a novel perspective, a new skill set can spawns something great.
Our willpower and imagination is an indicator that instructs us to cross obstacles and open a new chapter.
I've got a deeper understanding of atmospheric pollution, looking for data on air pollution over the past decade, and weather data from Johannesburg and surrounding areas. After that, together with my colleagues in South Africa and China, I created the Air Quality Resolution Support System and uploaded it to the cloud.
This software analyzes historical and real-time data to reveal trends in pollution over time and space.
We then use new machine learning technologies to predict future pollution days in advance.
This means residents can make better decisions about their daily itineraries and where to settle with their families.
We can anticipate adverse pollution events in advance, define major sources of pollution, so that relevant authorities can direct their operations to adjust their operations.
Through supporting scenario planning, urban planners can also make better decisions on how to expand infrastructure work, such as residential settlements in industrial areas.
We have set up an advance pilot of the technology, running for 120 days, covering the whole of South Africa.
Our expected results have been verified. The predictions we show are closely correlated with the data we collect in the field.
Through our management, we introduced the world's leading, cutting-edge instruments to predict atmospheric quality with unprecedented resolution and accuracy rates, benefiting the city I drove in the recent winter morning. And I said to myself, “Something isn't right, I have to find ways to do something.”
So, the point is: What if I didn't go deep into the problem of atmospheric pollution?
What if I don't focus on the state of the country, but rather hope to be in some places, others, to take care of these things?
What I learned from this is that, as we are fully committed to advancing a cause that we all believe in, it is important to focus on the possibilities of success and consider the consequences of inaction.
We should not be distracted by opposition and resistance; it should inspire us to go further.
So no matter where you are in the world, next time, when you find that some kind of curiosity you are born into is stirred, and it's about what you care about, you have some crazy or brave ideas, even if it's not your field of expertise, ask yourself: why not try it?
Why not brave to come straight to solve the problem? Do your best to your own way?
You may get unexpected joy.
Thank you all.
(Applause)
Many people think that driving is a thing that only those who can see it can do.
Blind people want to drive a car safely alone until now, is also considered an impossible task.
Hello everyone, my name is Dennis Hung, and we built a car designed for people with visual impairments for the freedom and independence of the blind.
Before I talk about this car for the blind, let me briefly say another project I've done is called the U.S. Department of Defense Advanced Research and Planning Bureau Urban Challenge.
It's about making a mechanical car that can drive itself.
You press the Start button, no longer touching anything, and it can reach its destination completely automatically.
In the 2007 Challenge, our team won $500,000 to win the third place in the competition.
Probably then, the National Association of the Blind, or the Blind Association, challenged the design team about who could design a car that would allow blind people to drive independently and safely.
We think we need to try it, because we think, ah, this will be difficult to go.
We already have an automatic car.
We just let the blind man drive inside, then we don't finish it, right?
(Laughter) But we're wrong.
What Blind wants is not a car that can carry blind people around, but a car that the blind can take the initiative to make choices and control.
So we had to give up everything we had to do from scratch.
To test this crazy idea, we designed a prototype car of a small sand truck to test its viability.
In the summer of 2009, we invited many young blind people across the country and gave them a chance to use this car for a ride.
It's definitely a cool experience.
But the problem with this car is that it is designed to allow blind people to drive in very limited environments, like a closed parking lot — even on roads made of red traffic cones.
So with this success, we decided to take the important next step, making a real car that can drive on real roads.
So how does it work?
Well, this is a relatively complex system, but let me explain it, to simplify it.
We have three stages.
We have induction stages, computational stages and non-visual interfaces.
The driver is obviously invisible, so the system must be able to perceive the surroundings and collect data for the driver.
For this point, we use the initial metering element.
It measures acceleration, angular acceleration — just like the human ear, the inner ear.
I combine this information with GPS to predict where the vehicle is.
We also use two cameras to detect the path of the road.
We also use three laser range finder.
Laser scans the environment to detect obstacles — the vehicle passing from the front and rear is accompanied by any obstacles that break into the road, any obstacles around the vehicle.
All the massive information is then aggregated into the computer, and the computer does two things.
First, one thing is to process information to understand the surroundings — which are driving paths, which are obstacles — and transforming that information to the driver.
This system is also very intelligent to calculate the safest driving path.
We can also issue instructions on how to operate the operating procedure of the vehicle.
But the question is: How can we pass information and instructions quickly and accurately enough to make sure he can drive?
To this end, we have designed a number of different non-visual user interface technologies.
The initial three-dimensional flat sound system, vibrating vest, voice gear, leg strap, and even pressure shoes on the foot.
But today we're talking about three of these non-visual user interface technologies.
The first interface is called the driver handle.
This is a pair of gloves, which has vibrating elements in the knuckles so that you can transmit instructions on how to travel — direction and amplitude.
The other device is called the speed shock belt.
This car chair — actually, it's a massage chair.
We disassemble it, we reassemble the vibrating elements of different modes. We let them transmit information about speed and also have instructions on how to use throttle and brakes.
Here, you can see how the computer understands the surroundings. Because you can't see the vibration, we actually installed a red LED on the driver, so he can see what's happening.
This is the sensing data, which is transferred from the sensor to the computer.
So these two devices, the driving handle and the speed shock belt, are very effective.
But the problem is that these are the instructions implied devices.
So that's not really freedom, right?
The computer tells you how to drive — turn left, turn right, accelerate, brakes.
I call this a copilot problem.
So we are avoiding instructions suggesting devices and focusing more on information devices.
A typical example of this non-visual information interface is called empty diagrams.
Think of this as a display for the blind.
This is a small table with a lot of holes on it, and compressed air is excluded from it, so that it can be described as a picture.
So even if you're blind, you put your hands on it, you can sense the path and obstacles.
In fact, you can also change the frequency of release in the air, and possibly the temperature.
This is actually a multidimensional user interface.
Here, you can see the cameras on the left and right sides and how the computer parses and sends this information to the empty image.
So, we're showing a simulation program where a blind man is driving with an empty figure.
This program is very helpful in training blind drivers and quickly testing different theories based on different kinds of non-visual user interfaces.
That's basically how it works.
But this car is a model car, and it won't go on the road unless it's proven to be as safe as today's car, or safer.
I really believe this will happen.
But do societies accept this radical idea?
How will we deal with insurance?
How will we issue a driver's license?
There are many different obstacles behind the technological challenges that we need to address before they really become a reality.
Of course, the main purpose of this project is to design a car driven by the blind.
But the potential more important than this is the great value of the by-products in this project.
A sensor that can be used to see dark, rain and fog.
And this new kind of interface, we can use these technologies to make them safer vehicles for the visual population.
Or for the blind, daily life on household devices — educational facilities, office facilities application services.
Imagine that teachers write notes on blackboard in class, blind students can also use these non-visual interfaces to understand and read what teachers write.
This is extremely precious.
Today, what I have shown to you, is just the beginning.
Thank you very much.
(Applause)
Being an artist, contact is very important to me.
Through my work of art, I try to make it clear that humans are not separated from nature, but that everything is connected.
I first went to Antarctica about 10 years ago, and I saw the iceberg for the first time.
I feel awe.
My heart swings quickly and dizzy, trying to understand exactly what this is in front of me.
The iceberg around me surfaced almost 200 feet. I can only feel strange. This is what one snowflake is covered in another, formed year after year.
The icebergs are formed when they break from the glacier or from the ice shelf.
Each iceberg has its own unique personality.
They have a distinct way of interacting with their surroundings and their circumstances.
Some icebergs refuse to compromise to the end, while others can't stand the cracking of water under a surge of intense passion.
When you see the icebergs, it's easy to think that they are all isolated, they are independent, separate, and more like what we humans sometimes think of ourselves.
But reality is far more than that.
As the iceberg melts, I breathe into its old scent.
As the iceberg melts, it releases mineral-rich fresh water that nourishes everything.
I started shooting these icebergs as if I was photographing portraits of my ancestors and learned that in these individual moments the icebergs were in that way but never again.
When they melt, it is never death; nor is it an end, but a continuation of the road to life.
I've photographed the iceberg, and some ice are very young — thousands of years old.
Some ice is over a hundred thousand years.
The final picture I want to show you is an iceberg I took on Kekertsuatsiak in Greenland.
This is a very rare opportunity for everyone to actually witness an iceberg rolling.
So that's as shown in the picture.
On the left you can see a boat.
This is a boat of about 15 feet.
I want you to pay attention to the shape of the iceberg and its deformation on the water.
Here you see that it starts to roll, the boat moves to the other side, and a man stands there.
This is an average size Greenland iceberg.
It surfaced about 120 feet tall or 40 meters tall.
This video is shot in real time.
(Music) Like this iceberg, they show you different aspects of their personality.
Thank you.
(Applause)
Do you know how many flowering plants are there?
There are 250,000 species — at least we know so many — 250,000 flowering plants.
And flowers are a troublesome thing.
It is really difficult to make plant breeding.
It requires a lot of experience and a lot of resources.
Why is it so bothered?
Of course, the answer is, like many other things in the world, gender.
I know what you think when you look at these pictures.
There is a reason why sexual reproduction is so important — there are many other ways in which plants can reproduce.
Can be used in the way of interpolation; can be multiply with strains; pollination can be the same strain.
But they do need to spread their genes mixed with other genes so that they can be ecologically.
That's how evolution works.
Now the way in which plants pass this message is through pollen.
Some of you may have seen these images before.
As I said, every family should have a scanning electron microscope that can see these.
There are many different types of pollen as many flowering plants.
This is actually quite useful for forensic science and so on.
Most of the pollen that causes us to get hay fever comes from plants that use the wind to spread pollen. It's a very inefficient process, which is why pollen always runs into our nose.
Because most of them are abandoned, it is hoped that the germ cells contained in pollen, male germ cells, will happen to fall on another flower.
All grass, which means all grains, and most trees spread pollen by wind.
But most species actually use insects to accomplish this process. In a way this is smarter, because it doesn't require much pollen.
Insects and other species can carry pollen and transfer pollen directly to where it is needed.
Obviously, we note the relationship between insects and plants.
This is a symbiotic relationship, whether it's birds or bees, they all get in return, usually the return is nectar.
Sometimes this symbiotic relationship leads to a marvelous adaptability change — a pretty adaptive change in the Red Skirt moth.
Plants also have harvest, Tian e spread pollen to other places.
Plants have developed, everywhere to create landed runways, bees may be lost among them.
Many plants have some markings that look like other insects.
These are the pollen capsules of lilies, very clever, so when unknowingly insects fall on them, the pollen capsules flip over and hit the back with a lot of pollen, so you can follow the insects to other plants.
There is an orchid that looks like it has a jaw. To some extent, it does; it forces insects to climb over, dip pollen, and take pollen somewhere else.
Orchid: There are at least 20,000 kinds of orchids — the variety is amazing.
They have a variety of tricks.
They must try and attract pollinators to help them through the process.
This orchid, known as Darwin's Orchids, because it was studied by Darwin and gave fantastic predictions when he saw this orchid. You can see a long nectar tube hanging from the orchids here.
Basically what the insects had to do — we came to the flower — it pierced the mouthpiece into the middle part of the way and knew the nectar tube down to get the nectar.
Darwin said, look at the flower, “I guess some things have developed with it.”
There is no doubt that it is insects.
I mean, usually it's all rolled up, but after it straighten, it looks like this.
Now imagine that if nectar, such a valuable thing, is expensive for plants and attracts many pollinators, then, as in human sex, people may start deceiving each other.
They might say, “I have some nectar. Do you want to come and get some?”
This is a plant.
This plant is loved by insects in South Africa. They have developed long mouthers to get nectar at the bottom.
This is an imitator.
This plant mimics the former plant.
There is a flies with a long mouth that doesn't get any nectar from the impersonator. Because the impersonator did not give it any nectar. It thought it could get.
So not only do flies not get nectar from fake plants, but — if you look very close to the top of the head, you'll see there's some pollen that will spread to other plants, if no botanist comes to stick it to a blue card.
(Laughter) This lies all over the plant kingdom.
This flower with black dots: they may seem like black spots in our view, but I tell you, for the proper species of male insects, it looks like two very, very sexy females.
(Laughter) When the insects arrive and land on it, dip themselves in pollen, and of course, these pollen will be taken by it to other plants, and if you look at the scanned electron microscopy that every family should have, you can see actually some patterns, three-dimensional patterns there.
It even makes insects feel comfortable and looks good.
These electron microscopy images — this is an orchids disguised as an insect — you can see that for our eyes different parts of the structure have different colors and different textures, and insects may perceive very, very different textures.
This orchid has progressed to mimic the metallic glossy surface seen on some beetles.
You can see this surface under a scanning electron microscope — this is very different from the other surfaces we've seen.
Sometimes the whole plant mimics an insect, even if we seem to be an insect.
I mean, I think this looks like some kind of flying animal or beast.
Is a wonderful and magical thing.
That's what it's clever. It's called Obsidian.
I think it's sometimes cunning.
For the kind of bee, this looks like another very aggressive bee, which will fly over and hit it many times with its head, try to drive it away, and of course, it will stick it with pollen.
Another thing it does is that this plant mimics another orchid rich in the food that insects love.
But in fact, nothing.
So it deceives on two levels — really incredible.
(Laughter) What we see is Ylang, a part with a strong scent.
I actually smell it before.
These flowers don't actually need to be so gorgeous.
They emit a wonderful scent that attracts any insects that are interested.
This flower doesn't smell so much.
This flower actually smells very unpleasant again, it's evolution, and it looks like carrion.
So flies like it.
Flies fly in and pollinate them.
This is White Star Arum, also known as Dead Horse Taro.
I don't know what a dead horse smells, but this flower may smell very much like.
It's terrible.
Green-headed flies cannot be restrain.
Fly into it, all the way into it.
Spawn eggs on top, think this is a very good carrion, without realizing that there are no eggs, these eggs die here, but at the same time the plant will benefit, because the hair loosens the flies disappear and pollinate to another flower — so wonderful.
This is the taro plant, macarum, spotted Aramus, called Trillium in this country.
I shot this last week in Dorset.
This guy heats up about 15 degrees higher than the ambient temperature — incredible.
If you look inside it, behind the spike is something a bit like a dam, and flies attract heat — this is a boiling volatile chemical, small bugs — they're trapped under this container.
They soared sweet nectar and then all became a bit slimy.
They are covered by pollen at night, sprayed down from them, and the hard hairs we see on it become withered, allowing these pollen bugs to escape — really incredible.
If you think it's incredible, this one is my favorite.
This is the spring feather Philodendron.
Those who come from Brazil should know this plant.
This is the most amazing thing.
Its stamens are about a foot long.
It has a capability that I do not know any other plant has, and when it blooms — this is a spike in the middle — for about two days, it produces some degree of metabolic change somewhat similar to mammals.
And there is no starch, this is the food of the plant, it has something very similar to brown fat burns it at the rate of burning fat, metabolized, about the speed of a kitten.
By weight ratio, twice the energy output of a hummingbird — absolutely amazing.
It also did something unusual.
Not only is it going to heat up to 155 degrees Fahrenheit, 43 or 44 degrees Celsius for two days, but also it will keep constant temperature.
There is a temperature regulation mechanism to maintain a constant temperature.
Why do you want to do this? I hear you guys ask.
You don't know yet, some beetles like to mating at this temperature.
They are drilled, stained with pollen.
(Laughter) Plants fill them with pollen, let them leave and pollinate.
This is a wonderful thing.
Now we think most pollinators are insects, but actually in the tropics, many birds and butterflies also pollinate.
Many tropical flowers are red, because butterflies and birds are similar to us, and we think we can see the red very well.
But if you look at the spectra, birds and us, we see red, green and blue see this spectrum.
Insects see green, blue and ultraviolet rays, they can see a variety of light and dark UV rays.
There are some colors behind this.
“Wouldn't it be nice if we could see those colors,” I heard you ask.
Yes, we can see.
So what do insects see?
Last week I took pictures of these desert lotus, Half-Day, in Dorset.
As we can see, these are small yellow flowers, which are everywhere.
It looks like this in the visible light.
If you remove the red looks like this.
Most bees do not perceive red.
And then I put a UV filter in front of my lens for a long exposure at a specific frequency of ultraviolet light, and I got this picture.
It's like a real marvelous bullseye.
Now we don't know exactly what bees see, and when I call it red, you know what I'm looking at.
We can't know what's going on, be it insects, or in other human brains.
But the contrast looks like this. Highlight from the background.
This is another type of flower — located in different UV frequency zones, with different filters to match different pollinators.
It looks like this.
To avoid thinking that all yellow flowers have this property — there is no damage to the flower during the shooting; just stick it to the tripod and not take it off — in UV light, look at this.
This can serve as a basis for sunscreen, which works by absorbing UV light.
So perhaps the chemicals are useful.
Finally, this is a twilight that was sent to me by Norwegian Bjorn Rorslett — the wonderful hidden pattern.
I like this hidden way.
I think it's poetic. These photos are taken with UV filters, which are primarily used by astronomers to shoot Venus — actually clouds on Venus.
This is the main use of this filter.
Of course, Venus is the god of love and fertility, this is the tale of flowers.
Just as the flowers spent so much effort trying to attract pollinators to accept their invitations, somehow, they managed to convince us of the rich content that we send flowers to each other at birth and death, especially at weddings, and when you think of it, in this moment, the genetic material is migrating from this moment. organisms to another.
Thank you very much.
(Applause)
