I am dedicated to helping computers communicate with the world around us.
There are many ways to do this, and I like to focus on helping computers talk about what they see and understand.
Given this scenario, a modern computer vision algorithm can tell you that there is a woman and a dog.
It can tell you that the woman is smiling.
It can even tell you that this dog is very cute.
I deal with this question thinking about how human beings understand and live with the world.
Those thoughts, memories, and stories in such a scene may evoke human attention.
The interconnectedness of all relevant situations.
Maybe you've seen such a dog before, or you've spent time running on such a beach and further evoking memories and thoughts of past vacations, when you used to go to the beach and spend time running around with other dogs.
One of my guiding principles is that by helping computers understand what this experience is, and thus what we believe and feel in common, then we have the ability to start evolving computer technology in a way that complements our experience.
So digging deep into this, I started working a few years ago to help computers produce human - like stories from image sequences.
So, one day, while I was working with the computer, I asked it what it thought about the trip to Australia.
It looked at the picture and saw a koala.
It didn't know what the koala was, but the computer said it thought the koala looked like an interesting creature.
I then shared a series of images with the computer of the house burning down.
The computer looked at the picture and said, "This is an amazing landscape! This is spectacular!"
It chills my spine.
The computer sees a terrible, life - changing and life - destroying event and thinks it's a positive thing.
I realised that the computer recognised the contrast between red and yellow and thought it was something worthy of a positive review.
Partly this is because most of the images I input into the computer are positive.
That's because people tend to share positive images when they talk about their experiences.
When was the last time you saw a selfie at a funeral?
I realized that in the process of improving AI, it is task by task, dataset by dataset, creating huge gaps, flaws and blind spots in the understanding of computers.
In doing so, I am coding for all kinds of biases.
Bias reflects limited views and stems from a dataset - which reflects the same things as humans, such as stereotypes and stereotypes.
I think back to the development of the technology that brought me to where I was that day - the first color image was calibrated for the skin color of a white woman, which meant that color photography was biased against blackface.
And the same bias, that blind spot continued into the 90s.
The same blind spot still exists today in how to recognize the faces of different people in the application of facial recognition technology.
In today's research, I think of the most advanced technologies, all of which tend to limit our ideas to one dataset and one problem.
And in doing so, we are creating more blind spots and biases that will be further amplified when using AI.
At that time, I realized that we had to ponder how the technology we invented today would be viewed in five to ten years.
In human interaction with the environment, humans take time to correct problems, so evolution is slow.
Artificial intelligence, by contrast, is developing at an incredible rate.
This means that it is really important, and we need to think about that now - reflect on our blind spots, and our biases, and consider how these biases affect the technology we create now, and discuss what today's technology means for the future.
CEOs and scientists have weighed their ideas about the future of artificial intelligence development.
Stephen Hawking warned: "Artificial intelligence will wipe out humanity."
Elon Musk warns this is an existential risk and one of the biggest risks we face as a civilised society.
"I don't understand why people aren't more worried about AI," Bill Gates said.
But these points are only part of the story.
The math, the models, these basic components of artificial intelligence, are something we can all acquire and use.
We have source code tools that are open to the public to learn about machines and make our own contributions at the same time.
In addition, we can also share our experiences.
We can share in terms of technology and how it relates to us, and how it excites us.
We can discuss what we love.
We can communicate with the foreseeable future that this may be more beneficial in terms of technology, or that more problems may arise over time.
If we all focus on opening up the discussion about AI to the future, it will help create a regular conversation and awareness about what AI is, what it can be, and all the things we need to do to achieve the results that best suit us.
We already see and understand this in the technology used today.
We use smartphones, digital assistants and automatic vacuum cleaners.
Are they evil?
Maybe sometimes.
Are they beneficial?
Yes, they are.
They are not identical.
There you have seen the light of the future.
The future will continue to start with what we build and create now.
We started the domino effect, which opened up the evolutionary pathway for artificial intelligence
In our time, the artificial intelligence that shapes tomorrow.
so that we can immerse ourselves in augmented reality technology and resurrect the world of the past,
When people have trouble communicating, technology helps them share each other's experiences.
Technology built on online visual media can be used for self - driving cars.
Technology, which produces language based on the understanding of images, can evolve into technology to assist visually impaired people and help them better own the visual world.
We have also seen how technology has led to some problems.
We have technology today that analyzes the physical characteristics of our birth - such as the color of our skin or the expression on our faces - to determine whether we are criminals or terrorists.
We have the technology to process data, to process data about gender or race, to determine whether we can get a loan.
Everything we see now is just a snapshot of the evolution of artificial intelligence.
Because where we are now, it is a moment in evolution.
This means that what we do now will affect the future development of things and extend to the future world.
If we want AI to help the way humans evolve, we need to define strategies and goals and open that path immediately.
What I want to see is the direction of development suitable for human culture and environment.
Technology can help us heal people with neurological diseases or other disabilities, making their lives as challenging as everyone else.
Technology does not work with your features or skin color in mind.
What I'm focusing on today is technology for tomorrow and ten years from now,
Artificial intelligence can emerge in many different ways.
But in this case, it is not a driverless car without any destination.
This is a car we can drive and control at the same time.
We choose when to accelerate and when to slow down.
We choose whether we need to turn.
We choose what the AI of the future will be.
There will be a vast arena to allow AI to be everything.
It will become a lot of different things.
It is now up to us to figure out what needs to be implemented to ensure that the results of AI are better for all humans.
Thank you.
(Applause)
I would like you to take a moment to consider the very simple fact that so far most of our understanding of the universe has come from light.
When we stand on the earth and look up at the night sky, we can see the stars with the naked eye.
The strong sunlight was so harsh,
We can see the light reflected back from the moon,
Ever since Galileo aimed his humble telescope at the celestial bodies of the universe, the universe as we know it today has been presented to us through light.
With the help of modern telescopes, we have been able to collect dazzling and silent images of the universe, a series of images that go all the way back to the Big Bang.
However, the universe is not a mime, because the universe is not really silent.
I want to tell you that the universe has its own soundtrack, and the universe itself is constantly playing, because space can vibrate like a drum.
So it can make a series of sounds into the universe when something big happens.
Now, we hope to be able to add sound to this magnificent visual work about the universe.
Although we have never heard a sound from outer space, we should be able to turn up the volume and listen to what is happening there in the next few years.
With the ambitious goal of capturing the sounds of the universe, we are focusing on black holes and the prospects they present, because black holes can hit space - time like a drumstick hitting the surface of a drum and make very special sounds, and I am very happy to play you some of the sounds we predict.
One day we may be able to see a shadow A black hole can leave a shadow on a very bright background, but it has not yet been observed.
Although black holes can't be seen, they can be heard because they hit space - time like a drum.
The idea that the universe can sound like a drum came from Albert Einstein. In fact, many of our ideas come from him.
Einstein realized that if the universe was empty, if the universe was empty, it would look like this picture, except for the auxiliary lines drawn on it.
But if we are in free fall in the universe, even without these auxiliary lines, our trajectory will draw these lines, because we will find that we are moving in a straight line, passing through the universe in a straight line that does not bend.
Einstein also realized - and this is really the most critical part (matter also means "matter ") - that if you put energy and matter into the universe, the universe will bend, and objects in free fall will be deflected along the curved path in space as they pass toward objects like the sun.
This is Einstein's great theory of general relativity.
Even the path of light can be bent.
When the bend is large enough, it revolves around the orbit of the sun, just as the earth revolves around the sun and the moon revolves around the earth.
This is the natural curve of the universe.
But Einstein did not realise that if you compress the sun into a ball 6 km in diameter, that is, you compress a million times the mass of the Earth into a ball 6 km in diameter, you will create a black hole that is so dense that if light gets too close to it, it will not escape - leaving a huge dark shadow in the universe.
But Einstein always thought that black holes were just mathematical singularities.
He did not believe that black holes really existed.
He believed that nature would prevent the formation of black holes to protect us.
It was decades before people began to use the term "black hole" and realized that black holes were real objects. In fact, they were the death states of some extremely massive stars after a catastrophic collapse at the end of their lives.
Our sun does not collapse to form a black hole.
It's not really big enough.
But if we do some thought experiments, which Einstein liked so much, we can imagine crushing the sun and compressing it within six kilometers, and then placing a small Earth in an orbit around it, say, 30 kilometers away from the black hole sun.
The earth will shine on its own because now the sun is gone and we have no other light source so our little earth will have to shine on its own.
You will find that you can even put the Earth in an orbit 30 kilometers away from the black hole and let it happily orbit.
The black hole is actually about the size of Manhattan.
Before it destroys the earth, it could swell to Hudson Street.
But basically that's what we're talking about.
We're talking about an object that has been compressed to half the size of Manhattan.
So we moved this Earth 30 kilometers closer to the black hole and we noticed that it was orbiting the black hole in a perfect orbit.
There are some rumors that black holes will devour everything in the universe, but in reality you have to be very close to actually fall in.
But what is impressive is that from our point of view, we can always see the Earth.
It can't hide behind a black hole.
Some of the light emitted from the Earth falls into the black hole, but some is bent by the black hole and seen by us.
So you can't hide anything behind a black hole.
If this is Battlestar Galactica and you're fighting the Cylons, don't hide behind a black hole.
They can see you.
Our Sun does not collapse into a black hole; it is not massive enough, but there are tens of thousands of black holes in our Milky Way.
If one of them were devouring the Milky Way, it would look like this.
We will see the shadow of a black hole cast on hundreds of billions of stars in the Milky Way and the dust bands illuminated by stars.
If we fall into this black hole, we will see light being refracted around the black hole, and we will not even feel some huge change quietly happening when we begin to enter this shadow.
If we try to start the rocket and get out of there, it won't turn out very well, because we can't escape, not even the light.
Although black holes are dark from the outside, they are not from the inside, because light from all galaxies can fall into them with us.
And even so, due to the relativistic time dilation effect, our clocks seem to be slowing down compared to the time of the Milky Way, which looks as if the galaxies outside are accelerating, just before we are destroyed by black holes.
It's like experiencing the feeling of dying, you see the light at the end of the tunnel, but it's a complete death experience.
(Laughter) There is no way you can tell anyone that you saw light at the end of the tunnel.
So far, we have never seen the shadow left by such a black hole, but black holes can be heard even if they cannot be seen.
Imagine, in a real astronomical scene, two black holes that have been together for a long time.
Perhaps they were stars before collapsing into two black holes, each with a mass 10 times that of the Sun.
Now we compress them to within 60 kilometers.
They can rotate hundreds of times per second.
At the end of their lives, they approach each other at the speed of light.
They can travel thousands of kilometers in a fraction of a second. In the process, they not only bend space, but also cause vibrations in space in the wake behind them, a real - life spacetime wave.
Black holes squeeze and stretch space as they collide with the universe.
These vibrations travel through space at the speed of light.
The computer simulation was done by NASA Goddard's Relativity Group.
It took nearly 30 years before and after to solve this problem.
This is one of many groups.
It shows two black holes rotating around each other. These are imaginary curves.
As you can see, it may be a little fuzzy, and you can see that the red waves are being emitted, and these are gravitational waves.
They are the actual sounds of the universe, which will travel at the speed of light from the black holes as they merge with each other until the two black holes merge into a single, quietly rotating black hole.
If you stand close enough, your ears will resonate with the squeezing and stretching of these spaces.
You can really hear these sounds with your own ears.
Of course, you will helplessly find that your head is also squeezed and stretched, so you may not be able to understand what happened.
But I'd like to play the sound of our predictions for you.
This is the result of my group's research - a relatively simple computational model.
Imagine a less massive black hole falling into a more massive black hole.
The sound you hear comes from small - mass black holes colliding with space as they approach massive black holes.
If they are far away, the sound will be very small.
But gradually the sound becomes like a drumstick pounding the space, making the space vibrate like a drum.
We can predict what this sound will become.
We know that small - mass black holes get faster and louder as they fall.
Eventually, we will hear that the small black hole has completely fallen into the big black hole.
I've never felt this loud - it's actually amplified here.
When I heard it at home, I felt that the sound was a little weak.
It sounds like, jingle, jingle, jingle.
This is another sound that our team simulated.
I'm not going to show you images here, because black holes don't leave any useful traces, and real space doesn't show you those virtual curves.
But if you hear this sound while holidaying in the universe, I advise you to run.
(Laughter) Better get away from the sound.
Both black holes are moving.
Two black holes are approaching each other.
In this case, they were all shaking violently.
Then, they will merge.
That shrill sound is a sign of black hole fusion - a shrill sound at the end of the fusion.
This is our prediction of what we will see.
Luckily we are very safe in Long Beach, CA.
There is no doubt that somewhere in the universe two black holes have merged.
There is also no doubt that the space around us can also feel these vibrations that travel a million light years, or from a million years ago, traveling at the speed of light and eventually meeting us.
But these sounds are so small that we can't hear them at all.
There are experiments around the world that take a lot of effort to set up. Among them is one called LIGO - which will be able to detect vibrations in space that are less than one atomic nucleus at a distance of four kilometers.
This is a very bold attempt, and its sensitivity will not be surpassed in the next few years - it will be used to detect vibrations in space.
Another research project on the universe, called LISA, is expected to be launched in the next decade.
LISA will be able to see supermassive black holes - those that are millions or even billions of times more massive than the Sun.
We see these two galaxies in images sent back by the Hubble Telescope.
It looks like they are still hugging each other.
They may each have a massive superblack hole at their center.
But they are not static; in fact, they are merging.
The two black holes will collide, and their fusion will take billions of years.
So collecting the sounds they make is beyond the limits of our human perception.
But LISA can see the final stages of two supermassive black holes that began to merge much earlier, 15 minutes before they merged.
This detection is not limited to black holes. It can also be used to detect any large disturbance in the universe - the biggest of which is the Big Bang.
When the term was coined, some people mocked - "Oh, who would believe in the Big Bang?"
This animated short, made by a friend of mine at Proton Studios, shows the Big Bang from the outside.
We would never really want to be like this; we want to be inside the universe, because there is no such thing as being outside the universe.
So imagine you're in the middle of a big bang.
The universe is everywhere, everything in the world is around you, and space is swaying in disorder.
Fourteen billion years later, and that voice still haunts us.
Galaxies gradually form, and groups of stars form in the galaxy. On a certain planet, there is at least one such planet, suitable for life.
Here, we frantically build experiments, do calculations, write computer code.
Imagine, a billion years ago, two black holes collided.
The sound has been moving through time and space all along.
We weren't even here.
It's getting closer - 40,000 years ago, we were still painting on the stone walls of the cave.
If the sound we were trying to get was from the Big Bang, it would sound like this.
Strictly speaking, it is noise.
It was a white noise, a chaotic ringing.
But it is everywhere around us, as long as it is not offset by some other process in the universe.
If we can detect these sounds, it will be like music to our ears, because the quiet echo comes from the moment we were created, from the universe we look up at.
So in the next few years, we will be able to turn up the volume of these soundtracks a little bit, so that the universe is presented to us in audio form.
But if we can detect those earliest moments, it will also take us a step closer to understanding the Big Bang, allowing us to ask some of the most difficult and ethereal questions.
If we play the history of the universe upside down, we can know that there was a big bang in the past, and we can even hear its noisy sound. But is our big bang the only big bang in the universe?
I mean, we can't help but ask, has there ever been a big explosion like that before?
Will it happen again in the future?
I want to say that if we take this question to the level that TED is advocating to trigger a rethink, at least in this last minute, we can ask some questions that we really may never be able to answer.
But we can't help but ask: could my universe be just an episode in a larger history?
Or would we just be a branch of the multiverse, each of which has experienced its own big bang, maybe some of them have buzzing black holes, maybe some don't, maybe some have conscious life, maybe some don't, they don't belong to our past, they don't exist in our future, but are somehow connected to us?
So we can't help but wonder, if there is a multiverse, is there life in other branches of this multiverse?
This is life in our multiverse.
Are there other beings in the multiverse, and are they also speculating about our existence and pondering their own origins?
If so, I can imagine them doing calculations, writing computer code, building experimental instruments, trying to detect the faint sounds from their origins, and wondering who else was there.
Thank you. Thank you all.
(Applause)
One winter morning a few years ago, in Johannesburg, South Africa, I was driving to work to find the city covered in haze.
I drive by there almost every day, but this was unusual. I had never seen such a sight before.
Johannesburg is known for its distinctive and beautiful skyline, but it was barely visible that morning.
I soon realized that what I was seeing was a severe haze caused by air pollution.
The contrast between the beautiful surroundings I used to know and the smog - shrouded skyline of the moment was a constant in my mind.
I fear there is a good chance that the once colourful beauty of the sunset will be swallowed up by a murky haze.
At that moment, I felt a strong urge to do something, but I didn't know what to do.
All I know is that I can't just stand by and watch.
The biggest challenge is that I don't understand environmental science, air quality management, or atmospheric chemistry.
I'm a computer engineer, and I'm pretty sure I can't code to solve the problem of air pollution.
(Laughter) In what capacity will I solve this problem?
I'm just a city guy.
Over the next few years, I learned an important lesson that we should all keep in mind if we want to achieve a better future.
Even if you are not an expert in a particular field, your expertise may contain solutions to problems in that field.
Sometimes, your unique perspective can inspire unconventional thinking to shape the situation, but you need to be bold.
Only then can you know the results.
What I knew at the time was that if I wanted to try to change, I had to know enough about pollution, so I became a student again.
I did some basic research and quickly learned that air pollution is the biggest environmental health risk in the world.
According to the World Health Organization, in 2012, almost 14% of deaths worldwide were caused by air pollution in and around households, especially in low - and middle - income countries.
The annual death rate from air pollution is higher than that from malaria and AIDS.
In Africa, premature deaths caused by unsafe sanitation, or deaths caused by malnutrition in children, pale in the face of air pollution, and it also carries huge economic costs: more than $400 billion was spent in 2013, according to the Organization for Economic Cooperation and Development.
In my work, I explore the technological frontiers of AI, including the symbiotic relationship between humans and machines, to find a useful foothold and help us make better decisions.
When I think about air pollution, it becomes clear that we need to find better ways to make better decisions. Considering that the problem is huge, it is very necessary to work together.
So I decided to get to know some people who work in this field.
I started talking to officials in Johannesburg and other surrounding cities, I joined the local scientific community, and I made some phone calls to people who were completely unfamiliar but related.
These experiences that I set out to intervene helped me to understand the problem more deeply.
It also helped me avoid the pitfall that people in my field sometimes fall into when trying to innovate: quickly adopting a technology before they really grasp the problem.
I began to think, what can I do to improve the situation?
I began to ask myself how I could effectively combine my knowledge and skills in software engineering and artificial intelligence with the expertise of the people I contacted.
I wanted to create an online air quality management platform to reveal future pollution trends and make predictions to determine what might happen.
I am convinced that my idea can be a realistic solution, but there is uncertainty, and I cannot guarantee that it will succeed.
What I have is a specific set of engineering skills, acquired from my job. (Laughter) Of course, for someone who has been working in the field of air pollution for many years, my skills are new.
I came to realize that sometimes a new perspective, a new skill set, can lead to something remarkable.
Our willpower and imagination are a beacon of light that will guide us past obstacles and open a new chapter.
I gained a deeper understanding of air pollution, looking for air pollution data from the past decade, as well as meteorological data from Johannesburg and its environs, and then, together with colleagues in South Africa and China, I created the Air Quality Resolution Support System and uploaded it to the cloud.
The software analyzes historical and real - time data to reveal trends in pollution over time and space.
We then used new machine learning techniques to predict future pollution days in advance.
This means that residents can make better decisions about their daily journeys and where to settle with their families.
We can anticipate adverse pollution events in advance, define major sources of pollution, and allow the relevant authorities to issue directives to adjust their operations.
By supporting scenario planning, urban planners can also make better decisions on how to expand infrastructure work, such as housing in industrial areas.
We have set up a pilot of the technology, which has been running for 120 days, covering the whole of South Africa.
Our expected results were validated, and the predicted data we presented showed a strong correlation with the data we collected in the field.
Through our management, we have introduced world - leading cutting - edge instruments to predict air quality with unprecedented resolution and accuracy, benefiting the city I drove into on a recent winter morning, when I said to myself, "Something is wrong, I have to find a way to do something."
So, the point is: what if I hadn't investigated the problem of air pollution in depth?
What if instead of paying attention to the state of the environment in the country, I hope that some place, some other person, will take care of these things?
What I have learned is that it is important to focus on the possibility of success and consider the consequences of inaction when advancing a cause that we all believe in.
We should not be distracted by opposition and resistance, it should motivate us to go further.
So wherever you are in the world, the next time you find that your innate curiosity is aroused, and that it is about something you care about, and you have some crazy or brave idea, even if it is not your area of expertise, ask yourself: Why not try it?
Why not go ahead and solve the problem? Try your best, in your own way?
You may get a surprise.
Thank you all.
(Applause)
Many people think that driving is something that only those who can see can do.
Until now, it was considered an impossible task for blind people to drive a car safely alone.
Hello everyone, my name is Dennis Hong, and we built a car for the freedom and independence of the blind for people with visual impairments.
Before I talk about the car for the blind, let me briefly talk about another project I've worked on called the Defense Advanced Research Projects Agency Urban Challenge.
This is about building a mechanical car that can drive itself.
You press the start button, you don't touch anything, and it will reach its destination completely automatically.
At the 2007 Challenge, our team won $500,000 to finish third in the competition.
Around that time, the National Association of the Blind, or the Blind Association, challenged the design team about who could design a car that would allow blind people to drive independently and safely.
We thought we had to try it, because we thought, hey, this is going to be hard.
We already have an autonomous car.
We just have to let the blind drive inside, and that's not all right?
(Laughter) But we were wrong.
What the Blind Association wants is not a car that can carry blind people around, but a car that blind people can actively make choices and drive.
So we had to give up everything we had and start from scratch.
To test this crazy idea, we designed a prototype of a small sand truck to test its feasibility.
In the summer of 2009, we invited many young blind people from all over the country and gave them a chance to take a ride in this car.
It was definitely a cool experience.
But the problem with the car is that it is designed to allow blind people to drive in a very limited environment, like a closed parking lot - even on a small road made of red traffic cones.
So with this success, we decided to take the important next step of building a real car that can drive on real roads.
How does it work?
Well, this is a relatively complex system, but let me explain it and simplify it.
We have three stages.
We have the sensing phase, the computing phase and the non - visual interface.
The driver is clearly invisible, so the system must be able to sense the surrounding environment and collect data for the driver.
For this, we use the initial metering element.
It measures acceleration, angular acceleration - just like the human ear, the inner ear.
I combined this information with GPS to predict the location of the vehicle.
We also use two cameras to detect the path of the car.
We also use three laser rangefinders.
The laser scans the environment to detect obstacles - vehicles passing from the front, from the rear, as well as any obstacles in the road, any obstacles around the vehicle.
All this massive amount of information is then aggregated into a computer, which does two things.
First, one thing is to process information to understand the surrounding environment - which are driving paths and which are obstacles - and translate that information to the driver.
This system is also very intelligent to calculate the safest driving path.
We can also issue instructions on how to operate the vehicle's operating procedures.
But the question is: How can we transmit information and instructions quickly and accurately enough to a blind person to ensure that he can drive?
To this end, we have designed many different non - visual user interface technologies.
The original three - dimensional flat sound system, vibrating vests, voice - controlled gears, leg straps and even shoes that put pressure on the feet.
But today we're talking about three of these non - visual user interface technologies.
The first interface is called the driving handle.
This is a set, and in the knuckles it has vibrating elements, so you can transmit instructions on how to drive - direction and amplitude.
The other device is called a velocipede.
This car chair - - actually, this is a massage chair.
We take it out, we reassemble the different modes of the vibration elements, we let them transmit information about the speed, but also instructions on how to use the throttle and brake.
Here, you can see how the computer understands its surroundings. Because you can't see the vibrations, we actually put red LEDs on the driver, so he can see what is happening.
This is the sensing data, which is transmitted from the sensor to the computer.
So these two devices, the driving handle and the speed shock belt, are very effective.
But the problem is that these are command hinting devices.
So this is not freedom in the true sense, right?
The computer tells you how to drive - turn left, turn right, accelerate, brake.
I call this the co - pilot problem.
So we are avoiding instruction - hinting devices and focusing more on information devices.
A typical example of such a non - visual information interface is called a null graph.
Think of this as a monitor for the blind.
This is a small tabletop with a lot of holes in it, compressed air out of it, so it can be described as a picture.
So even if you are blind and you put your hand on it, you can sense the path and the obstacles.
In fact, you can also change the frequency and possibly the temperature of the air.
This is actually a multi - dimensional user interface.
Here, you can see the left and right cameras and how the computer parses and transmits this information to the empty map.
So, we're showing a simulation program where a blind person is driving with an empty map.
This program is very helpful in training blind drivers and quickly testing different theories based on different types of non - visual user interfaces.
That's basically how it works.
But this car is a model car, and it won't be on the road unless it proves to be as safe to drive as today's cars, or safer.
I really believe that this will happen.
But will society, will they accept this radical idea?
How will we deal with insurance?
How will we issue a driving licence?
Behind the technical challenges there are many different obstacles that we need to address before they become a reality.
Of course, the main purpose of this project is to design a car driven by blind people.
But potentially more important than that is the huge value in the by - products of this project.
A sensor that can be used to see through darkness, rain and fog.
And with this new kind of interface, we can use these technologies to make them safer vehicles for the visible crowd.
Or for the blind, the daily life of household devices - educational facilities, office facilities application services.
Imagine a teacher writing notes on a blackboard in class. Blind students can also use these non - visual interfaces to understand and read what the teacher writes.
It is extremely precious.
What I'm showing you today is just the beginning.
Thank you very much.
(Applause)
As an artist, connection is very important to me.
Through my works of art I try to make it clear that human beings are not separated from nature but that everything is interconnected.
I went to Antarctica for the first time about 10 years ago, and I saw icebergs for the first time.
I was in awe.
My heart slammed, dizzy, trying to understand what it was in front of me.
The iceberg next to me surfaced almost 200 feet above the water. I can only wonder that this is one snowflake covering another, year after year.
Icebergs form when they break away from glaciers or from ice shelves.
Each iceberg has its own unique personality.
They interact with their surroundings and their circumstances in a distinct way.
Some icebergs refuse to compromise and stay the course, while others can't stand to collapse under a momentary outpouring of passion.
When you look at icebergs, it is easy to think that they are all isolated, they are independent, separate, more like what we humans sometimes think of ourselves.
But the reality is much more than that.
As the iceberg melts, I breathe in its ancient smell.
As the iceberg melts, it releases fresh mineral - rich water that nourishes everything.
I set out to photograph these icebergs as if I were taking portraits of my ancestors, knowing that at these individual moments the icebergs existed that way but never again.
When they melt, it is not death; it is not an end, but a continuation on the road to eternity.
I have photographed icebergs, and some of the ice is very young - thousands of years old.
Some ice is more than a hundred thousand years old.
The last image I want to show you is an iceberg I took on Kekertsuatsiak in Greenland.
This is a very rare opportunity for everyone to actually witness an iceberg tumble.
So this is as shown in the figure.
On the left you can see a small boat.
This is a boat of about 15 feet.
I want you to pay attention to the shape of the iceberg and its deformation on the surface of the water.
Here you see it begin to roll, the boat moves to the other side, and a man stands there.
This is an average - sized Greenland iceberg.
It surfaced about 120 feet high or 40 meters high.
The video was shot in real time.
(Music) is like this iceberg, they show you different aspects of their personality.
Thank you.
(Applause)
Do you know how many medium - flowering plants there are?
There are 250,000 species - at least as many as we know - 250,000 medium - flowering plants.
And flowers are a nuisance.
It's really hard to get plants to breed.
It takes a lot of experience and a lot of resources.
Why is it so disturbing?
Of course, the answer is, like so many other things in the world, gender.
I know what's in your head when you look at these pictures.
The reason sexual reproduction is so important - plants have many other ways to reproduce.
It can be used in the form of cuttings; it can reproduce both sexes in the same plant; it can pollinate in the same plant.
But they do need to spread their genes and mix them with other genes so that they can live in the environment.
This is how evolution works.
Now the way plants transmit this information is through pollen.
Some of you may have seen these pictures before.
As I said, every home should have a scanning electron microscope that can see this.
There are as many different types of pollen as there are flowering plants.
This is actually quite useful for forensics and so on.
Most of the pollen that causes us to develop hay fever comes from plants that use the wind to spread pollen. This is a very inefficient process, which is why pollen always runs up our noses.
Because most of them are discarded, it is hoped that the germ cells contained in the pollen, the male germ cells, will happen to fall on another flower.
All grass, which means all grain, and most trees rely on the wind to spread pollen.
But most species actually use insects to do this, which is somewhat smarter because it doesn't require much pollen.
Insects and other species can carry pollen and transfer it directly to where it is needed.
Obviously, we notice the relationship between insects and plants.
This is a symbiotic relationship, and both birds and bees reap the rewards, usually in the form of nectar.
Sometimes this symbiotic relationship leads to wonderful adaptive changes - - the red - skirt moth is a beautiful adaptive change.
The plants were also harvested, and the sky spread the pollen elsewhere.
Plants have evolved to create landing runways everywhere, and bees can get lost in them.
Many plants have markings that look like other insects.
These are the pollen sacs of lilies, so ingenious that when an unsuspecting insect falls on them, the sacs flip over and hit the insect with a lot of pollen on its back, so that it can follow the insect to other plants.
There is an orchid that looks like it has a jaw. In a way, it does; it forces insects to crawl over, dabble in pollen, and carry it elsewhere.
Orchids: There are at least 20,000 species of orchids - an amazing variety.
They have all kinds of tricks.
They must try and attract pollinators to help them complete the process.
This orchid, known as Darwin's orchid because it was studied by Darwin and gave a wonderful prediction when he saw it, can be seen here with a long nectar tube hanging from the orchid.
Basically what the insect has to do is - we come to the middle of the flower - it pricks its mouthpiece into the middle part all the way down to the nectar tube to get the nectar.
Darwin said, looking at the flower, "I guess something has co - evolved with it."
Insects, no doubt.
When I mean, it's usually rolled up, but when it's straightened, it looks like this.
Now imagine that if something so valuable as nectar is costly for plants to produce and attracts many pollinators, then, as in human sexuality, people may begin to deceive each other.
They might say, "I have some nectar. Would you like to get some?"
This is a plant.
The plant is popular with insects in South Africa, which have evolved long mouthparts to get nectar from the bottom.
This is an impersonator.
This plant is imitating the former plant.
There was a fly with a long mouthpiece that didn't get any nectar from the impostor. Because the impostor didn't give it any nectar. It thought it could.
So not only does the fly not get nectar from the fake plant, but - - if you look very close to the top of the head, you will see that there is some pollen there that will be spread to other plants, if no botanist comes and sticks it to a blue card.
(Laughter) This lies all over the plant kingdom.
This flower with black dots: They may look like black dots to us, but I tell you, to a male insect of the right species, this looks like two very, very sexy females.
(Laughter) When the insect arrives and lands on it, it immerses itself in the pollen, which of course will be carried by it to other plants, and if you look at the scanning electron microscope images that every home should have, you can see that there are actually patterns there, three - dimensional patterns.
It even makes insects feel comfortable and looks good.
These electron microscope images - - this is an orchid masquerading as an insect - - you can see that to our eyes, different parts of the structure have different colors and different textures, and insects may be able to perceive very, very different textures.
The orchid evolved to mimic the metallic glossy surface seen on some beetles.
You can see this surface under a scanning electron microscope - - it's very different from other surfaces we've seen.
Sometimes the whole plant mimics an insect, even if it looks like an insect to us.
I mean, I think it looks like some kind of flying animal or beast.
It's a wonderful and magical thing.
This is the cleverness of it. It is called obsidian.
I think it can be cunning at times.
For the right kind of bee, this looks like another very aggressive bee, which will fly over and hit it with its head many, many times to try to get rid of it, and of course, this will get it stained with pollen.
Another thing it does is that the plant mimics another orchid that is rich in the food that insects love.
But there was nothing.
So it cheats on two levels - unbelievable.
(Laughter) What we see is ylang ylang, the strongly scented part.
I actually smelled it before.
These flowers don't really need to be so showy.
They emit a wonderful scent to attract any interested insect.
This flower doesn't smell very good.
This flower actually smells very bad to mention again, it's evolved and it looks like carrion.
So flies like it.
Flies fly in and help pollinate them.
This is the white star sea potato, also known as the dead horse sea potato.
I don't know what a dead horse smells like, but this flower probably smells like it.
It was terrible.
The green - headed fly can't help it.
Fly into it, fly all the way into it.
To lay eggs on it, thinking it was a good piece of carrion, not realising there was no food for the eggs, which would die here, but at the same time the plant would benefit as the hard - haired flies disappeared and pollinated to another flower - amazing.
This is the sea jelly plant, the sea jelly, the variegated arrowhead, known in this country as the longgrass.
I shot this last week in Dorset.
This guy heats up to about 15 degrees higher than the ambient temperature - incredible.
If you look inside it, behind the spike of meat is something a little like a dam, and flies are attracted to the heat - it's a boiling volatile chemical, small insects - and they are trapped under this container.
They drink the sweet nectar and then they all become a little sticky.
At night they are covered in pollen, sprayed on top of them, and then the hard hairs we see on top become wilted allowing these pollen - covered insects to escape - it's unbelievable.
If you think it's unbelievable, this one is my favorite.
This is spring plume and green velvet.
Everyone here from Brazil should know about this plant.
This is the most amazing thing.
Its stamens are about a foot long.
It has an ability that no other plant I know of has, and when it blooms - this is the spike of meat in the middle - for about two days, it produces some degree of metabolic change somewhat similar to that of mammals.
It doesn't have starch, it's plant food, it has something very similar to brown fat that burns it and metabolizes it at the rate of burning fat, about the speed of a kitten.
By weight, it's twice the energy output of a hummingbird - absolutely staggering.
It also did some unusual things.
Not only will it warm up to 155 degrees Fahrenheit, 43 or 44 degrees Celsius, for two days, but it will remain constant.
There is a temperature regulation mechanism to keep the temperature constant.
Why do you do this? I hear you ask.
Unbeknownst to you, some beetles like to mate at this temperature.
They dig in and are covered in pollen.
(Laughter) Plants scatter pollen all over them and let them go and pollinate.
What a wonderful thing it is.
Now we think that most pollinators are insects, but actually in the tropics, many birds and butterflies also pollinate.
Many tropical flowers are red, and this is because butterflies and birds are similar to us, and we think that we can see red very well.
But if you look at the spectrum, birds and us, we see red, green and blue see this spectrum.
Insects see green, blue and ultraviolet light. They can see all kinds of light and dark ultraviolet light.
There's still some color behind this.
"Wouldn't it be good if we could see those colors," I heard you ask.
Yes, we can see.
So what do insects see?
Last week I took pictures of these desert lotus, a half - day flower, in Dorset.
As we can see, these are little yellow flowers, and there are these little yellow flowers everywhere.
It looks like this in visible light.
If you remove the red it looks like this.
Most bees do not perceive red.
Then I put a UV filter in front of my lens and exposed it for a long time at a specific frequency of UV light to get this picture.
It's like a real, wonderful bull's - eye.
Now we don't know what the bees actually see, and when I call it red, you know what I'm looking at.
We can't know what's going on, whether it's in the brains of insects or other humans.
But the contrast probably looks like this. It's highlighted from the background.
This is another small flower - located in different UV frequency ranges, with different filters to match different pollinators.
It probably looks like that.
Lest you think that all yellow flowers have this property - no damage to the flower during the shoot; just stick it on a tripod and don't pick it off - under UV light, look at this.
This can be used as the basis for sunscreen, which works by absorbing ultraviolet light.
So perhaps the chemicals are of some use.
Finally, this is a nocturnal fragrance sent to me by Bjorn Rorslett of Norway - a wonderfully hidden pattern.
I like this way of hiding.
I thought it was poetic. The pictures were taken with ultraviolet filters, the main use of which astronomers use to photograph Venus - actually the clouds on Venus.
This is the main use of this filter.
Of course, Venus is the god of love and fertility, which is the story of flowers.
Just as flowers spend so much effort trying to attract pollinators to their invitation, somehow they also succeed in convincing us that there is something rich in it. We send flowers to each other at birth and death, especially at weddings, when you think of it, in that moment genetic material moves from one organism to another.
Thank you very much.
(Applause)
