I work on helping computers communicate about the world around us.
There are a lot of ways to do this, and I like to focus on helping computers to talk about what they see and understand.
Given a scene like this, a modern computer-vision algorithm can tell you that there's a woman and there's a dog.
It can tell you that the woman is smiling.
It might even be able to tell you that the dog is incredibly cute.
I work on this problem thinking about how humans understand and interact with the world.
The thoughts, memories and stories that a scene like this might evoke for humans.
All the interconnections of related situations.
Maybe you've seen a dog like this one before, or you've spent time running on a beach like this one, and that further evokes memories and thoughts of a past vacation, past times to the beach, times spent running around with other dogs.
One of my guiding principles is that by helping computers to understand what it's like to have these experiences, to understand what we share and believe and feel, then we're in a position to start evolving computer technology in a way that's complementary to our own experiences.
So, digging deeper into this, a few years ago I began working on helping computers generate human-like stories from sequences of images.
So, one day, I was working with my computer to ask it what it thought about a trip to Australia.
It took a look at the pictures, and it saw a koala.
It didn't know what the koala was, but it said it thought it was an interesting-looking creature.
Then I shared with it a sequence of images of a house burning down.
The computer took a look at the pictures and it said, " This is an amazing view! This is spectacular! "
It chills my back.
It saw a horrible, life-changing and life-destroying event and thought it was something positive.
I realized that the computer recognized the contrast between red and yellow and thought it was something worth commenting on positively.
And part of it was because most of the images I had given it were positive images.
That's because people tend to share positive images when they talk about their experiences.
When was the last time you saw a selfie at a funeral?
I realized that, as I worked on improving AI, it was task by task, dataset by dataset, that I was creating huge gaps, holes and blind spots in what the computer could understand.
And while doing so, I'm encoding all kinds of biases.
Biases that reflect a limited viewpoint, limited to a single dataset -- biases that reflect human biases like prejudice and stereotyping.
I thought back to the evolution of the technology that brought me to where I was that day -- the first color images were calibrated against a white woman's skin, meaning that color photography was biased against black faces.
And that same bias, that blind spot continued well into the' 90s.
The same blind spot persists even today in how well we recognize the faces of different people in facial recognition technology.
In research today, I think of state-of-the-art technology that tends to limit our thinking to one dataset and one problem.
And in doing so, we're creating more blind spots and biases that can be further amplified with AI.
I realized then that we had to think deeply about how the technology we invent today looks in five years, in 10 years.
Humans evolve slowly, with time to correct for problems in the interaction between humans and the environment.
In contrast, artificial intelligence is evolving at an incredibly fast rate.
And that means that it really matters that we think about this carefully right now -- that we reflect on our own blind spots, our own biases, and think about how that's affecting the technology we're creating and discuss what the technology of today will mean for tomorrow.
CEOs and scientists have weighed in on what they think about the future of artificial intelligence.
Stephen Hawking warns, " Artificial intelligence will destroy mankind. "
Elon Musk warns that it's an existential risk and one of the greatest risks that we face as a civilization.
Bill Gates put it, " I don't understand why people aren't more concerned about AI. "
But these views -- they're part of the story.
The math, the models, the basic building blocks of artificial intelligence are something that we can all access and use.
We have open-source tools for machine learning and machine learning that we can contribute to.
And beyond that, we can share our experiences.
We can share our experiences with technology and how it concerns us and how it excites us.
We can discuss what we love.
We can communicate with foresight about aspects of technology that could be more beneficial or could be more problematic over time.
If we all focus on opening up the discussion on AI with foresight towards the future, this will help create a general conversation and awareness about what AI is, what it can become and all the things that we need to do in order to achieve that outcome that best suits us.
We already see and know this in the technology we use today.
We use smart phones, digital assistants and vacuum cleaners.
Are they evil?
Maybe sometimes.
Are they beneficial?
Yes, they are, too.
They're not all the same.
And there you already see the light of the future.
The future continues on from what we build and create right now.
We activate the domino effect, which unlocks the evolutionary path of artificial intelligence.
In our time, we shape the artificial intelligence of tomorrow.
Technology that immerses us in augmented reality, bringing to life past worlds.
Technology that helps people to share their experiences when they have difficulty communicating.
Technology built on online visual media that can be used in self-driving cars.
Technology built on understanding images and generating language, evolving into technology that helps the visually impaired to have better access to the visual world.
We also see how technology can lead to problems.
We have technology today that analyzes physical characteristics we're born with -- such as the color of our skin or the look of our face -- to determine if we're criminals or terrorists.
We have technology that processes data, data about our gender or our race, to determine whether or not we can get a loan.
All that we see now is a snapshot of the evolution of artificial intelligence.
Because where we are now, is a moment in evolution.
That means that what we do now will affect what happens down the line and in the future.
If we want AI to evolve in a way that helps humans, then we need to define the strategies and goals that enable that path now.
What I'd like to see is something that fits well with human culture and the environment.
Technology that can help us heal people with neurological disorders or other disabilities, enabling them to make life equally challenging for everyone.
Technology that works regardless of your characteristics or the color of your skin.
What I focus on today is the technology for tomorrow and for 10 years from now.
AI can turn out in many different ways.
But in this case, it's not a self-driving car without any destination.
This is the car we're driving.
We choose when to speed up and when to slow down.
We choose if we need to make a turn.
We choose what the AI of the future will be.
There's a vast playing field of all the things that artificial intelligence can become.
It will become many different things.
Now it's up to us to figure out what we need to put in place to make sure the outcomes of artificial intelligence are the ones that will be better for all of us.
Thank you.
(Applause)
I want you all to consider for a moment the very simple fact that, by far, most of what we know about the universe comes to us from light.
We can stand on the Earth and look up at the night sky and see stars with our bare eyes.
The sun shines so brightly,
We can see light reflected back from the moon.
Ever since Galileo pointed that rudimentary telescope at the celestial bodies, the known universe has come to us through light.
And with the help of modern telescopes, we've been able to collect stunning silent images of the universe -- these series of images that go all the way back to the Big Bang.
But the universe is not a silent movie because the universe isn't really silent.
I'd like to tell you that the universe has a soundtrack and that the universe itself is playing on and off, because space can vibrate like a drum.
So it can ring out a sequence of sounds into the universe when something big happens.
Now, we want to be able to add sound to this magnificent visual composition of the universe.
And while we've never heard a sound from outer space, we should, within the next few years, be able to turn up the volume on what's going on out there.
So in this ambition to capture the sounds of the universe, we turn our focus to black holes and the promise they have, because black holes can bang on space-time like mallets on a drum and have a very characteristic sound, and I'd like to play for you some of our predictions.
We might one day see a shadow a black hole can cast on a very bright background, but we haven't yet.
And even though black holes aren't seen, they might be heard, and that's because they bang on space-time like a drum.
We owe the idea that space can ring like a drum to Albert Einstein, to whom we owe so much.
Einstein realized that if space were empty, if space were empty, it would look like this picture, except for the helpful grid drawn on it.
But if we were freely falling through the universe, even without this helpful grid, we would be able to paint it ourselves, because we would notice that we traveled along straight lines, undeflected straight paths through the universe.
Einstein also realized -- and this is the real meat of the matter -- that if you put energy or mass in the universe, it would curve space, and a freely falling object would pass by, let's say, the Sun and it would be deflected along the curves in the space.
This was Einstein's great general theory of relativity.
Even the paths of light can be bent.
And when you're bent so much that you're in orbit around the Sun, it's like the Earth around the Sun, the Moon around the Earth.
These are the natural curves in the universe.
But Einstein did not realize that if you took our Sun and you crushed it down to six kilometers -- so you took a million times the mass of the Earth and you crushed it to six kilometers across, you would make a black hole, an object so dense that if light veered too close, it would never escape -- a dark shadow against the universe.
But Einstein always thought black holes were a mathematical oddity.
He didn't believe in black holes.
He believed that nature would protect us from their formation.
It was decades before the term " black hole " was coined and people realized that black holes are real astrophysical objects -- in fact, they're the death state of very massive stars that collapse catastrophically at the end of their lifetime.
Our Sun will not collapse to a black hole.
It's actually not massive enough.
But if we did a little thought experiment -- as Einstein was very fond of doing -- we could imagine putting the Sun crushed down to six kilometers, and putting a tiny little Earth around it in orbit, maybe 30 kilometers outside of the black-hole sun.
And it would be self-illuminated, because now the Sun's gone, we have no other source of light -- so let's make our little Earth self-illuminated.
And you might find that you could put the Earth in a happy orbit even 30 kilometers outside of the black hole.
This black hole is actually about the size of Manhattan.
And before it destroyed the Earth, it might swell up into Hudson Avenue.
But basically that's what we're talking about.
We're talking about an object that's compressed down to half the size of Manhattan.
So we move this Earth very close -- 30 kilometers outside -- and we notice it's perfectly fine orbiting around the black hole.
There's a sort of myth that black holes devour everything in the universe, but you actually have to get very close to fall in.
But what's very impressive is that, from our perspective, we can always see the Earth.
It cannot hide behind the black hole.
And of the light from the Earth, some of it falls into the black hole, and some of it gets bent and brought to us.
So you can't hide anything behind a black hole.
If this were Battlestar Galactica and you're fighting the Cylons, don't hide behind the black hole.
They can see you.
Our Sun will not collapse to a black hole; it's not massive enough, but there are tens of thousands of black holes in our galaxy.
And if one were to devour the Milky Way, this is what it would look like.
We're going to see a shadow of a black hole on the hundreds of billions of stars in the Milky Way and on the star-illuminated dust lanes.
If we were to fall towards this black hole, we would see light refracted around it, and we would even start to cross into this shadow and not notice that anything dramatic had happened.
It would be bad if we tried to fire the rockets and get out of there, because we couldn't, not even light.
Although the black hole is dark from the outside, it's not dark on the inside, because all the light from the galaxy can fall in with us.
And even though, due to the relativistic effect of time dilation, our clocks seem to slow down relative to galactic time, it looks as if the evolution of the galaxy was accelerating, right before we were destroyed by the black hole.
It's like a near-death experience where you see the light at the end of the tunnel, but it's a complete death experience.
(Laughter) There's no way of telling anyone you saw light at the end of the tunnel.
So far, we've never seen a shadow like this of a black hole, but black holes can be heard, even if they're not seen.
Imagine, in an astronomical reality -- imagine two black holes that have been together for a long time.
Maybe they started as stars and collapsed to two black holes -- each one 10 times the mass of the Sun.
Now we're going to crush them down to 60 kilometers.
They can spin hundreds of times a second.
At the end of their lives, they're approaching each other at the speed of light.
They travel thousands of kilometers in a fraction of a second, and as they do so, they not only curve space, but they leave behind in their wake a ringing of space, an actual wave on space-time.
Space is squeezed and stretched as black holes collide with the universe.
These vibrations travel through space at the speed of light.
This computer simulation was done by the relativity group at NASA Goddard.
It took almost 30 years before and after solving this problem.
This is one of the groups.
It shows two black holes in orbit around each other, and these are imaginary curves.
And as you can see -- it's kind of fuzzy -- you can see the red waves emanating out, and these are the gravitational waves.
They're literally the sounds of space ringing that will travel out from these black holes at the speed of light as they merge, until the two black holes merge into one spinning, quiet black hole.
If you were standing close enough, your ear would resonate with the squeezing and stretching of space.
You can really hear it with your own ear.
Of course, you'll notice helplessly that your head is squeezed and stretched, too, so you might have trouble understanding what's going on.
But I'd like to play for you the sound we predict.
This is from my group -- a rather sketchy computational model.
Imagine a lighter black hole falling into a more massive black hole.
The sound you're hearing is the light black hole colliding with space as it gets close.
And if they're far away, they're very quiet.
But gradually it becomes like a mallet that beats space, and it vibrates like a drum.
We can predict what the sound will be.
We know that, as it falls, it gets faster and it gets louder.
And eventually, we're going to hear the little one fall into the bigger one.
I've never heard it that loud -- it's actually amplified here.
At home, it sounds kind of anticlimactic.
It sounds like ding, ding, ding.
This is another sound from our group.
I'm not going to show you the images, because black holes don't leave any useful trails, and real space doesn't show you the curves.
But if you're on a space vacation and you hear that, I suggest you run.
(Laughter) You'd better get away from the sound.
Both black holes are moving.
The two black holes are getting closer together.
In this case, they're both wobbling violently.
And then they're going to merge.
That chirp is the hallmark of black holes merging -- that chirp at the end.
This is our prediction of what we will see.
Luckily we're safe in Long Beach, California.
And surely, somewhere in the universe two black holes have merged.
And surely, the space around us is feeling these vibrations that travel a million light years, or a million years ago, at the speed of light to get to us.
But it's too loud for us to ever hear.
There are very industrious experiments being built on Earth -- one called LIGO -- that will detect the vibrations of space at less than the fraction of a nucleus of an atom over four kilometers.
It's a very ambitious experiment, and it's going to be at advanced sensitivity within the next few years -- to detect vibrations in space.
Another research project on the universe is expected to start within the next decade, called LISA.
And LISA will be able to see super-massive black holes -- black holes millions or billions of times the mass of the Sun.
In this Hubble image, we see two galaxies.
They look like they're in a quiet embrace.
And each one probably has a super-massive black hole at its core.
But they're not stationary; they're actually merging.
These two black holes will collide, and they will merge over a billion-year period.
So it's beyond our human perception to pick up the sounds they make.
But LISA could see the final stages of two super-massive black holes merging long ago, the last 15 minutes before they merge.
And it's not just black holes, but it's also any big disturbance in the universe -- the biggest of which is the Big Bang.
When the term was coined, it was derisive -- " Oh, who would believe in the Big Bang? "
This animation from my friends at Proton Studios shows looking at the Big Bang from the outside.
We never really want to do that; we want to be inside the universe because there's no such thing as being outside the universe.
So imagine you're in the middle of the Big Bang.
The universe is everywhere, everything is around you, and space is wobbling in disorder.
Fourteen billion years pass and the sound is still ringing all around us.
Galaxies form, and hordes of stars form in the galaxy, and on one planet, at least one, habitable planet.
Here, we're frantically building experiments, doing calculations, writing computer code.
Imagine a billion years ago, two black holes collided.
It's been ringing through space all the time.
We weren't even here.
It gets closer and closer -- 40,000 years ago, we're still painting on the walls of caves.
If it was the Big Bang we were going to pick up, it would sound like this.
It's literally noise.
It's white noise, a chaotic ringing.
But it's around us everywhere, if only it hasn't been wiped out by some other process in the universe.
And if we pick it up, it will be music to our ears because it will be the quiet echo of that moment of our creation, of our observable universe.
So within the next few years, we'll be able to turn up the soundtrack a little bit and present the universe in audio.
But if we detect those earliest moments, it'll bring us a step closer to understanding the Big Bang, where we can ask some of the hardest, most elusive, questions.
And if we play the universe backwards, we know there was a Big Bang in the past, and we might even hear the cacophonous sound of it, but was our Big Bang the only Big Bang?
I mean we have to ask, has it happened before?
Will it happen again?
I mean, if we take this question to the level of TED's advocacy for rethinking, we can ask questions, at least for this last minute, that really might never answer.
But we have to ask: Is it possible that our universe is just a plume off of a greater history?
Or, is it possible that we're just a branch off of a multiverse -- each branch with its own Big Bang in its past -- maybe some of them with black holes playing drums, maybe some without -- maybe some with sentient life, and maybe some without -- not in our past, not in our future, but somehow connected to us?
So we have to wonder, if there's a multiverse, in some other patch of that multiverse, is there life?
These are creatures in our multiverse.
Are there other creatures in the multiverse, wondering about us and wondering about their own origins?
And if they are, I can imagine them as we are, calculating, writing computer code, building instruments, trying to detect that faintest sound of their origins and wondering who else is out there.
Thank you. Thank you.
(Applause)
One winter morning, a few years ago, I was driving to work in Johannesburg, South Africa, and noticed a haze hanging over the city.
I drive by almost every day, but this time it's unusual that I've never seen anything like this before.
Johannesburg is known for its distinctive skyline, which I could barely see that morning.
It didn't take long for me to realize that I was looking at an enormous cloud of air pollution.
The contrast between the beautiful environment I knew and this haze-covered skyline reverberated within me.
I was afraid it would be possible that the once colourful sunsets would be swallowed up by a dark haze.
At that moment, I felt an urge to do something, but I didn't know what.
All I knew was I couldn't just stand idly by.
The big challenge was, I didn't know much about environmental science air-quality management or atmospheric chemistry.
I am a computer engineer, and I was pretty sure I couldn't code my way out of this air pollution problem.
(Laughter) Who was I going to do anything about this?
I'm just a citizen.
In the following years, I learned a very important lesson, a lesson we all need to take to heart if we are to work towards a better future.
Even if you're not an expert in a particular field, your expertise may hold the key to solving problems in that field.
Sometimes the unique perspective you have can lead to unconventional thinking that can shape the situation, but you need to be bold enough to try.
Only then will you know the outcome.
What I knew then was that if I was going to try to make a difference, I had to get smart about pollution first, so I became a student again.
I did some basic research and soon learned that air pollution is the world's biggest environmental health risk.
Data from the World Health Organization shows that almost 14 percent of all deaths worldwide in 2012 were attributable to household and ambient air pollution, with most occurring in low- and middle-income countries.
Air pollution causes more deaths each year than malaria and AIDS.
In Africa, premature deaths from unsafe sanitation or childhood malnutrition pale in comparison to deaths from air pollution, and it comes at a huge economic cost: over 400 billion US dollars in 2013, according to the Organisation for Economic Cooperation and Development.
In my work, I explore new frontiers in artificial intelligence, where the symbiotic relationship between humans and machines can find a beneficial footing and help us make better decisions.
As I thought about the air pollution problem, it became clear that we needed to find a way to make better decisions about how we manage air pollution, and given the scale of the problem, it was necessary to collaborate.
So I decided to get to know some people working in the field.
I started talking to officials from Johannesburg and other surrounding cities, and I engaged the local scientific community, and I made a few cold calls.
The engagement I embarked upon helped me to develop a deeper understanding of the problem.
It also helped me to avoid the trap that people in my profession sometimes fall into when trying to innovate: to quickly adopt a technology before you've really grasped the problem.
I began to wonder what I could do to improve the situation.
I started by asking myself how I could effectively combine my skills in software engineering and artificial intelligence with the expertise of the people I'd reached out to.
I wanted to create an online air-quality management platform that would uncover trends in pollution and make predictions about what might happen.
I was confident that my idea would translate into a practical solution, but I faced uncertainty and had no guarantee of success.
What I had was a very particular set of engineering skills, skills I'd acquired over my career (Laughter) that were new to people who had been working on air pollution for so many years.
I have come to realize that sometimes one fresh perspective, one new skill set, can lead to something remarkable.
Our willpower and imagination are a guiding light that guides us through obstacles and opens new chapters.
Having developed a deeper understanding of the air pollution problem, and having found data on air pollution for over a decade, and meteorological data for in and around Johannesburg, my colleagues from South Africa and China and I created an air-quality decision support system uploaded to the cloud.
This software analyzes historical and real-time data to uncover spatial and temporal trends in pollution.
We then used new machine learning technology to predict future levels of pollution days in advance.
This means that residents can make better decisions about their daily movements and about where to settle their families.
We can predict adverse pollution events ahead of time, identify heavy polluters, and the relevant authorities can direct them to scale back their operations.
Through assisted scenario planning, city planners can also make better decisions about how to extend infrastructure, such as human settlements in industrial zones.
We've built a pilot of this technology over a period of 120 days, covering all of South Africa.
Our results were confirmed when we demonstrated a tight correlation between the forecasting data and the data we were getting on the ground.
Through our leadership, we have brought cutting-edge, world-leading assets that can perform air-quality forecasting at an unprecedented resolution and accuracy, benefiting the city that I drove into one winter morning not very long ago, and thought to myself, " Something is wrong here. I wonder what can be done? "
So the point is: What if I hadn't investigated the air pollution problem further?
What if I didn't pay attention to the state of the environment in my country and hoped that someone, somewhere, was taking care of the matter?
What I have learned is that, when embarking on a challenging endeavor that advances a cause that we firmly believe in, it is important to focus on the possibility of success and consider the consequences of not acting.
We should not get distracted by opposition and resistance; it should motivate us further.
So wherever you are in the world, the next time you find that there's some natural curiosity you have that is being piqued, and it's about something you care about, and you have some crazy or bold ideas, and even if it's outside the realm of your expertise, ask yourself this: Why not?
Why not just go ahead and tackle the problem as best as you can, in your own way?
You may be pleasantly surprised.
Thank you.
(Applause)
Many people think that driving is something that only those who can see can do.
A blind person driving a car safely and independently was considered an impossible task until now.
Hello, my name is Dennis Hong, and we're bringing freedom and independence to the blind by building a car for the visually impaired.
So before I talk about this car for the blind, let me briefly tell you about another project I worked on called the DARPA Urban Challenge.
This is about building a robotic car that can drive itself.
You press start, it doesn't touch anything anymore, and it can reach its destination fully autonomously.
At the 2007 Challenge, our team won half a million dollars and finished third in the competition.
About that time, the National Federation of the Blind, or NFB, challenged the design team about who can develop a car that lets a blind person drive safely and independently.
We decided to give it a try, because we thought, " Hey, how hard could it be? "
We already have an autonomous vehicle.
We just put a blind person in it and we're done, right?
(Laughter) We couldn't have been more wrong.
What NFB wanted was not a car that can drive a blind person around, but a car where a blind person can make active choices and drive.
So we had to give up everything we had and start from scratch.
To test this crazy idea, we developed a small dune buggy prototype vehicle to test the feasibility.
In the summer of 2009, we invited a lot of blind youth from all over the country and gave them a chance to take it for a spin.
It was an absolutely amazing experience.
But the problem with this car was it was designed to only be driven in a very limited environment, in a closed-off parking lot -- even the lanes of red traffic cones.
So with this success, we decided to take the next big step, to develop a real car that can be driven on real roads.
So how does it work?
Well, it's a rather complex system, but let me explain it, simplify it.
We have three stages.
We have perception, computation and non-visual interfaces.
The driver is obviously out of sight, so the system has to perceive the environment and gather data for the driver.
For this, we use an initial measurement unit.
It measures acceleration, angular acceleration -- like a human ear, inner ear.
I combined that information with the Global Positioning System (GPS) to predict the location of the vehicle.
We also use two cameras to detect the lanes of the road.
We also use three laser range finders.
The lasers scan the environment to detect obstacles -- a vehicle approaching from the front, the back and also any obstacles that run into the road, any obstacles around the vehicle.
All this vast amount of information is then fed into the computer, and the computer can do two things.
One is, first of all, process the information to understand the environment -- which are the lanes of the road, which are the obstacles -- and convey that information to the driver.
The system is also smart enough to figure out the safest way to drive.
We can also issue instructions on how to operate the procedures of the vehicle.
But the question is: How do we convey information and instructions to a blind person fast enough and accurate enough to make sure he can drive?
So for this, we developed many different types of non-visual user interface technology.
So starting with a three-dimensional ping sound system, a vibrating vest, a voice-controlled gear, a leg strip, even a shoe that puts pressure on the foot.
But today we're going to talk about three of these non-visual user interfaces.
The first interface is called a DriveGrip.
These are a pair of gloves, and it has vibrating elements on the knuckle part so you can convey instructions about how to steer -- the direction and the intensity.
Another device is called SpeedStrip.
This is a chair -- actually, it's a massage chair.
We take it apart, and we rearrange the vibrating elements in different patterns, and we use them to convey information about the speed, and also instructions how to use the gas and the brakes.
And here you can see how the computer understands the environment, and because you can't see the vibration, we actually put red LED's on the driver so he can see what's happening.
This is the sensory data, which is transferred from the sensor to the computer.
So these two devices, DriveGrip and SpeedStrip, are very effective.
But the problem is these are instructional cue devices.
So it's not really freedom, right?
The computer tells you how to drive -- turn left, turn right, speed up, stop.
I call this the co-driver problem.
So we're moving away from instructional cue devices and focusing more on informational devices.
A good example of this informational non-visual interface is called AirPix.
Think of this as a monitor for the blind.
It's a small desktop, has a lot of holes in it, and compressed air comes out, so it can paint a picture.
So even if you're blind, you put your hand over it, you can sense the lanes and obstacles.
Actually, you can also change the frequency of the air coming out and possibly the temperature.
This is actually a multi-dimensional user interface.
Here, you can see the left and right cameras and how the computer interprets and sends that information to the AirPix.
So for this, we're showing a simulator, a blind person driving using AirPix.
This program was very useful for training blind drivers and quickly testing different theories for different types of non-visual user interfaces.
So basically that's how it works.
But this is a model car, and it won't be on the road unless it proves to be as safe to drive as today's cars, or safer.
I was really convinced that it would happen.
But will society, will they accept this radical idea?
How are we going to handle insurance?
How are we going to issue driver's licenses?
There are many different kinds of hurdles behind the technology challenge that we need to address before it becomes a reality.
Of course, the main goal of this project is to develop a car for the blind.
But potentially more important than that is the tremendous value of the spin-off from this project.
Sensors that can be used to see through the dark, the fog and rain.
And together with this new type of interfaces, we can use these technologies and apply them to safer vehicles for sighted people.
Or for the blind, everyday home appliances -- educational facilities, office applications.
Just imagine, in a classroom a teacher writes on the blackboard and a blind student can use these non-visual interfaces to see and read what the teacher is writing.
This is extremely precious.
Today, the things I've shown you today, is just the beginning.
Thank you very much.
(Applause)
As an artist, connection is very important to me.
Through my work I'm trying to make it clear that humans are not separate from nature and that everything is interconnected.
I first went to Antarctica about 10 years ago, and I saw my first icebergs.
I was in awe.
My heart beat fast, my head was dizzy, trying to understand what it was that stood in front of me.
The icebergs around me were almost 200 feet out of the water, and I could only help but wonder that this was one snowflake on top of another snowflake, year after year.
Icebergs are formed when they break apart from glaciers or break apart from ice shelves.
Each iceberg has its own individual personality.
They have a distinct way of interacting with their environment and their circumstances.
Some refuse to give in and hold on to the end, while others can't stand to crumble in a fit of intense passion.
It's easy to think, when you look at an iceberg, that they're isolated, that they're separate, alone, much like we as humans sometimes think of ourselves.
But the reality is much more than that.
As an iceberg melts, I breathe in its ancient smell.
As the iceberg melts, it releases mineral-rich fresh water that nourishes all things.
I set out to photograph these icebergs as if I was making portraits of my ancestors, knowing that in these individual moments they exist in that way and will never exist that way again.
It is not a death when they melt; it is not an end, but a continuation of their path through life.
Some of the ice in the icebergs I photograph is very young -- a couple thousand years old.
Some of the ice is over 100,000 years old.
The last pictures I'd like to show you are of an iceberg I photographed in Kekertsuatsiak, Greenland.
It's a very rare occasion that you get to actually witness an iceberg rolling.
So here it is.
On the left you can see a small boat.
This is a boat of about 15 feet.
I'd like you to pay attention to the shape of the iceberg and how it deforms on the water.
And here you see it starts to roll, and the boat moves to the other side, and the man is standing there.
This is an average-size Greenlandic iceberg.
It's about 120 feet above the water, or 40 meters.
This video was shot in real time.
(Music) And just like this iceberg, they're showing you a different side of their personality.
Thank you.
(Applause)
Do you know how many species of flowering plants there are?
There are a quarter of a million -- at least those are the ones we know about -- a quarter of a million species of flowering plants.
And flowers are a real bugger.
It's really difficult for plants to produce.
It takes a lot of experience and a lot of resources.
Why would it bother you so much?
The answer, of course, is, like so many things in the world, sex.
I know what's on your mind when you look at these pictures.
And the reason that sexual reproduction is so important -- there are many other ways that plants can reproduce.
You can take cuttings; they can have sex with themselves; they can pollinate themselves.
But they really need to spread their genes to mix with other genes so that they can be eco-friendly.
Evolution works that way.
Now the way that plants transmit that information is through pollen.
Some of you may have seen these pictures before.
As I say, every home should have a scanning electron microscope that can see these things.
There are as many different types of pollen as there are flowering plants.
And that's actually pretty useful for forensics and so on.
Most pollen that causes hay fever for us is from plants that use the wind to spread the pollen, and that's a very inefficient process, which is why it gets up our noses so much.
Because most of it gets dumped in the hope that the germ cells contained in the pollen, the male germ cells, will just happen to fall on another flower.
All the grasses, which means all the cereals, and most of the trees have wind-borne pollen.
But most species actually use insects to do their bidding, and that's smarter in a way, because they don't need much pollen.
Insects and other species can take the pollen and transfer it directly to where it's needed.
Obviously, we're aware of the relationship between insects and plants.
It's a symbiotic relationship, whether it's a bird or a bee, they get something in return, usually nectar.
Sometimes this symbiosis leads to fantastic adaptations -- the hummingbird hummingbird is a beautiful adaptation.
The plant gets something, too, and it spreads the pollen somewhere else.
Plants have evolved to create landing strips everywhere where bees might get lost.
There are markings on many plants that look like other insects.
These are the anthers of a lily, cleverly done so that when the unsuspecting insect lands on it, the anther flips up and whops it on the back with a lot of pollen that it can follow to another plant.
There's an orchid that might look like it has jaws, and in a way, it does; it forces the insect to crawl over, getting covered in pollen that it takes somewhere else.
Orchids: There are at least 20,000 species of orchids -- amazingly diverse.
They have all sorts of tricks.
They have to try and attract pollinators to help them through the process.
This orchid, known as Darwin's orchid, because it's one that Darwin studied and made a fantastic prediction when he saw it -- you can see that there's a very long nectar tube that descends down from the orchid.
And basically what the insect has to do -- we're in the middle of the flower -- it has to stick its proboscis into the middle all the way down to the nectar tube to get to the nectar.
Darwin said, looking at this flower, " I guess something has coevolved with it. "
And sure enough, they're insects.
I mean, normally it rolls up, but when it straightens out, that's what it looks like.
Now you can imagine that if nectar is such a valuable thing and expensive for the plant to produce and it attracts lots of pollinators, then, just as in human sex, people might start to deceive.
They might say, " I have some nectar. Do you want to get it? "
This is a plant.
This is a plant that insects in South Africa love, and they've evolved with a long proboscis to get the nectar at the bottom.
This is an imitator.
This plant is mimicking the first plant.
There's a long-billed fly that doesn't get any nectar from the impersonator, because the impersonator doesn't give it any nectar. It thought it would get it.
So not only has the fly not got the nectar from the dummy plant, it's also -- if you look very closely just at the head end, you can see that it's got a bit of pollen that it would be transmitting to another plant, if only some botanist hadn't come along and stuck it to a blue card.
(Laughter) This lies all over the plant kingdom.
This flower with its black dots: they might look like black dots to us, but let me tell you, to a male insect of the right species, it looks like two females who are really, really sexy.
(Laughter) And when the insect gets there and lands on it, dousing itself in pollen, of course, that it's going to take to another plant, if you look at the every-home-should-have-one scanning electron microscope picture, you can see that there are actually some patterning there, which is three-dimensional.
It even feels good for the insect, and it looks good.
And these electron microscope images -- here's an orchid masquerading as an insect -- you can see that different parts of the structure have different colors and different textures to our eye, and an insect might perceive very, very different textures.
This orchid has evolved to mimic the glossy metallic surfaces you see on some beetles.
And you can see the surface under the scanning electron microscope -- very different from the other surfaces we looked at.
Sometimes the whole plant mimics an insect, even to us.
I mean, I think it looks like some sort of flying animal or beast.
It's a wonderful, amazing thing.
And that's what makes it smart. It's called obsidian.
I think it's tricky sometimes.
To the right species of bee, this looks like another very aggressive bee, and it will come and bang it on the head lots and lots of times, trying to drive it away and, of course, covering it with pollen.
The other thing it does is that this plant mimics another orchid that has a lot of food for insects.
But there's nothing.
So it's deceiving on two levels -- fabulous.
(Laughter) What we see is ylang ylang, the fragrant part.
I actually smelt it before.
These flowers don't really have to be that showy.
They give off a wonderful scent that appeals to any insect that has an interest.
This one doesn't smell so good.
This is a flower that actually smells really nasty, and again, it's evolved, and it looks like carrion.
So flies love it.
The flies fly in and they pollinate.
This is white starfish arum, also known as dead horse arum.
I don't know what a dead horse smells like, but this one probably smells pretty much like it.
It was horrible.
Green-headed flies can't help themselves.
Fly into it, fly all the way into it.
They lay their eggs in it, thinking it's a nice bit of carrion, and not realizing that there's no food for the eggs, that the eggs are going to die, but the plant, meanwhile, has benefited, because the bristles release and the flies disappear to pollinate the next flower -- fantastic.
This is arum, arum maculatus, or arum maculatus in this country.
I photographed this thing last week in Dorset.
This guy heats up by about 15 degrees above ambient temperature -- amazing.
And if you look inside, behind the spadix is something a bit like a dam, flies get attracted by the heat -- which is boiling off volatile chemicals, little bugs -- and they get trapped underneath this container.
They drink a lot of sweet nectar and then they all get a little sticky.
At night they get covered in pollen, which showers down over them, and then the bristles we saw above, they wilt and allow these little pollen-covered insects to escape -- fabulous thing.
And if you think it's fabulous, this is one of my favorites.
This is the green velvet of spring feathers.
For anyone here from Brazil, you should know about this plant.
This is the most amazing thing.
Its stamens are about a foot long.
It has an ability that no other plant that I know of has, and that when it's in full bloom -- that's the spadix in the middle -- for a period of about two days, it metabolizes in a way that is somewhat similar to mammals.
And instead of having starch, which is the food of plants, it has something very similar to brown fat and burns it at such a rate that it burns fat, metabolizing, about the rate of a small cat.
That's twice the energy output, weight for weight, than a hummingbird -- absolutely amazing.
And it does something unusual.
Not only will it raise itself to 155 Fahrenheit, 43 or 44 degrees Celsius, for two days, but it keeps constant temperature.
There's a thermoregulation mechanism in there that keeps constant temperature.
Why do you do this? I hear you ask.
Now you don't know it, there's some beetles that just love to mate at that temperature.
They get inside, and they get covered in pollen.
(Laughter) And the plant sprinkles them with pollen and lets them go and pollinate.
What a wonderful thing it is.
Now we think most pollinators are insects, but actually in the tropics, many birds and butterflies pollinate.
Many of the tropical flowers are red, and that's because butterflies and birds see similarly to us, we think, and can see red very well.
But if you look at the spectrum, birds and us, we see red, green and blue and see that spectrum.
Insects see green, blue and ultraviolet, and they see various shades of ultraviolet.
There's some color behind that.
" And wouldn't it be great if we could see those colors, " I hear you ask.
Yes, we can.
So what is an insect seeing?
Last week I took these pictures of rock rose, helianthemum, in Dorset.
These are little yellow flowers, as we all see, little yellow flowers all over the place.
This is what it looks like with visible light.
This is what it looks like if you take out the red.
Most bees don't perceive red.
And then I put ultraviolet filters on my camera and took a very long exposure at certain frequencies of ultraviolet light, and that's what I got.
It's like a real fantastic bull's eye.
Now we don't know exactly what a bee sees, or you know what I'm seeing when I call this red.
We don't know what's going on in there, be it an insect's or another human being's mind.
But the contrast will look something like that, so stand out from the background.
Here's another little flower -- different range of ultraviolet frequencies, different filters to match the pollinators.
And that's what it looks like.
And lest you think that all yellow flowers have this property -- no flower was damaged in the process of this shot; it was just attached to the tripod, not removed -- under ultraviolet light, look at this.
This can be the basis of a sunscreen because sunscreens work by absorbing ultraviolet light.
So maybe the chemical in there might be something useful.
Finally, there's one of evening primrose that Bjorn Rorslett from Norway sent me -- fantastic hidden pattern.
I love the way it's hidden.
I think it's poetic that these pictures are taken with ultraviolet filters, the main use of that filter is for astronomers to take pictures of Venus -- actually the clouds of Venus.
This is the main use of this filter.
Venus, of course, is the god of love and fertility, which is the flower story.
And just as flowers spend a lot of effort trying to get pollinators to do their bidding, they've also somehow managed to convince us that they're so rich that we send flowers to each other at times of birth and death, and especially at marriage, which, when you think of it, is the moment that encapsulates the transfer of genetic material from one organism to another.
Thank you very much.
(Applause)
