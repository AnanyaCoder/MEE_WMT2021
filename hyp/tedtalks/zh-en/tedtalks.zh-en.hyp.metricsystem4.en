I am committed to helping computers communicate with the world around us.
There are many ways to do this, and I like to focus on helping computers talk about what they see and understand.
Given this scenario, a modern computer vision algorithm can tell you that there's a woman and a dog.
It can tell you that the woman is smiling.
It can even tell you that this dog is very cute.
I deal with this problem thinking about how humans understand and live with the world.
Those thoughts, memories, and stories in scenes like this, might arouse human attention.
all interrelationships.
Maybe you've seen a dog like this before, or you've spent time running on a beach like this and further evoked memories and thoughts from past vacations, when you used to go to the beach and spent time running around with other dogs.
One of my guiding principles is that by helping computers understand what kind of experience this is, and thus understand what we believe and feel in common, then we have the ability to start evolving computer technology in a way that complements our experience.
So, digging deeper into this, I started working on helping computers generate human-like stories a few years ago, from image sequences.
So, one day, while I was working on my computer, I asked it about my trip to Australia.
He looked at the picture and saw a koala.
It doesn't know what a koala is, but the computer says it thinks a koala looks like an interesting creature.
Then I shared a series of images with the computer of a burning house.
The computer looked at the picture and it said, "This is an amazing view! It's spectacular!"
It sent chills down my spine.
The computer sees a horrific, life-changing and life-destroying event and thinks it's a positive thing.
I realized that the computer recognizes the contrast between red and yellow, and thinks it's something to be positively evaluated.
Part of the reason is because most of what I input into the computer is positive images.
That's because people tend to share positive images when they talk about their experiences.
When was the last time you saw a selfie at a funeral?
I realized that in the process of improving AI, it's task-by-task and dataset-by-dataset, creating huge gaps, flaws and blind spots in computer understanding.
While doing this, I'm coding for various biases.
Prejudice reflects a limited perspective that comes from a data set -- and it reflects the same human things, like stereotypes and stereotypes.
I think back to the development of that technology that got me to where I was that day -- the first color image was calibrated for the skin color of a white woman, which meant that color photography was biased against blackface.
And that same bias, that blind spot carried over into the 1990s.
The same blind spot, even today, still exists in the application of facial recognition technology, how to identify the faces of different people.
In today's research, I think of state-of-the-art techniques that tend to limit our thinking to one dataset and one problem.
And in doing so, we're creating more blind spots and biases that will be further amplified when using AI.
That's when I realized we had to think about how we're going to invent and create technology today, and how we're going to be seen five to 10 years from now.
In human interaction with the environment, humans take time to correct problems, so evolution is slow.
Artificial intelligence, by contrast, is advancing at an incredible rate.
And that means it's really important, and we're going to have to think about this now -- to reflect on our blind spots and our biases, and to think about how those biases affect the technology we're creating now, and to talk about what today's technology means for the future.
CEOs and scientists, have weighed their ideas about the future of AI.
Stephen Hawking warned: “Artificial intelligence will kill humanity.”
Elon Musk warns that this is an existential risk, and one of the biggest risks we face as a civilized society.
Bill Gates said, “I don’t see why people aren’t more worried about AI.”
But these views -- are only part of the story.
The math, the models, the basic building blocks of artificial intelligence, that we can all get and use.
We have open-source tools for learning machines and making our own contributions at the same time.
In addition, we can also share our experience.
We can share about technology and how it's related to us and how we're excited.
We can discuss what we love.
We can communicate with the foreseeable future, which may be more beneficial on the technical side, or more problems may arise over time.
If we all focus on opening up conversations about AI and looking to the future, it will help create a regular conversation and awareness about what AI is, what it can become, and all the things we need to do to achieve the outcomes that are best for us.
We have seen and understood this in the technologies used today.
We use smartphones, digital assistants and automatic vacuum cleaners.
Are they evil?
Maybe sometimes it is.
Are they beneficial?
Yes, they are.
They are not exactly the same.
There you have seen the light of the future.
The future will continue to start with what we build and create now.
We started the domino effect, which opened up the evolutionary path of AI.
In our time, the artificial intelligence of tomorrow is shaped.
Let us immerse ourselves in the technology of augmented reality, resurrect the world of the past,
When people have trouble communicating, technology helps them share their experiences with each other.
Technologies built on online visual media can be used for autonomous vehicle driving.
Technology, which generates language based on image understanding, can evolve into technology that assists the visually impaired, helping them better own the visual world.
We also see how technology can cause some problems.
We have technology today that analyzes the physical characteristics of our birth -- like the color of our skin or the expression on our faces -- to determine if we're criminals or terrorists.
We have the technology to process data, to process data about gender or race to determine if we can get a loan.
Everything we see now is just a snapshot of the evolution of AI.
Because where we are now, it's a moment of evolution.
This means that what we do now will affect how things will go down the road and into the future.
If we want AI to help us evolve the way humans do, we need to define strategies and goals, and open that path right away.
What I want to see is the direction of the development of culture and environment suitable for human beings.
Technology can help us heal people with neurological disorders or other disabilities, and make life as challenging as everyone else.
Technology doesn't work with your features or skin color.
I'm focused today on the technology of tomorrow and ten years from now.
Artificial intelligence can emerge in many different ways.
But in this case, it's not a driverless car without any destination.
This is a car we can drive and control at the same time.
We choose when to speed up and when to slow down.
We choose whether or not to turn.
We choose what the future of artificial intelligence will be.
There will be a vast arena where AI can be everything.
It will become a lot of different things.
Now it's up to us to figure out what needs to be implemented to make sure that the outcome of AI is better for all humans.
Thank you.
(applause)
I want you to take a moment to consider the very simple fact that most of what we know about the universe so far has come from light.
When we stand on the earth and look up at the night sky, we can see the stars in the sky.
The strong sunlight is so dazzling,
We can see the light reflected from the moon.
Ever since Galileo pointed his humble telescope at the celestial bodies in the universe, the universe as we know it today is presented to us through light.
With the help of modern telescopes, we've been able to collect dazzling, silent images of the universe -- a series of images that go all the way back to the Big Bang.
However, the universe is not a mime, because the universe is not really silent.
I want to tell you that the universe has its own soundtrack, and the universe itself is constantly playing, because space can vibrate like a drum.
So when something big happens, it's able to send out a series of sounds to the universe.
Now, we want to be able to add sound to this magnificent visual work of the universe.
While we've never heard voices from outer space, we should be able to turn up the volume and hear what's going on there in the next few years.
With the lofty goal of capturing cosmic sounds, we've focused our attention on black holes and the promise they present, because black holes can hit space-time like a drumstick hitting a drumhead and make a very special sound, and I'm very excited to show you some of the sounds we've predicted.
It's possible that one day we'll see a shadow. A black hole can leave a shadow on a very bright background, but it hasn't been observed yet.
Although black holes can't be seen, they can be heard because they hit space-time like drums.
The idea that the universe could sound like a drum came from Albert Einstein, and many of our ideas come from him.
Einstein realized that if the universe was empty, if the universe was empty, it would look just like this picture, except for those guide lines that were drawn on it.
But if we were free-falling through the universe, even without these auxiliary lines, our trajectory would draw these lines, because we would find ourselves moving in straight lines through the universe along straight lines that don't bend.
Einstein also realized -- and this is really the most critical part (matter also means "matter") -- that if you put energy and matter in the universe, the universe will bend, and objects in free fall will be deflected as they pass through a celestial body like the Sun, following a curved path through space.
This is Einstein's great theory of general relativity.
Even the path of light can be bent.
When the bend is large enough, it will revolve around the orbit of the sun, just as the earth revolves around the sun and the moon revolves around the earth.
This is a natural curve in the universe.
But Einstein didn't realize that if you squeezed the Sun into a ball 6 kilometers in diameter -- that is, if you squeezed a million times the mass of Earth into a ball 6 kilometers in diameter, you would create a black hole, an object so dense that if light got too close to it, it wouldn't be able to escape -- leaving a huge black shadow in the universe.
Einstein always thought that black holes were just mathematical singularities.
He did not believe that black holes really existed.
He believed that nature would prevent black holes from forming to protect us.
It was decades before people started using the term "black hole" and realized that black holes are real objects -- in fact, they are the death of some very massive stars after a catastrophic collapse at the end of their lives.
Our sun does not collapse to form a black hole.
The quality of it isn't great enough.
But if we do some thought experiments -- which Einstein liked so much -- we can imagine smashing the sun into six kilometers, and then putting a tiny Earth in an orbit around it, say, 30 kilometers away from the black hole sun.
The earth will shine by itself, because now the sun is gone and we have no other source of light - so our little earth will have to shine by itself.
You'll find that you can even put the Earth in an orbit 30 kilometers away from the black hole and have it orbit happily.
The black hole is only about the size of Manhattan.
It could swell up to Hudson Avenue before it destroys the Earth.
But basically that's what we're talking about.
We're talking about an object compressed to half the size of Manhattan.
So we moved this Earth closer to the black hole — 30 kilometers away — and we noticed that it was orbiting the black hole in perfect orbit.
There are some rumors that black holes will eat everything in the universe, but in reality you have to get really close to actually fall in.
But impressively, from our point of view, we can always see the Earth.
It cannot hide behind a black hole.
Some of the light emitted from the Earth falls into the black hole, but some of it is bent by the black hole and is seen by us.
So you can't hide anything behind a black hole.
If this is Battlestar Galactica and you're fighting Cylons, don't hide behind a black hole.
They can see you.
Our sun doesn't collapse into a black hole; it's not massive enough, but there are tens of thousands of black holes in our galaxy.
If one of them was eating the Milky Way, it would look like this.
We're going to see the shadow of a black hole cast on hundreds of billions of stars in the Milky Way and the dust lanes lit by the stars.
If we were to fall into this black hole, we would see light refracted around the black hole, and we wouldn't even be able to feel some huge change happening at all when we started to enter this shadow.
If we try to fire up the rocket and get out of there, it won't work out well, because we can't escape, not even light.
Although black holes look dark from the outside, they don't look like that from the inside, because light from all galaxies can fall with us into the black hole.
And even so, because of relativistic time dilation, our clocks seem to be slowing down compared to galactic time, which makes it seem as if the galaxies outside are accelerating, just before we ourselves are destroyed by the black hole.
It's like experiencing a near-death experience, where you see the light at the end of the tunnel, but it's a complete death experience.
(Laughter) You can't tell anyone that you saw the light at the end of the tunnel.
Until now, we've never seen such a shadow cast by a black hole, but black holes can be heard, even if they can't be seen.
Imagine, in a real astronomical scene – imagine two black holes that have been together for a long time.
Maybe they used to be stars and then collapsed into two black holes - each 10 times the mass of the Sun.
Now we compress them to within 60 km.
They can rotate hundreds of times per second.
At the end of their lives, they approach each other at the speed of light.
They can travel thousands of kilometers in a fraction of a second, and in the process, they not only bend space, but they also create vibrations in space in the wake behind them, a kind of real space-time wave.
When a black hole collides with the universe, space is squeezed and stretched.
These vibrations travel through space at the speed of light.
This computer simulation was done by Goddard's Relativity Group at NASA.
It took almost 30 years to solve this problem.
This is one of many groups.
It shows two black holes orbiting each other, and these are imaginary curves.
As you can see - maybe a little blurry - you can see the red waves being emitted, these are gravitational waves.
They're the tangible cosmic sounds that will travel outward at the speed of light as the black holes merge into one another, until the two black holes merge into a single, quietly spinning black hole.
If you stand close enough, your ears will resonate with the squeezing and stretching of these spaces.
You can really hear these sounds.
Of course, you will find helplessly that your head is also squeezed and stretched, so you may not be able to understand what is going on.
But I would like to play for you the sound of our predictions.
This is the result of my group's research - a relatively simple computational model.
Imagine a less massive black hole falling into a more massive black hole.
The sound you hear comes from the collision of the small black hole with space as it approaches the massive black hole.
If they are far away, the sound will be very small.
But gradually the sound became like a drumstick hitting the space, vibrating the space like a drum.
We can predict what this sound will become.
We know that in the process of falling, low-mass black holes get faster and louder.
Eventually, we will hear that the small black hole falls completely into the big black hole.
I've never felt this sound so loud - it's actually amplified here.
When I listened to it at home, I thought it was a little awkward.
It sounds like, ding, ding, ding.
This is another sound simulated by our research group.
I'm not going to show you images here, because black holes don't leave any useful trails, and real space doesn't show you those virtual curves.
But if you hear this sound while you're on vacation in space, I suggest you run.
(laughs) It's best to stay away from this sound.
Both black holes are moving.
Two black holes are approaching each other.
In this case, they are all shaking violently.
Then, they will blend into one.
That high-pitched sound is a sign of black hole fusion — a high-pitched sound when the fusion ends.
This is our prediction of what we're going to see.
Luckily we were very safe in Long Beach, CA.
There is no doubt that two black holes have merged somewhere in the universe.
It's also unquestionable that the space around us can also feel these vibrations that travel a million light-years, or from a million years ago, travel at the speed of light and eventually meet us.
But these sounds are so small that we can't hear them at all.
There are some experiments in the world that take a lot of effort to set up -- one of them, called LIGO -- that will detect vibrations in space that are less than one atomic nucleus every four kilometers.
This is a very bold attempt, and its sensitivity won't be surpassed in the next few years -- it will be used to detect spatial vibrations.
There's another cosmic research project that's expected to start in the next decade, and it's called LISA.
LISA will be able to see supermassive black holes—those that are millions or even billions of times the mass of the sun.
In images from Hubble, we see these two galaxies.
It looked like they were still hugging each other.
There may be a supermassive black hole at their center.
But they are not standing still, in fact they are merging.
The two black holes will collide, and their fusion will take billions of years.
So collecting the sounds they make is beyond the limits of our human perception.
But LISA can see the final stages of two supermassive black holes that started merging long ago, 15 minutes before they merge.
This detection is not limited to black holes, it can also be used to detect any large perturbation in the universe - the biggest of which is the "big bang".
When the term was coined, some people taunted - "Oh, who would believe in the Big Bang?"
This animated short, made by my friends at Proton Studios, shows what it looks like to watch the Big Bang from the outside.
We would never really want to do that; we would like to be inside the universe, because there is no such thing as being outside.
So imagine you're in the middle of a big bang.
The universe is everywhere, everything in the world surrounds you, and space swings in disorder.
Fourteen billion years have passed, and the voice still haunts us.
Gradually, galaxies form, clusters of stars form in galaxies, and on a certain planet, there is at least one such planet that is habitable for life.
Here, we frantically build experiments, do calculations, write computer code.
Imagine that a billion years ago, two black holes collided.
The sound has been traveling through time and space.
We didn't even show up here.
It's getting closer - 40,000 years ago, we were still painting on the stone walls of the cave.
If the sound we were trying to capture was the Big Bang, it would sound like this.
Strictly speaking, it is noise.
It's a white noise, a chaotic ringtone.
But it's everywhere around us, as long as it's not canceled out by some other process in the universe.
If we could detect these sounds, it would be like music to our ears, because this quiet echo comes from the moment we were created, from the universe we look up into.
So in the next few years, we're going to be able to turn up those soundtracks a little bit, and let the universe come to us as audio.
But if we can detect those earliest moments, it will also bring us one step closer to understanding the Big Bang, and enable us to ask some of the most difficult and elusive questions.
If we play the history of the universe backwards, we can know that there was a big bang in the past, and we can even hear its loud noise, but is our big bang the only big bang in the universe?
I mean, we can’t help but ask, has there ever been a similar big bang before then?
Will it happen again in the future?
I would say that if you take this question up to the level that TED advocates for rethinking, at least in the last minute, we can ask questions that we may never be able to answer.
But we can't help but ask: Could our universe be just an episode in a larger history?
Or are we just a branch of the multiverse — each of which has experienced its own Big Bang — maybe some of them have humming black holes, maybe some don’t — maybe some have conscious life, maybe some don’t — they don’t belong in our past, they don’t exist in our future, but they are somehow connected to us?
So, we can't help but wonder, if there is a multiverse, is there life in other branches of this multiverse?
This is life in our multiverse.
Are there other beings in the multiverse that are also speculating about our existence, thinking about their own origins?
If so, I can imagine them doing the same calculations as us, writing computer code, building experimental instruments, trying to detect those faint sounds from their origins, and wondering who else was there.
Thank you.Thank you all.
(applause)
One winter morning a few years ago, I was driving to work in Johannesburg, South Africa, and the city was shrouded in smog.
I drive by it almost every day, but this time it's unusual, I've never seen anything like it before.
Johannesburg is famous for its distinctively beautiful skyline, but it was barely visible that morning.
I soon realized that what I was seeing was a severe haze caused by air pollution.
The contrast between the beautiful environment I used to know and the haze-covered skyline of the present day swells in my mind.
I fear that there is a good chance that the once colorful sunset will be swallowed up by a dark haze.
At that moment, I felt a strong urge to do something, but I didn't know what to do.
All I know is that I can't just stand by.
The biggest challenge was that I didn't know much about environmental science, air quality management, or atmospheric chemistry.
I'm a computer engineer, and I'm pretty sure I can't solve air pollution by coding.
(Laughter) In what capacity am I going to address this?
I'm just a market guy.
Over the next few years, I learned an important lesson that we should all take to heart if we want to achieve a better future.
Even if you are not an expert in a particular field, your expertise may imply solutions to problems in that area.
Sometimes, the unique perspective you have can trigger unconventional thinking to shape the situation, but you need to be bold.
Only then can you know the results.
What I knew at the time was that if I wanted to try to change, I had to know enough about pollution, so I was a student again.
I did some basic research, and I quickly learned that air pollution is the biggest environmental health risk in the world.
According to the World Health Organization, in 2012, almost 14 percent of all deaths worldwide were caused by air pollution in and around households, especially in low- and middle-income countries.
Air pollution kills more people each year than malaria and AIDS.
In Africa, premature deaths from unsafe sanitation, or deaths from malnutrition among children, pale in the face of air pollution, and it also comes with a huge economic cost: In 2013, according to the Organization for Economic Co-operation and Development, spending on them exceeded $400 billion.
In my work, I explore the frontiers of artificial intelligence, including the symbiotic relationship between humans and machines, to find useful footholds and help us make better decisions.
When I think about air pollution again, it becomes clear that we need to find better ways to make better decisions about how to deal with air pollution.
So I decided to meet some people working in this field.
I started talking to officials in Johannesburg and other surrounding cities, I joined the local scientific community, and I made some phone calls to people who were completely unfamiliar but connected.
These experiences that I have embarked on have helped me to understand this issue more deeply.
It also helped me avoid the pitfall that people in my field sometimes fall into when trying to innovate: adopting a technology quickly before you've really mastered the problem.
I started thinking, what can I do to improve this situation?
I started asking myself, how can I effectively combine my knowledge and skills in software engineering and artificial intelligence with the expertise of the people I connect with.
I wanted to create an online air quality management platform that would reveal future pollution trends and make predictions about what might happen.
I'm sure that my idea can become a realistic solution, but there's uncertainty, and I can't guarantee it will work.
All I have is a specific set of engineering skills, skills that I get from my job. (Laughter) Of course, my skills are new to someone who's been working in air pollution for years.
I've come to realize that sometimes a fresh perspective, a new skill set, can lead to something remarkable.
Our willpower and imagination are a beacon that directs us to overcome obstacles and start a new chapter.
I got a deeper understanding of the air pollution problem, looking for air pollution data for the past decade, and meteorological data in and around Johannesburg, and then I worked with my colleagues in South Africa and China to create an air quality resolution support system and upload it to the cloud.
The software can analyze historical and real-time data to reveal trends in pollution over time and space.
We then used new machine learning techniques to predict future pollution days in advance.
That means residents can make better decisions about their daily itineraries and where to settle with their families.
We can predict adverse pollution events in advance, define serious pollution sources, and enable relevant authorities to issue orders to adjust their operations.
By supporting scenario planning, city planners can also make better decisions about how to expand infrastructure work, such as housing settlements in industrial areas.
We've set up a pilot pilot of the technology, running it for 120 days, covering the whole of South Africa.
Our expectations were validated, and the predicted data we showed showed a strong correlation with the data we collected in the field.
Through our management, we brought in the world's leading, cutting-edge instrumentation to predict air quality with unprecedented resolution and accuracy, to the benefit of the city I drove into on a recent winter morning, and I said to myself, "Something's not right, I have to figure out what to do about it."
So, the point is: What if I hadn't researched in depth about air pollution?
What if I didn't pay attention to the state of the country's environment, and instead hoped that some place, some other person would take care of it?
What I've learned from this is that when working hard on a cause that we all believe in, it's important to focus on the likelihood of success and consider the consequences of inaction.
We should not be distracted by opposition and resistance, it should motivate us to go further.
So no matter where you are in the world, the next time, when you find that some kind of natural curiosity in you is piqued, and it's about something you care about, and you have some crazy or brave idea, even if it's not your area of expertise, ask yourself: Why not try it?
Why not go ahead and solve the problem and do your best, in your own way?
You might get a surprise.
Thank you all.
(applause)
Many people think that driving is something that only those who can see can do.
Blind people want to drive a car alone and safely. Until now, it was considered an impossible task.
Hi, my name is Dennis Hong, and we've built a car for people with visual impairments for the freedom and independence of the blind.
Before I talk about this car for the blind, let me briefly mention another project I worked on called the DARPA Urban Challenge.
It's about building a mechanical car that can drive itself.
You press the start button, no longer touch anything, and it will reach its destination completely automatically.
In the 2007 Challenge, our team won $500,000 to finish third in the competition.
Around that time, the National Association of the Blind, or the Blind Association, challenged the design team about who could design a car that would allow blind people to drive independently and safely.
We thought we'd give it a try, because we thought, hey, where is this going to be difficult.
We already have an autonomous car.
We just have to let blind people drive inside, and that's all it takes, right?
(Laughter) But we were wrong.
What the Blind Society wants is not a car that can carry blind people around, but a car that blind people can make choices and drive.
So we had to give up everything we had and start from scratch.
To test this crazy idea, we designed a prototype of a small sand buggy to test its feasibility.
In the summer of 2009, we invited many blind youths across the country and gave them a chance to take this car for a ride.
It's definitely a cool experience.
But the problem with this car is that it's designed to allow blind people to drive only in very limited situations, like a closed parking lot -- even on roads made of red traffic cones.
So with this success, we decided to take the important next step of making a real car that can drive on real roads.
How does it work?
Well, it's a relatively complex system, but let me explain it a little bit to simplify it.
We have three stages.
We have the induction phase, the computation phase and the non-visual interface.
The driver is clearly invisible, so the system must be able to sense its surroundings and collect data for the driver.
For this, we use the initial metering element.
It measures acceleration, angular acceleration -- just like the human ear, the inner ear.
I combined this information with the global positioning system to predict where the vehicle is.
We also use two cameras to detect the driving path.
We also used three laser rangefinders.
The laser scans the environment to detect obstacles -- vehicles passing by from the front, rear, and any obstacles in the way, any obstacles around the vehicle.
All this massive amount of information is then aggregated into a computer, and the computer does two things.
First and foremost, one thing is to process information to understand the surroundings -- what are the driving paths and what are the obstacles -- and translate that information to the driver.
This system is also very intelligent and can calculate the safest driving path.
We can also issue instructions on how to operate the vehicle's operating procedures.
But the question is: How can we transmit information and instructions quickly and accurately enough to a blind person to make sure he can drive?
To this end, we have designed many different non-visual user interface technologies.
The original three-dimensional flat sound system, vibrating vests, voice-activated gears, leg straps, even shoes that put pressure on the feet.
But today we're talking about three of these non-visual user interface technologies.
The first interface is called the steering handle.
It's a pair of gloves, and it has vibrating elements in the knuckles, so you can transmit instructions on how to drive -- direction and amplitude.
Another device is called a velocity belt.
This car chair -- actually, it's a massage chair.
We took it apart, we reorganized the vibrating elements in different modes, and we let them transmit information about speed, but also instructions on how to use the throttle and brakes.
Here, you can see how the computer understands its surroundings, and because you can't see the vibrations, we actually put red LEDs on the driver so he can see what's going on.
This is the sensor data, which is transmitted from the sensor to the computer.
So these two devices, the steering handle and the speed belt, are very effective.
But the problem is that these are instruction hinting devices.
So it's not really freedom, right?
The computer tells you how to drive -- turn left, turn right, accelerate, brake.
I call this the co-pilot problem.
So we're avoiding command-hint devices and focusing more on information devices.
A typical example of such a non-visual information interface is called an empty graph.
Think of this as a display for the blind.
It's a small tabletop with a lot of holes in it through which compressed air is drawn out, so it can be described as a picture.
So even if you're blind and you put your hand on it, you can sense the path and the obstacles.
In fact, you can also change the frequency of emissions in the air and possibly the temperature.
This is actually a multi-dimensional user interface.
Here, you can see the left and right cameras and how the computer parses and sends this information to the empty image.
So, we're showing a simulation program where a blind man is driving with an empty map.
This program is very helpful in training blind drivers and quickly testing different theories in terms of different kinds of non-visual user interfaces.
That's basically how it works.
But this car is a model car, and it won't be on the road unless it's proven to be as safe to drive as today's cars, or safer.
I really do believe this will happen.
But are societies, can they accept this radical idea?
How will we handle insurance?
How will we issue a driver's license?
Behind the technical challenges there are many different hurdles that we need to address before they become a reality.
Of course, the main purpose of this project is to design a car that can be driven by blind people.
But potentially even more important than that is the tremendous value in the by-products of this project.
Can be used to see through the dark, rain and fog sensors.
And this new kind of interface, we can use these technologies to make them safer vehicles for visible crowds.
Or for the blind, home devices for everyday life - educational facilities, office facilities application services.
Imagine a classroom where a teacher writes notes on a blackboard. Blind students can also use these non-visual interfaces to understand and read what the teacher writes.
This is extremely precious.
What I have shown you today is just the beginning.
Thank you very much.
(applause)
As an artist, connection is very important to me.
Through my art I try to show that human beings are not separated from nature but that everything is connected.
I went to Antarctica for the first time about 10 years ago, and I saw icebergs for the first time.
I feel awe.
My heart was beating fast, dizzy, trying to understand what was in front of me.
The iceberg next to me surfaced almost 200 feet above the water, and I could only find it strange that it was one snowflake over another snowflake, year after year.
Icebergs form when they break from glaciers or from ice shelves.
Each iceberg has its own unique personality.
They have a distinct way of interacting with their surroundings and their situations.
Some icebergs refuse to compromise and stick to the end, while others can't stand to break apart in a moment of intense passion.
When you look at the icebergs, it's easy to think that they're all isolated, they're separate, they're all alone, more like what we humans sometimes think of ourselves.
But the reality is much more than that.
As the iceberg melts, I breathe its ancient smell.
As the iceberg melts, it releases fresh, mineral-rich water that nourishes everything.
I set out to photograph these icebergs as if I was photographing portraits of my ancestors, and I learned that at these individual moments, the icebergs were there in that way but never again.
When they melt, it's not death; it's not an end, but a continuation of the road to life.
Some of the icebergs I've photographed are very young -- thousands of years old.
Some ice is more than 100,000 years old.
The final image I want to show you is an iceberg that I took from Kekertsuatsiak in Greenland.
This is a very rare opportunity for people to actually witness an iceberg roll.
So this is as shown in the figure.
On the left you can see a boat.
It's a boat about 15 feet.
I want you to pay attention to the shape of the iceberg and its deformation on the water.
Here you see it start to roll, the boat moves to the other side, and a man is standing there.
This is an average-sized Greenland iceberg.
It surfaced about 120 feet high or 40 meters high.
This video was shot in real time.
(Music) Like these icebergs, they show people different aspects of their personality.
Thank you.
(applause)
Do you know how many flowering plants there are?
There are 250,000 species - at least as many as we know - 250,000 flowering plants.
And flowers are a problem.
It's really hard to get plants to thrive.
It takes a lot of experience and a lot of resources.
Why is it so troublesome?
The answer, of course, is, like so many other things in the world, gender.
I know what goes through your mind when you look at these pictures.
The reason sexual reproduction is so important -- there are many other ways plants can reproduce.
can be used by cuttings; can be bisexually propagated from the same plant; can be pollinated from the same plant.
But they do need to spread their genes and mix with other genes so that they can survive.
This is how evolution works.
Plants now transmit this information through pollen.
Some of you may have seen these pictures before.
Like I said, every family should have a scanning electron microscope that can see this.
There are as many different types of pollen as there are flowering plants.
This is really useful for forensics.
Most of the pollen that causes us to get hay fever comes from plants that use wind to spread pollen, which is a very inefficient process, and that's why pollen always ends up in our noses.
Because most of them were discarded, it was hoped that the germ cells contained in the pollen, the male germ cells, would happen to land on another flower.
All grasses, which means all grains, and most trees spread their pollen by the wind.
But most species actually use insects to do this, and in a way it's smarter because it doesn't require as much pollen.
Insects and other species can carry pollen and move it directly to where it's needed.
Obviously, we noticed the relationship between insects and plants.
It's a symbiotic relationship, whether it's a bird or a bee, they both get a reward, and the reward is usually nectar.
Sometimes this symbiotic relationship leads to wonderful adaptations -- the red-dressed hawkmoth is a beautiful adaptation.
Plants also harvested, and Tian'e spread the pollen elsewhere.
Plants have evolved, creating runways everywhere that bees can get lost.
Many plants have markings that look like other insects.
These are the pollen sacs of lilies, and it's so clever that when an unsuspecting insect lands on it, the sac flips over and hits the insect's back with a lot of pollen, so that it can follow the insect to other plants.
There's an orchid that looks like it has jaws, and in a way, it does;
Orchids: There are at least 20,000 species of orchids - an amazing variety.
They have all sorts of tricks.
They have to try and attract pollinators to help them through this process.
This orchid, known as Darwin's orchid, because it was studied by Darwin and made a fantastic prediction when he saw this orchid, you can see there's a long nectar tube hanging down from the orchid.
Basically what the insect has to do is -- we get to the middle of the flower -- and it sticks its mouthparts into the middle and all the way down to the nectar tube to get the nectar.
Looking at the flower, Darwin said, "I guess something has co-evolved with it."
No doubt, it's insects.
I mean, usually it's rolled up, but when it's straightened, it looks like this.
Now imagine that if nectar, such a valuable thing, is expensive for plants to produce and attracts many pollinators, then, as in human sexuality, people might start to deceive each other.
They might say, "I have some nectar. Would you like to come and get some?"
This is a plant.
This plant is loved by insects in South Africa, which have evolved long mouthparts to get nectar from the bottom.
This is an imitator.
This plant mimics the previous plant.
There's a fly with long mouthparts that doesn't get any nectar from the counterfeiter, because the counterfeiter doesn't give it any nectar, and it thinks it can get it.
So not only are the flies not getting nectar from the fake plants, but -- if you look very closely at the top of the head, you'll see there's some pollen there that's going to spread to other plants, if no botanist comes along and sticks it on a blue card.
(Laughter) It's a lie all over the plant kingdom.
This flower with black spots: They may look like black spots to us, but I'm telling you, to a male insect of the right species, this looks like two very, very sexy females.
(Laughter) When the insect arrives and lands on it, it immerses itself in the pollen, and of course, that pollen will be carried to other plants by it, and if you look at the scanning electron microscope image that every family should have, you can see that there are actually patterns there, three-dimensional patterns.
It can even make insects feel comfortable and look good.
These electron microscope images -- this is an orchid masquerading as an insect -- you can see to our eyes that different parts of the structure have different colors and different textures, and insects may perceive very, very different textures.
This orchid evolved to mimic the metallic, shiny surface seen on some beetles.
You can see this surface under a scanning electron microscope -- it's very different from other surfaces we've seen.
Sometimes the whole plant mimics an insect, even if it looks like an insect to us.
I mean, I think this looks like some kind of flying animal or beast.
It's a wonderful and magical thing.
That's where it's clever.It's called obsidian.
I think it is sometimes dodgy.
For a bee of the right kind, this looks like another very aggressive bee, and it'll fly over and hit it with its head many, many times, trying to drive it away, and of course, it'll get pollen.
Another thing it does is that the plant mimics another orchid rich in insect-loving food.
But actually nothing.
So it's cheating on two levels -- it's unbelievable.
(Laughter) What we're looking at is ylang-ylang, the fragrant part.
I've actually smelled it before.
The flowers don't actually have to be so showy.
They give off a wonderful fragrance that attracts any interested insect.
This flower doesn't smell very good.
This flower actually smells very bad. Again, this is evolution, and it looks like carrion.
So flies like it.
Flies fly in and pollinate them.
This is the white star calla lily, also known as the dead horse calla lily.
I don't know what a dead horse smells like, but this flower probably smells very much like it.
It's terrible.
The green-headed flies are stubborn.
Fly into it, fly into it.
Laying eggs on it, thinking it's a nice piece of carrion, not realizing that there's no food for the eggs here, the eggs will die here, but at the same time the plant will benefit because the bristles loosen and the fly disappears and pollinates another flower -- it's amazing.
This is the Alocasia plant, Alocasia, variegated aroma, known in this country as Trillium.
I shot this in Dorset last week.
This guy is heating up about 15 degrees above the ambient temperature -- unbelievable.
If you look inside it, there's something kind of a dam behind the spikes, and the flies are attracted to the heat -- it's a boiling volatile chemical, bugs -- and they're trapped under this container.
They drank the sweet nectar and they all became a little slimy.
At night they're covered in pollen, sprayed down from above them, and then the bristles we see above them wilt and allow these pollen-covered bugs to escape -- unbelievable.
If you think it's unbelievable, this one is my favorite.
This is spring plume.
Anyone here from Brazil should know this plant.
This is the most amazing thing.
Its stamens are about a foot long.
It has an ability that no other plant that I know of has, and when it blooms -- this is the ear in the middle -- for about two days, it produces some sort of metabolic change that's kind of mammal-like.
It doesn't have starch, it's plant food, and it has something very similar to brown fat that burns it at the rate it burns fat, metabolizes it, at about the rate of a kitten.
That's twice the energy output of a hummingbird by weight - absolutely amazing.
It also did something unusual.
Not only will it heat up to 155 degrees Fahrenheit, 43 or 44 degrees Celsius for two days, but it will remain constant.
There is a thermoregulation mechanism to maintain a constant temperature.
Why do you do this, I hear you ask.
What you don't know yet is that some beetles like to mate at this temperature.
They burrow in, covered in pollen.
(Laughter) Plants sprinkle pollen on them and let them go and pollinate them.
What a wonderful thing this is.
Now we think that most pollinators are insects, but in fact in the tropics, many birds and butterflies also pollinate.
Many tropical flowers are red, and that's because butterflies and birds are similar to us, and we think they can see red very well.
But if you look at the spectrum, birds and us, we see red, green and blue and see this spectrum.
Insects see green, blue, and ultraviolet. They can see all kinds of light and dark ultraviolet.
There are some colors on the back.
"Wouldn't it be nice if we could see those colors," I hear you ask.
Yes, we can see it.
So what do insects see?
Last week I took photos of these desert rosettes, Half Heliotrope, in Dorset.
As we can see, these are little yellow flowers, and these little yellow flowers are everywhere.
It looks like this in visible light.
If you remove the red it looks like this.
Most bees cannot perceive red.
Then I put a UV filter in front of my lens and took a long exposure at a specific frequency of UV light, and I got this picture.
It's like a real magic bullet.
Now we don't know what the bees are seeing, and when I call it red, you know what I'm looking at.
We don't know what's going on in it, whether it's an insect or another human brain.
But the contrast looks presumably like it stands out from the background.
This is another kind of flower -- in different UV frequency ranges, with different filters to match different pollinators.
It looks like this.
And lest you think that all yellow flowers have this property -- there's no damage to the flower during the shoot; just stick it on a tripod, and don't take it off -- under UV light, look at this.
This can serve as the basis for sunscreens, since sunscreens work by absorbing ultraviolet light.
So maybe the chemicals in it have some use.
And finally, this is a nocturnal scent that Bjorn Rorslett from Norway sent me -- a wonderful hidden pattern.
I like this hidden way.
I think it's very poetic, because these pictures were taken with an ultraviolet filter, and the main use of this filter is for astronomers to photograph Venus -- actually the clouds on Venus.
This is the main purpose of this filter.
Of course, Venus is the god of love and fertility, and this is the story of flowers.
Just as flowers spend so much effort trying to lure pollinators into accepting their invitations, somehow they also succeed in convincing us that there is so much content in them. We send flowers to each other at birth and death, and especially at weddings, when you think about it, in that very moment, genetic material moves from one organism to another.
Thank you very much.
(applause)
