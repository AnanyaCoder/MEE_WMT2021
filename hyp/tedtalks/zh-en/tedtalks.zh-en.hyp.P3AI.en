I am committed to assisting computers to communicate with the world around us.
Yes, there are many ways to do this, and I like to focus on helping computers talk about what they see and understand.
In view of such a scenario, a modern computer vision algorithm can tell you that there is a woman and a dog.
It can tell you that the woman is smiling.
It can even tell you that this dog is very cute.
I deal with this problem by thinking about how human beings understand and live with the world.
Those thoughts, memories and stories, in such scenes, may call attention to human beings.
The interconnectedness of all relevant situations.
Maybe you've seen a dog like this before, or maybe you've spent time running on a beach like this, and further evoking memories and thoughts of past vacations. When you used to go to the beach, you spent time with other dogs, running around.
One of my guiding principles is to understand what we believe and feel in common by helping computers understand what kind of experience this is, and then we have the ability to start developing computer technology in a way that complements our experience.
So, digging deeper into this, I started working a few years ago to help computers produce human-like stories, from image sequences.
So, one day, while I was working on my computer, I asked him what he thought of the trip to Australia.
He looked at the picture and saw a koala.
It doesn't know what a koala is, but the computer says it thinks the koala looks like an interesting creature.
Then I shared a series of images with my computer about the burning of houses.
When the computer looked at the picture, it said, "This is an amazing view! This is spectacular!"
It sent chills down my spine.
The computer saw a horrible, life-changing and life-destroying event and thought it was a positive thing.
I realized that the computer recognized the contrast between red and yellow, and thought it was something worthy of a positive review.
Part of the reason is because most of the images I type into my computer are positive.
That's because when people talk about their experiences, they tend to share positive images.
When was the last time you saw a selfie at a funeral?
I realized that in the process of improving artificial intelligence, tasks are assigned to tasks and data sets are assigned to data sets, creating huge gaps, flaws and blind spots in the understanding of computers.
In doing so, I am coding for all kinds of biases.
Biases reflect limited viewpoints and stem from a dataset that reflects the same stereotypes and stereotypes that humans share.
I think back to the development of the technology that got me to where I was that day - the first color image was calibrated for a white woman's skin color, which meant color photography was biased against blackface.
And with the same deviation, that blind spot continues to carry into the 1990s.
Even today, the same blind spot still exists in the application of facial recognition technology, how to recognize the faces of different people.
In today's research, I think of the most advanced technologies that tend to limit our thinking to a single data set and a single problem.
And in doing so, we are creating more blind spots and biases that will be amplified by the use of AI.
At that time, I realized that we had to think deeply about how we would be perceived five to ten years from now when we invent and create technology today.
In the interaction between human beings and the environment, human beings use time to correct problems, so evolution is slow.
Artificial intelligence, by contrast, is evolving at an incredible rate.
That means it's really important, and we need to think about that now - reflect on our own blind spots and biases, and consider how those biases affect the technology we create now, and discuss what today's technology means for the future.
CEOs and scientists have weighed their ideas about the future of artificial intelligence.
Stephen Hawking warned, "Artificial intelligence will destroy humanity."
Elon Musk warns that this is an existential risk, and one of the biggest risks we face as a civilized society.
"I don't understand why people aren't more worried about artificial intelligence," Bill Gates said.
But these points of view are only part of the story.
The math, the models, the basic components of artificial intelligence that we can all acquire and use.
We have source code tools that are open to the public to learn about machines and make our own contributions at the same time.
In addition to this, we can also share our experiences.
We can share the technical aspects, the relationship with us, and how to make us feel good.
We can talk about the things we love.
We can communicate with the foreseeable future that this may be more beneficial in terms of technology, or that there may be more problems over time.
If we all focus on opening up the discussion of AI to the future, it will help to create a regular conversation and awareness about what AI is, what it can become, and all the things we need to do to achieve the results that are best for us.
We have already seen and understood this in the technology we use today.
We use smartphones, digital assistants and automatic vacuum cleaners.
Are they evil?
Maybe sometimes it is.
Will they be beneficial?
Yes, they are, too.
They are not exactly the same.
There you can already see the light of the future.
The future will continue to start with what we are building and creating now.
We set in motion the domino effect, which opens the way for AI to evolve.
In our time, the artificial intelligence that shapes tomorrow.
So that we can immerse ourselves in augmented reality and resurrect the world of the past,
When people have trouble communicating, technology helps them share their experiences with each other.
Technology built on online visual media can be used for autonomous driving of cars.
Technology produces language based on the understanding of images, which can evolve into technology to assist the visually impaired and help them to better own the visual world.
We also see how technology can lead to some problems.
Today, we have technology to analyze the physical characteristics of our birth -- such as the color of our skin or the expression on our face -- to determine whether we are criminals or terrorists.
We have the technology to process data, to process data on gender or ethnicity, to determine whether we can get a loan.
Everything we see now is just a snapshot in the evolution of artificial intelligence.
Because where we are now, it is a moment in evolution.
This means that what we do now will affect the future development of things and extend to the future world.
If we want AI to help humans evolve in a way, we need to identify strategies and goals and open up that path right away.
What I want to see is a development direction that suits the culture and environment of human beings.
Technology can help us heal patients with neurological disorders or other disabilities, making life as challenging as everyone else's.
Technology doesn't work with your characteristics or skin color in mind.
What I focus on today is the technology of tomorrow and ten years from now,
Artificial intelligence can emerge in many different ways.
But in this case, it is not a driverless vehicle without any destination.
This is a car we can drive and control at the same time.
We choose when to speed up and when to slow down.
We choose whether we need to turn a corner.
We choose what the artificial intelligence of the future will be.
There will be a vast arena, allowing artificial intelligence to be everything.
It's going to be a lot of different things.
It is now up to us to figure out what needs to be implemented to ensure that the results of AI will be better for all humans.
Thank you very much.
(Applause)
I hope you will take a moment to consider the very simple fact that up to now, most of our knowledge of the universe has come from light.
When we stand on the earth and look up at the night sky, we can see the stars in the sky with naked eyes.
The intense sunlight is so harsh,
We can see the light reflected back from the moon,
Ever since Galileo Galilei aimed his humble telescope at the cosmic bodies, the universe as we know it today has appeared before our eyes through light.
With the help of modern telescopes, we have been able to collect dazzling, silent images of the universe - a series of images dating all the way back to the Big Bang.
However, the universe is not a mime, because the universe is not really silent.
I want to tell you that the cosmos has its own soundtrack, and the cosmos itself is constantly playing, because space can vibrate like a drum.
So when something big happens, it can send out a series of sounds to the universe.
Now, we hope to lend a voice to this magnificent visual work about the universe.
Although we have never heard from outer space, we should be able to turn up the volume and listen to what's going on there in the next few years.
For the ambitious goal of capturing the sound of the universe, we are focusing on the black hole and its promise. Because black holes can hit spacetime like drumsticks hitting the surface of a drum, they can make a very special sound. I am also very happy to play you some of the sounds we predicted.
One day in the future, we may be able to see a shadow. A black hole can leave a shadow on a very bright background, but it has not yet been observed.
Although black holes cannot be seen, they are likely to be heard because they hit spacetime like a drum.
The idea that the universe can make a sound like a drum came from Albert Einstein. In fact, many of our ideas came from him.
Einstein realized that if the universe were empty, if the universe were empty, it would look like this picture, except for the auxiliary lines drawn on it.
But if we are in freefall in the universe, even without these auxiliary lines, our trajectory will draw these lines, because we will find that we are moving in a straight line, following a straight line that does not bend.
Einstein also realized - and this is really the most crucial part (matter also means "matter") - that if you put energy and matter into the universe, the universe will bend, and objects in free fall will be deflected along the curved path of space as they pass toward objects like the sun.
This is Einstein's great general theory of relativity.
Even the path of the light will be bent.
When the bend is large enough, it will revolve around the orbit of the sun, just as the earth revolves around the sun and the moon revolves around the earth.
This is the natural curve of the universe.
But Einstein did not realize that if you compress the sun into a ball 6 kilometers in diameter -- that is, if you compress a million times the mass of the earth into a ball 6 kilometers in diameter -- you will create a black hole, an object so dense that if the light is too close to it, it will not escape -- leaving a huge dark shadow in the universe.
Einstein, however, always believed that black holes were a mathematical singularity.
He did not believe in the existence of a black hole.
He believed that nature would prevent the formation of black holes to protect us.
It took decades before people began to use the term "black hole" and realized that black holes are real objects - in fact, they are the death states of some extremely massive stars after a catastrophic collapse at the end of their lives.
Our sun does not collapse to form a black hole.
Its quality is actually not big enough.
But if we do some thought experiments - which Einstein liked very much - we can hypothetically crush the sun and compress it within six kilometers, and then put a small Earth in orbit around it, say, 30 kilometers away from the black hole sun.
The earth will shine on itself because now the sun is gone and we have no other light source - therefore, our little earth has to shine on its own.
You will find that you can even put the Earth in an orbit 30 kilometers away from the black hole and make it happy to orbit.
This black hole is actually only about the size of Manhattan.
Before it destroys the Earth, it could expand into Hudson Street.
But basically, that's what we're talking about.
We're talking about an object half the size of Manhattan that has been compressed.
So we moved this Earth closer to the black hole - 30 kilometers away - and we noticed that it orbited the black hole in a perfect orbit.
There are some rumors that black holes will devour everything in the universe, but in reality you have to be very close to it before you actually fall in.
But what is impressive is that from our perspective, we can always see the Earth.
It cannot hide behind a black hole.
Some of the light emitted from the Earth falls into the black hole, but others are bent by the black hole and seen by us.
So you can't hide anything behind a black hole.
If this is the story of Battlestar Galactica and you're fighting the Cylons, don't hide behind a black hole.
They can see you.
Our sun does not collapse into a black hole; it is not massive enough, but there are tens of thousands of black holes in our Milky Way.
If one of them were engulfing the Milky Way, it would look like this.
We will see the shadow of a black hole cast on hundreds of billions of stars in the Milky Way, as well as the dust belt illuminated by stars.
If we were to fall into this black hole, we would see light being refracted around the black hole, and we would not even begin to feel some huge changes happening quietly when we started to enter this shadow.
If we try to launch the rocket and get out of there, the result will not be very good, because we cannot escape, even the light cannot escape.
Although black holes look dark from the outside, this is not the case from the inside, because the light from all galaxies can fall into the black hole with us.
And even so, because of relativistic time dilation, our clocks seem to slow down compared to the time of the Milky Way, which looks as if the galaxies outside are changing at an accelerated pace, just before we ourselves are destroyed by black holes.
It's like experiencing the feeling of dying, you see the light at the end of the tunnel, but it's a complete death experience.
(Laughter) There's no way you can tell anyone you see light at the end of the tunnel.
So far, we have never seen such a shadow left by a black hole, but black holes can be heard, even if they cannot be seen.
Imagine, in a real astronomical scene - imagine two black holes that have existed together for a long time.
Perhaps they were stars before collapsing into two black holes - each 10 times the mass of the sun.
Now we are compressing them to within 60 kilometers.
They can rotate hundreds of times per second.
At the end of their lives, they move closer to each other at the speed of light.
They can travel thousands of kilometers in a fraction of a second. In the process, they will not only bend the space, but also create vibrations in the wake behind them, a kind of real space-time wave.
When a black hole collides with the universe, space is squeezed and stretched.
These vibrations travel through space at the speed of light.
The computer simulation was carried out by NASA Goddard's Relativity Group.
It took nearly 30 years to solve the problem before and after.
This is one of the many groups.
It shows two black holes revolving around each other, and these are imaginary curves.
As you can see - maybe a little blurry - you can see the red waves being emitted, and these are the gravitational waves.
They are real cosmic sounds that will travel outward at the speed of light as black holes merge with each other, until the two black holes merge into a quietly spinning black hole.
If you stand close enough, your ears will resonate with the squeezing and stretching of these spaces.
You can really hear these voices with your own ears.
Of course, you will be helpless to find that your head is also being squeezed and stretched, so you may not be able to understand what is going on.
But I would like to play the sound of our prediction for you.
This is the result of my group's research - a relatively simple computational model.
Imagine a smaller black hole falling into a more massive black hole.
The sound you hear comes from the collision of a low-mass black hole with space as it approaches a massive black hole.
If they are very far away, the sound will be very low.
But gradually the sound becomes like a drumstick beating on the space, making the space vibrate like a drum.
We can predict what the sound will be like.
We know that in the process of falling, the small mass black hole will get faster and make louder sounds.
Eventually, we will hear that the small black hole has completely fallen into the big black hole.
I've never felt the sound so loud - it's actually amplified here.
When I listened to it at home, I felt it was a bit weak.
It sounds like Ding, Ding, Ding.
This is another sound that our research team has simulated.
I'm not going to show you images here, because black holes don't leave any useful traces, and real space doesn't show you those virtual curves.
But if you hear it while vacationing in the cosmos, I suggest you run.
(Laughs) It's best to get away from the sound.
Both of these black holes are moving.
Two black holes are moving closer to each other.
In this case, they are all shaking violently.
Then, they will merge into one.
That shrill sound is a sign of black hole fusion - a shrill sound at the end of the fusion.
It's a prediction of what we're going to see.
Luckily, we are very safe in Long Beach, California.
Needless to say, somewhere in the universe, two black holes have merged.
There is also no doubt that the space around us can also feel these vibrations that travel through a million light years, or from a million years ago, and travel at the speed of light and eventually meet us.
But these sounds are so small that we can't hear them at all.
There are experiments in the world that take a lot of effort to set up - one of them, LIGO, will be able to detect vibrations in space that are less than one atomic nucleus every four kilometers.
This is a very bold attempt, and its sensitivity will not be surpassed in the next few years - it will be used to detect vibrations in space.
Another research project on the universe, called LISA, is expected to be launched within the next decade.
Lisa will be able to see supermassive black holes - those millions or even billions of times the mass of the Sun.
In the images sent back from Hubble, we see these two galaxies.
It looks like they're still hugging each other.
There may be a massive superblack hole at the center of each.
But they are not stationary, in fact they are merging.
The two black holes will collide, and their fusion will take billions of years.
Therefore, collecting the sounds they make is beyond the limits of our human perceptions.
But LISA can see the final stage of the fusion of two supermassive black holes that began long ago, 15 minutes before they merged.
This kind of detection is not limited to black holes. It can also be used to detect any large disturbances in the universe - the biggest of which is the "Big Bang."
When the term was coined, some people mocked it and said, "Oh, who would believe in the Big Bang?"
This animated short film, made by my friends at Proton Studios, shows the Big Bang from outside.
In fact, we would never really want to be like this; we want to be inside the universe, because there is no such thing as being outside the universe.
So, imagine you're in the middle of a big bang.
The universe is everywhere, everything in the world surrounds you, and the space is swaying in a disorderly way.
Fourteen billion years later, the sound still haunts us.
Galaxies are gradually forming, and a number of stars are forming in the galaxy. On a certain planet, there is at least one such planet that is habitable for life.
Here, we frantically set up experiments, do calculations, and write computer code.
Imagine, a billion years ago, two black holes collided.
The sound has been moving through time and space all along.
We didn't even show up.
It's getting closer and closer - 40,000 years ago, we were painting on the stone walls of the cave.
If the sound we're trying to get is from the Big Bang, it will sound like this.
Strictly speaking, it is noise.
It's a white noise, a chaotic ringing.
But it is ubiquitous around us, as long as it is not offset by some other process in the universe.
If we can detect these sounds, it will be like music to our ears, because this quiet echo comes from the moment we are created, from the universe we look up at.
So in the next few years, we will be able to turn up the volume of these soundtracks a little bit, so that the universe can be presented to us in audio form.
But if we can detect those earliest moments, it will also take us a step closer to understanding the Big Bang and enable us to ask some of the most difficult, but also the most ethereal, questions.
If we play the course of the universe upside down, we can know that there was a big bang in the past, and we can even hear the noise of it. But is our big bang the only big bang in the universe?
I mean, we can't help but ask, has there ever been a big explosion like this before?
Will it happen again in the future?
I would say that if the significance of this question is raised to the level that TED is advocating to provoke people to rethink, at least at the last minute, we can ask questions that we really may never be able to answer.
But we can't help but ask: Will our universe be just an episode in a larger history?
Or are we just a branch of the multiverse - each of which has experienced its own Big Bang - and maybe some of them have buzzing black holes, maybe some don't - maybe some have conscious life, maybe some don't - they don't belong to our past, or exist in our future, but are connected to us in some way?
Therefore, we can't help but speculate, if there is a multiverse, is there life in other branches of this multiverse?
This is life in this multiverse of ours.
Are there any other beings in the multiverse who are also speculating about our existence and thinking about their own origins?
If so, I can imagine them doing the same calculations as us, writing computer code, building experimental instruments, trying to detect the faint sounds from their origins, and wondering who else is there.
Thank you. Thank you to everyone.
(Applause)
One winter morning a few years ago, I was driving to work in Johannesburg, South Africa, when I noticed that the city was shrouded in haze.
I drive past it almost every day, but this time it's very unusual, I've never seen anything like it before.
Johannesburg is famous for its unique and beautiful skyline, but it was barely visible that morning.
It soon dawned on me that what I was seeing was a severe haze caused by air pollution.
The contrast between the beautiful environment I used to know and the smog-shrouded skyline at the moment is surging in my mind.
I fear that the once-colourful sunset will be swallowed up by a gloomy haze.
At that moment, I felt a strong impulse to do something, but I didn't know what to do.
All I know is I can't just stand by and watch.
The biggest challenge is that I don't know the science of the environment, air quality management, or atmospheric chemistry.
I'm a computer engineer, and I'm pretty sure I can't solve the problem of air pollution by coding.
(Laughter) In what capacity will I solve this problem?
I'm just a small citizen of the city.
In the next few years, I learned a very important lesson, which we should all take to heart if we want to achieve a better future.
Even if you are not an expert in a particular field, your expertise may imply a way to solve problems in that field.
Sometimes, the unique perspective you hold can inspire unconventional thinking to shape the situation, but you need to be bold to try.
Only in this way can you know the result.
What I knew at the time was that if I wanted to try to change, I had to know enough about pollution first, so I went back to being a student.
I did some basic research and quickly learned that air pollution is the biggest environmental health risk in the world.
According to the World Health Organization, in 2012, almost 14% of the world's deaths were caused by air pollution in and around homes, especially in low- and middle-income countries.
The annual death rate from air pollution is higher than that from malaria and AIDS.
In Africa, premature deaths caused by unsafe sanitation, or malnutrition among children, pale in the face of air pollution. At the same time, it comes with huge economic costs: According to the Organization for Economic Cooperation and Development, spending in 2013 was more than $400 billion.
In my work, I explore the scientific and technological frontiers of artificial intelligence, including the symbiotic relationship between humans and machines, finding a useful foothold and helping us make better decisions.
When I think about the problem of air pollution again, it becomes clear how to deal with it. We need to find better ways to make better decisions. Considering that the problem is huge, it is very necessary to cooperate.
So I decided to meet some of the people who work in this field.
I started talking to officials in Johannesburg and other surrounding cities, I joined the local science community, and I made some phone calls to people who were completely unfamiliar but relevant.
The experiences I set out to intervene in helped me understand the problem more deeply.
It also helped me avoid the pitfall that people in my field sometimes fall into when trying to innovate: Quickly adopting a technology before they have really grasped the problem.
I began to think, what can I do to improve the situation?
I began to ask myself how I could effectively combine my knowledge and skills in software engineering and artificial intelligence with the expertise of the people I connected with.
I would like to create an online air quality management platform to reveal future pollution trends and make relevant predictions to determine the possible outcomes.
I'm sure my idea can be a realistic solution, but with uncertainty, I can't guarantee it will be successful.
What I have is a specific set of engineering skills, skills I have gained from my work. (Laughter) Of course, for someone who has worked in the field of air pollution for many years, my skills are completely new.
I've come to realize that sometimes a novel perspective, a new skill set, can lead to something remarkable.
Our willpower and imagination are a beacon that tells us to overcome obstacles and start a new chapter.
I gained a deeper understanding of the air pollution problem, looking for air pollution data from the past decade or so, as well as meteorological data from Johannesburg and the surrounding areas. After that, I worked with colleagues from South Africa and China to create an air quality resolution support system, which was uploaded to the cloud.
The software is capable of analyzing historical and real-time data to reveal trends in pollution over time and space.
We then used the new machine learning technology to predict future pollution several days in advance.
This means that residents can make better decisions about their daily itinerary and where to settle with their families.
We can anticipate unfavorable pollution events in advance, define sources of heavy pollution, and enable relevant authorities to issue directives to adjust their business activities.
By aiding scenario planning, urban planners can also make better decisions on how to expand infrastructure work, such as residential housing in industrial areas.
We have set up a pilot of the technology, running for 120 days, covering the whole of South Africa.
Our expected results were validated, and the predictive data we showed showed showed a strong correlation with the data we collected in the field.
Through our management, we introduced the world's leading cutting-edge instruments to predict the quality of the atmosphere with unprecedented resolution and accuracy, benefiting the city I drove into on a recent winter morning, when I said to myself, "Something is wrong, I have to find a way to do something."
So, the point is: What if I hadn't researched the problem of air pollution?
What if, instead of paying attention to the state of the country's environment, I hope that some people in some places and others will take care of these things?
What I have learned from this is that it is important to focus on the possibility of success and consider the consequences of inaction when pushing ahead with a cause that we all believe in.
We should not be distracted by opposition and resistance, it should motivate us to go further.
So no matter where you are in the world, the next time you find out that some of your natural curiosity is aroused, and it's about what you want to do, you have some crazy or brave ideas, even if it's not your area of expertise. Ask yourself: Why not try?
Why not go ahead and solve the problem? Do your best, in your own way?
You may be in for a surprise.
Thank you to everyone.
(Applause)
A lot of people think that driving is something only those who can see can do.
Until now, it was considered an impossible task for blind people to drive a car safely and alone.
Hello everyone, my name is Dennis Hong, and for the freedom and independence of the blind, we have built a car designed for people with visual impairments.
Before I talk about this blind car, let me briefly talk about another project I've worked on called the Defense Advanced Research Projects Agency Urban Challenge.
This is about building a mechanical car that can drive itself.
When you press the start button, you will not touch anything, and it will reach its destination automatically.
In the 2007 Challenge, our team won $500,000 to finish third in the competition.
Around that time, the National Association for the Blind, or the Association for the Blind, challenged the design team on who could design a car that would allow blind people to drive independently and safely.
We feel like we need to try it out because we feel like, hey, this is going to be hard.
We already have an automatic car.
All we have to do is let the blind drive inside, and that's not the end of it, is it?
[Laughs] But we're wrong.
What the Blind Association wants is not a car that can carry blind people around, but a car that blind people can take the initiative to make a choice and drive.
So we had to give up all the things we had and start from scratch.
To test this crazy idea, we designed a prototype of a small sand truck to test its viability.
In the summer of 2009, we invited many young blind people from all over the country and gave them a chance to use the car for a ride.
It's definitely a cool experience.
But the problem with the car is that it is designed to allow blind people to drive in a very limited environment, like a closed parking lot -- even on a path made of red traffic cones.
So with this success, we decided to take the important next step and build a real car that can drive on a real road.
So how does it work?
Well, it's a relatively complex system, but let me explain it and simplify it.
We have three phases.
We have the sensing phase, the computational phase and the non-visual interface.
The driver is clearly invisible, so the system must be able to sense the surrounding environment and collect data for the driver.
At this point, we use the initial metering element.
It measures acceleration, angular acceleration -- just like the human ear, the inner ear.
I combined this information with the Global Positioning System (GPS) to predict the location of vehicles.
We also use two cameras to detect the path of the vehicle.
We also use three laser rangefinders.
The laser scans the environment to detect obstructions -- from the front, from the rear, and from any obstructions that break into the road, from any obstruction around the vehicle.
All the massive amounts of information are then aggregated into the computer, which does both.
First of all, one thing is to process the information to understand the surrounding environment -- which are the driving paths and which are the obstacles -- and to translate that information to the driver.
This system is also very intelligent and can calculate the safest driving path.
We can also issue instructions on how to operate the vehicle's operating procedures.
But the question is: How can we transmit information and instructions fast enough and accurately enough to a blind person to ensure that he can drive?
To this end, we have designed a number of different non-visual user interface technologies.
The original three-dimensional flat sound system, vibrating vests, voice-controlled gears, leg straps, and even shoes that put pressure on the feet.
But today we are talking about three of these non-visual user interface technologies.
The first interface is called the driver's handle.
This is a pair of gloves that have a vibrating element at the knuckles so that you can transmit instructions on how to drive -- direction and amplitude.
The other device is called a velocity shock band.
This car chair -- in fact, it's a massage chair.
We take it apart, we reassemble the vibrating elements in different modes, we let them transmit information about the speed, and we also have instructions on how to use the throttle and brake.
Here, you can see how the computer understands the surroundings. Because you can't see the vibrations, we actually have a red light-emitting diode installed on the driver, so he can see what is happening.
This is sensory data, which is transferred from the sensor to the computer.
So these two kinds of devices, the driver's handle and the speed shock band, are very effective.
But the problem is that these are command cue devices.
So it's not really about freedom, is it?
The computer tells you how to drive -- turn left, turn right, speed up, brake.
I call this the copilot problem.
So we are avoiding the command cue device and focusing more on the information device.
A typical example of this kind of non-visual information interface is called an empty graph.
Think of this as a blind person's monitor.
This is a small tabletop, with many holes in it, from which compressed air is removed, so that it can be described as a picture.
So even if you're blind and you put your hand on it, you can sense the path and the obstacles.
In fact, you can also change the frequency of the air release and possibly the temperature.
This is actually a multi-dimensional user interface.
Here, you can see the cameras on the left and right sides and how the computer parses and transmits this information to the blank map.
In this way, we are demonstrating a simulation program in which a blind person is driving with an empty map.
This program is of great help in training blind drivers and quickly testing different theories based on different kinds of non-visual user interfaces.
That's how it works, basically.
But the car is a model car, and it won't hit the road unless it proves to be as safe to drive as today's cars, or safer.
I truly believe this is going to happen.
But are societies, and can they, accept this radical idea?
What are we going to do with insurance?
How are we going to issue driver's licenses?
There are still many different obstacles behind the technological challenge that we need to address before it becomes a reality.
Of course, the main purpose of this project is to design a car driven by a blind person.
But what is potentially more important than that is the enormous value contained in the by-products of this project.
A sensor that can be used to see through darkness, rain and fog.
As well as this new kind of interface, we can use these technologies to make them safer vehicles for the visible crowd.
Or for the blind, the daily life of household devices -- educational facilities, office facilities application services.
Imagine that in class, the teacher writes notes on the blackboard. Blind students can also use these non-visual interfaces to understand and read what the teacher has written.
This is extremely precious.
What I am showing you today is just the beginning.
Thank you very much.
(Applause)
As an artist, the connection is very important to me.
Through my works of art, I try to make clear that human beings are not separated from nature, but that everything is interconnected.
I went to Antarctica for the first time about 10 years ago, and I also saw icebergs for the first time.
I was in awe.
My heart was pounding fast, my head was dizzy, trying to understand what this was really like in front of me.
The iceberg near me surfaced almost 200 feet above the surface, and I could only wonder if it was one snowflake covering another, forming year after year after year.
Icebergs are formed when they break off from glaciers or break off from ice shelves.
Each iceberg has its own unique personality.
They have a distinct way of interacting with their surroundings and their circumstances.
Some icebergs refuse to compromise and stay the course, while others can't bear to crumble in a moment of intense passion.
When you look at icebergs, it's easy to think that they are all isolated, that they are separate, separate, and more like what we humans sometimes think of ourselves.
But the reality is much more than that.
As the iceberg melted, I breathed in its ancient smell.
As the iceberg melts, it releases fresh, mineral-rich water that nourishes everything.
I set out to photograph these icebergs as if I were taking portraits of my ancestors, learning that in these individual moments the icebergs would have existed in that way but never again.
When they melt, it is not a death; it is not an end, but a continuation of the path to life.
Some of the icebergs I've photographed are very young -- thousands of years old.
Some ice is more than 100,000 years old.
The last image I want to show you is of an iceberg I took on Kekertsuatsiak in Greenland.
This is a very rare opportunity for everyone to actually witness an iceberg tumble.
So this is shown in the picture.
On the left side you can see a small boat.
This is a boat of about 15 feet.
I want you to pay attention to the shape of the iceberg and its deformation on the water surface.
Here you see it begin to roll over, the boat moves to the other side, and a man stands there.
This is an average-sized Greenland iceberg.
It surfaced about 120 feet or 40 meters above the surface.
The video was filmed in real time.
(Music) is like this iceberg, and what they show is different aspects of their personality.
Thank you very much.
(Applause)
Do you know how many medium - flowering plants there are?
There are 250,000 species -- at least as many as we know -- and 250,000 of them are flowering plants.
And the flowers are a nuisance.
It's really hard to get plants to breed.
It takes a lot of experience and a lot of resources.
Why is it so troublesome?
The answer, of course, is, as with so many other things in the world, gender.
I know what's going through your mind when you look at these pictures.
The reason why sexual reproduction is so important -- there are many other ways plants can reproduce.
It can be branched; it can reproduce with both sexes; it can be pollinated with the same plant.
But they do need to spread their genes and mix them with other genes so that they can be ecological.
That's how evolution works.
Now the way plants convey this message is through pollen.
Some of you may have seen these pictures before.
As I said, every family should have a scanning electron microscope that can see these things.
There are as many different types of pollen as there are flowering plants.
This is actually quite useful for forensic science and so on.
Most of the pollen that causes hay fever comes from plants that use the wind to spread pollen. This is a very inefficient process, which is why pollen is always running up our noses.
Because most of them have been discarded, it is hoped that the germ cells contained in the pollen, the male germ cells, will happen to fall on another flower.
All the grass, which means all the grains, and most of the trees rely on the wind to spread pollen.
But most species actually use insects to do this, which is smarter in a way because it doesn't require too much pollen.
Insects and other species can carry the pollen and transfer it directly to where it is needed.
Obviously, we have noticed the relationship between insects and plants.
It's a symbiotic relationship, with both birds and bees reaping the rewards, usually nectar.
Sometimes this symbiotic relationship can lead to wonderful adaptations -- the red skirted moth is a beautiful adaptability.
Plants are also harvested, and Tian Ying has spread the pollen elsewhere.
Plants have evolved to create landing strips everywhere, and bees can get lost in them.
Some of the plants look like markers of other insects.
These are the pollen sacs of lilies, which are so ingenious that when an unsuspecting insect falls on them, the pollen sacs flip over and hit the insect on the back with a lot of pollen, so that they can follow the insect to other plants.
There is an orchid that looks like it has a mandible. In a way, it does; it forces insects to crawl over, dip in pollen, and take pollen elsewhere.
Orchids: There are at least 20,000 species of orchids -- an astonishing variety.
They have all kinds of tricks.
They have to try and attract pollinators to help them through the process.
This orchid, known as Darwin's orchid because it was studied by Darwin and gave a wonderful prediction when he saw it, can be seen here with a very long nectar tube hanging down from the orchid.
Basically what the insect has to do -- we come to the middle of the flower -- it pierces the mouthpiece into the middle part all the way down to the nectar tube to get the nectar.
Looking at the flower, Darwin said, "I suspect that some things have evolved with it."
There is no doubt that it is an insect.
I mean, it's usually rolled up, but when it's straightened out, it looks like this.
It is now conceivable that if nectar, such a valuable thing, is expensive for plants to produce and can attract many pollinators, then, as in human sexuality, people may start to cheat each other.
They might say, "I have some nectar. Do you want to come and get some?"
This is a plant.
The plant is a favorite of insects in South Africa, which have evolved long mouthpieces to capture nectar at the bottom.
This is an imitator.
This kind of plant is imitating the former.
There is a fly with a long mouthpiece that doesn't get any nectar from the impostor because the impostor doesn't give it any nectar. It thinks it can get it.
So, not only do flies not get nectar from fake plants, but if you look very close to the top of the head, you will see that there is some pollen there that will be spread to other plants, if no botanist comes to stick it on a blue card.
(Laughter) This kind of lie is spread all over the plant kingdom.
This flower with black dots: They may look like black dots to us, but let me tell you, to the right species of male insects, they look like two very, very sexy females.
(Laughter) When an insect arrives and lands on it, it immerses itself in pollen, which, of course, it will take to other plants. If you look at the scanning electron microscope images that every family should have, you can see that there are actually some patterns there, three-dimensional patterns.
It even makes insects feel comfortable, and it looks good.
These electron microscope images -- this is an orchid masquerading as an insect -- you can see that for our eyes, different parts of the structure have different colors and different textures, and insects may be able to perceive very, very different textures.
The orchid evolved to mimic the metallic sheen seen on some beetles.
You can see this surface under a scanning electron microscope -- it's very different from other surfaces we've looked at.
Sometimes the whole plant will mimic an insect, even if we look like an insect.
I mean, I think it looks like some kind of flying animal or beast.
It's a wonderful and magical thing.
That's the clever thing about it. It's called obsidian.
I think it can be tricky at times.
For the right kind of bee, this looks like another very aggressive bee that will fly over and hit it with its head many times, trying to drive it away, which will, of course, make it pollen.
Another thing it does is that the plant mimics another orchid that is rich in insects' favorite food.
But there's really nothing.
So it's deceiving on two levels -- it's unbelievable.
(Laughter) What we see is ylang ylang, the part that has a strong fragrance.
Actually, I've smelled it before.
These flowers don't really need to be so showy.
They give off a wonderful scent to attract any interested insect.
This flower doesn't smell very good.
This flower actually smells very bad to mention again, this is an evolution, it looks like carrion.
So the flies like it.
The flies fly in and help pollinate them.
This is the white star potato, also known as the dead horse potato.
I don't know what a dead horse smells like, but this flower probably smells very similar.
It's just awful.
The green-headed fly couldn't help but feel it.
Fly into it, fly all the way into it.
Laying eggs on it, thinking it's a nice piece of carrion, and not realizing there's no food for eggs here, the eggs will die here, but at the same time the plant will benefit because the hard hairs loose and the flies disappear and pollinate to another flower -- it's amazing.
This is the potato plant, the European potato, the variegated Arrowhead, known in this country as the longevity grass.
I photographed this in Dorset last week.
This guy heats up to about 15 degrees above the ambient temperature -- incredible.
If you look inside, behind the meat spike is something like a dam, and the flies are attracted to the heat -- it's a boiling volatile chemical, the insects -- and they're trapped under this container.
They drank the sweet nectar and then all became a little slimy.
At night they are covered in pollen, sprayed down from above, and then the stiff hairs we see on them become withered, allowing the pollen-covered insects to escape -- it's incredible.
If you think this is unbelievable, this one is my favorite.
This is spring-feathered green velvet.
Everyone here from Brazil should know about this kind of plant.
It's the most amazing thing.
Its stamens are about a foot long.
It has an ability that no other plant has as far as I know, and when it is in full bloom -- this is the meat spike in the middle -- for about two days, it produces some sort of metabolic change somewhat similar to that of a mammal.
It doesn't have starch, it's a plant food, it has something very similar to brown fat that burns it at the rate of fat burning, metabolizing it at the rate of about a kitten.
It's twice the energy output of a hummingbird by weight -- absolutely amazing.
It has also done some unusual things.
Not only will it heat up to 155 degrees Fahrenheit, 43 degrees Celsius or 44 degrees Celsius for two days, but it will stay at a constant temperature.
There is a temperature-regulating mechanism for maintaining a constant temperature.
Why do you do this? I hear you ask.
Unbeknownst to you at present, some beetles like to mate at this temperature.
They burrowed in and were covered in pollen.
(Laughter) Plants sprinkle pollen all over their bodies and let them leave to pollinate.
What a wonderful thing it is.
Now we think most pollinators are insects, but in fact in the tropics, many birds and butterflies also pollinate.
Many tropical flowers are red, because butterflies and birds are similar to us, and we think it's very good to see red.
But if you look at the spectrum, the birds and us, we see red, green and blue to see this spectrum.
Insects see green, blue, and ultraviolet light, and they can see all kinds of light and dark ultraviolet light.
There are still some colors behind it.
"Wouldn't it be nice if we could see those colors?" I hear you ask.
Yes, we can see that.
So what do the insects see?
Last week I took these pictures of desert lotus, the half-day flower genus, in Dorset.
As we can see, these are small yellow flowers, and there are many of them everywhere.
It looks like this in the visible light.
If you remove the red color it looks like this.
Most bees are unable to perceive red.
Then I put an ultraviolet filter in front of my lens for a long exposure at a specific frequency of ultraviolet light, and got this picture.
It's like a real, wonderful bullseye.
Now we don't know exactly what the bees are seeing, and when I call it red, you know what I'm looking at.
We have no way of knowing what's going on, whether it's insects or other human brains.
But the contrast looks like this. It's highlighted in the background.
This is another kind of florets -- located in different ultraviolet frequency ranges, with different filters to match different pollinators.
It probably looks that way.
To avoid thinking that all yellow flowers have this property - no damage to the flowers during the shoot; just stick it on a tripod and don't take it off - in ultraviolet light, look at this.
This can be used as a base for sunscreen, which works by absorbing ultraviolet light.
So maybe some of the chemicals are useful.
Finally, it's a nocturnal fragrance sent to me by Norway's Bjorn Rorslett - a wonderfully hidden pattern.
I like the way it's hidden.
I think it's very poetic. These pictures were taken with an ultraviolet filter, which astronomers use to photograph Venus -- actually the clouds on Venus.
This is the main purpose of this filter.
Venus, of course, is the god of love and fertility, and this is the story of flowers.
Just as flowers spend so much energy trying to attract pollinators to accept their invitation, somehow they also succeed in convincing us that they are rich in meaning. We send flowers to each other at birth and death, especially at weddings, and when you think about it, it is in this moment that genetic material moves from one organism to another.
Thank you very much.
(Applause)
